{"posts":[{"title":"SpringBoot 集成 Mybatis-Plus","content":"1 Mybatis-Plus简介 1.1 简介 MyBatis-Plus（简称 MP）是一个 MyBatis 的增强工具，在 MyBatis 的基础上只做增强不做改变，为简化开发、提高效率而生。该框架由baomidou（苞米豆）组织开发并且开源的。官网：https://mp.baomidou.com/，码云地址：https://gitee.com/organizations/baomidou 愿景 我们的愿景是成为 MyBatis 最好的搭档，就像魂斗罗 中的 1P、2P，基友搭配，效率翻倍。 1.2 特性 无侵入：只做增强不做改变，引入它不会对现有工程产生影响，如丝般顺滑 损耗小：启动即会自动注入基本 CURD，性能基本无损耗，直接面向对象操作 强大的 CRUD 操作：内置通用 Mapper、通用 Service，仅仅通过少量配置即可实现单表大部分 CRUD 操作，更有强大的条件构造器，满足各类使用需求 支持 Lambda 形式调用：通过 Lambda 表达式，方便的编写各类查询条件，无需再担心字段写错 支持多种数据库：支持 MySQL、MariaDB、Oracle、DB2、H2、HSQL、SQLite、Postgre、SQLServer2005、SQLServer 等多种数据库 支持主键自动生成：支持多达 4 种主键策略（内含分布式唯一 ID 生成器 - Sequence），可自由配置，完美解决主键问题 支持 XML 热加载：Mapper 对应的 XML 支持热加载，对于简单的 CRUD 操作，甚至可以无 XML 启动 支持 ActiveRecord 模式：支持 ActiveRecord 形式调用，实体类只需继承 Model 类即可进行强大的 CRUD 操作 支持自定义全局通用操作：支持全局通用方法注入（ Write once, use anywhere ） 支持关键词自动转义：支持数据库关键词（order、key......）自动转义，还可自定义关键词 内置代码生成器：采用代码或者 Maven 插件可快速生成 Mapper 、 Model 、 Service 、 Controller 层代码，支持模板引擎，更有超多自定义配置等您来使用 内置分页插件：基于 MyBatis 物理分页，开发者无需关心具体操作，配置好插件之后，写分页等同于普通 List 查询 内置性能分析插件：可输出 Sql 语句以及其执行时间，建议开发测试时启用该功能，能快速揪出慢查询 内置全局拦截插件：提供全表 delete 、update 操作智能分析阻断，也可自定义拦截规则，预防误操作 内置 Sql 注入剥离器：支持 Sql 注入剥离，有效预防 Sql 注入攻击 2 快速入门 2.1 创建数据库及表 -- 创建测试表 CREATE TABLE `sys_user` ( `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '主键ID', `user_name` varchar(20) NOT NULL COMMENT '用户名', `name` varchar(30) DEFAULT NULL COMMENT '姓名', `age` int(11) DEFAULT NULL COMMENT '年龄', PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; -- 插入测试数据 INSERT INTO `sys_user` (`id`, `user_name`, `name`, `age`) VALUES ('1', 'zhangsan', '张三', '18'); INSERT INTO `sys_user` (`id`, `user_name`, `name`, `age`) VALUES ('2', 'lisi', '李四', '20'); INSERT INTO `sys_user` (`id`, `user_name`, `name`, `age`) VALUES ('3', 'wangwu', '王五', '28'); INSERT INTO `sys_user` (`id`, `user_name`, `name`, `age`) VALUES ('4', 'zhaoliu', '赵六', '21'); INSERT INTO `sys_user` (`id`, `user_name`, `name`, `age`) VALUES ('5', 'sunqi', '孙七', '24'); ~~~![](http://blog.ludangxin.club/post-images/1597929873595.jpg) ### 2.2 工程搭建 #### 完整的项目结构图示 ![](http://blog.ludangxin.club/post-images/1597929500996.jpg) #### 2.2.1 添加所需依赖 ~~~xml &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--简化代码的工具包--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!--mybatis-plus的springboot支持--&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.3.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--mysql驱动--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; 2.2.2 配置 application.yml spring: datasource: # Oracle: oracle.jdbc.OracleDriver # 5.7之前版本使用 com.mysql.jdbc.Driver driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/mp?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8 username: root password: root type: com.zaxxer.hikari.HikariDataSource hikari: minimum-idle: 5 maximum-pool-size: 5 auto-commit: true idle-timeout: 30000 pool-name: DatebookHikariCP max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1 # Oracle: SELECT 1 FROM DUAL mybatis-plus: # 设置Mapper接口所对应的XML文件位置，如果你在Mapper接口中有自定义方法，需要进行该配置 mapper-locations: classpath*:mybatis/*.xml # 设置别名包扫描路径，通过该属性可以给包中的类注册别名 type-aliases-package: com.ludangxin.mp.pojo configuration: # 控制台sql打印 log-impl: org.apache.ibatis.logging.stdout.StdOutImpl 2.2.3 编写pojo import com.baomidou.mybatisplus.annotation.TableName; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @AllArgsConstructor @TableName(&quot;sys_user&quot;) public class User { @TableId(&quot;ID&quot;) private Long id; //驼峰命名,则无需注解 @TableField(&quot;USER_NAME&quot;) private String userName; @TableField(&quot;NAME&quot;) private String name; @TableField(&quot;AGE&quot;) private Integer age; } 2.2.5 编写mapper接口和配置文件 import com.ludangxin.mp.pojo.User; import com.baomidou.mybatisplus.core.mapper.BaseMapper; public interface UserMapper extends BaseMapper&lt;User&gt; { } 在resources目录下新建一个文件夹mybatis，专门存放mapper配置文件 &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt; &lt;mapper namespace=&quot;com.ludangxin.mp.mapper.UserMapper&quot;&gt; &lt;/mapper&gt; 2.2.6 修改启动类 import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.SpringApplication; import org.springframework.boot.WebApplicationType; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.boot.builder.SpringApplicationBuilder; //设置mapper接口的扫描包 @MapperScan(&quot;com.ludangxin.mp.mapper&quot;) @SpringBootApplication public class MyApplication { public static void main(String[] args) { SpringApplication.run(MyApplication.class, args); } } 2.2.7 编写测试用例 import com.ludangxin.mp.mapper.UserMapper; import com.ludangxin.mp.pojo.User; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import java.util.List; @RunWith(SpringRunner.class) @SpringBootTest public class TestMybatisSpringBoot { @Autowired private UserMapper userMapper; @Test public void testSelect() { //根据id查询数据 User user = userMapper.selectById(2L); System.out.println(user); } } 测试结果： JDBC Connection [HikariProxyConnection@358849801 wrapping com.mysql.cj.jdbc.ConnectionImpl@4fba8eec] will not be managed by Spring ==&gt; Preparing: SELECT ID,USER_NAME,NAME,AGE FROM sys_user WHERE ID=? ==&gt; Parameters: 2(Long) &lt;== Columns: ID, USER_NAME, NAME, AGE &lt;== Row: 2, lisi, 李四, 20 &lt;== Total: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@39da5e49] User(id=2, userName=lisi, name=李四, age=20) 3 通用CRUD 在入门案例中，我们的Mapper接口继承了BaseMapper，然后就可以进行到各种各样的单表操作，接下来我们将详细讲解这些操作。 3.1 插入操作 3.1.1 insert方法 /** * 插入一条记录 * @param entity 实体对象 */ int insert(T entity); 3.1.2 测试用例 import com.ludangxin.mp.mapper.UserMapper; import com.ludangxin.mp.pojo.User; import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import java.util.List; @RunWith(SpringRunner.class) @SpringBootTest public class TestUserMapper { @Autowired private UserMapper userMapper; @Test public void testInsert(){ User user = new User(); user.setAge(301); user.setUserName(&quot;caocao&quot;); user.setName(&quot;曹操&quot;); //返回的result是受影响的行数，并不是自增后的id int result = userMapper.insert(user); System.out.println(&quot;result = &quot; + result); //自增后的id会回填到对象中 System.out.println(user.getId()); } } 测试结果： JDBC Connection [HikariProxyConnection@1240320816 wrapping com.mysql.cj.jdbc.ConnectionImpl@59303963] will not be managed by Spring ==&gt; Preparing: INSERT INTO sys_user ( ID, USER_NAME, NAME, AGE ) VALUES ( ?, ?, ?, ? ) ==&gt; Parameters: 1295736901034086401(Long), caocao(String), 曹操(String), 301(Integer) &lt;== Updates: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@108e9837] result = 1 1295736901034086401 3.1.3 主键生成策略 在刚才的例子中，数据已经保存到了数据库，但是id的值不是我们期望的自增长，而是MP生成了id的值并写入到了数据库。我们也可以通过IdType类自己设置id的生成策略。 package com.baomidou.mybatisplus.annotation; import lombok.Getter; /** * 生成ID类型枚举类 */ @Getter public enum IdType { /** * 数据库ID自增 */ AUTO(0), /** * 该类型为未设置主键类型，这是默认值 */ NONE(1), /** * 用户输入ID * &lt;p&gt;该类型可以通过自己注册自动填充插件进行填充&lt;/p&gt; */ INPUT(2), /* 以下3种类型、只有当插入对象ID为空，才自动填充。 */ /** * 全局唯一ID (idWorker) */ ID_WORKER(3), /** * 全局唯一ID (UUID) */ UUID(4), /** * 字符串全局唯一ID (idWorker的字符串表示) */ ID_WORKER_STR(5); private final int key; IdType(int key) { this.key = key; } } 修改User对象，设置id为自增长： import com.baomidou.mybatisplus.annotation.IdType; import com.baomidou.mybatisplus.annotation.TableId; import com.baomidou.mybatisplus.annotation.TableName; import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; @Data @NoArgsConstructor @AllArgsConstructor @TableName(&quot;sys_user&quot;) public class User { @TableId(type = IdType.AUTO) //指定id为自增长 private Long id; ... ... } 3.2 更新操作 3.2.1 updateById方法 /** * 根据ID修改 * @param entity 实体对象 */ int updateById(@Param(Constants.ENTITY) T entity); #### 3.2.2 测试用例 @Test public void testUpdateById() { User user = new User(); user.setId(5L); //主键 user.setAge(21); //更新的字段 //根据id更新，更新不为null的字段 this.userMapper.updateById(user); } } 测试结果： JDBC Connection [HikariProxyConnection@864078397 wrapping com.mysql.cj.jdbc.ConnectionImpl@23310248] will not be managed by Spring ==&gt; Preparing: UPDATE sys_user SET AGE=? WHERE id=? ==&gt; Parameters: 21(Integer), 5(Long) &lt;== Updates: 1 3.3 删除操作 3.3.1 deleteById /** * 根据 ID 删除 * @param id 主键ID */ int deleteById(Serializable id); 3.3.2 测试用例 @Test public void testDeleteById() { //执行删除操作 int result = this.userMapper.deleteById(6L); System.out.println(&quot;result = &quot; + result); } } 测试结果： JDBC Connection [HikariProxyConnection@103068963 wrapping com.mysql.cj.jdbc.ConnectionImpl@50b46e24] will not be managed by Spring ==&gt; Preparing: DELETE FROM sys_user WHERE id=? ==&gt; Parameters: 5(Long) &lt;== Updates: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@5934ca1e] result = 1 3.3.3 批量删除 @Test public void testDeleteByIds() { //根据id集合批量删除 int result = this.userMapper.deleteBatchIds(Arrays.asList(1L,10L,20L)); System.out.println(&quot;result = &quot; + result); } 3.4 查询操作 MP提供了多种查询操作，包括根据id查询、批量查询、查询单条数据、查询列表、分页查询等操作。 3.4.1 selectById /** * 根据ID查询 * @param id 主键ID */ T selectById(Serializable id); 3.4.2 测试用例 @Test public void testSelectById() { //根据id查询数据 User user = this.userMapper.selectById(2L); System.out.println(&quot;result = &quot; + user); } } 测试结果： JDBC Connection [HikariProxyConnection@1317052417 wrapping com.mysql.cj.jdbc.ConnectionImpl@624b523] will not be managed by Spring ==&gt; Preparing: SELECT id,USER_NAME,NAME,AGE FROM sys_user WHERE id=? ==&gt; Parameters: 2(Long) &lt;== Columns: id, USER_NAME, NAME, AGE &lt;== Row: 2, lisi, 李四, 20 &lt;== Total: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@1cbc5693] result = User(id=2, userName=lisi, name=李四, age=20) 4 条件构造器 在增删改查中，最复杂的就是带有各种条件的操作。在MP中，专门针对sql条件进行了封装，提供了各种Wrapper接口及其实现类。XxxWrapper类提供了各种方法来封装sql条件。 MP提供了各种方法用来支持带有条件的查询方法、修改方法和删除方法： /** 根据 entity 条件，查询一条记录 @param queryWrapper 实体对象封装操作类（可以为null） */ T selectOne(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper); /** 根据 Wrapper 条件，查询总记录数 @param queryWrapper 实体对象封装操作类（可以为null） */ Integer selectCount(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper); /** 根据 entity 条件，查询全部记录 @param queryWrapper 实体对象封装操作类（可以为null） */ List&lt;T&gt; selectList(@Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper); 下面我们以查询方法为例学习条件构造器的具体用法。 4.1 比较操作 eq 等于 = ne 不等于 &lt;&gt; gt 大于 &gt; ge 大于等于 &gt;= lt 小于 &lt; le 小于等于 &lt;= between BETWEEN 值1 AND 值2 notBetween NOT BETWEEN 值1 AND 值2 in 字段 IN (value.get(0), value.get(1), ...) notIn 字段 NOT IN (v0, v1, ...) 测试用例： @Test public void testEq() { QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;(); //SELECT id,user_name,name,age FROM sys_user WHERE // AND age &gt;= ? AND name IN (?,?,?) wrapper.ge(&quot;age&quot;, 20) .in(&quot;name&quot;, &quot;李四&quot;, &quot;王五&quot;, &quot;赵六&quot;); List&lt;User&gt; users = this.userMapper.selectList(wrapper); for (User user : users) { System.out.println(user); } } } 测试结果: JDBC Connection [HikariProxyConnection@525275084 wrapping com.mysql.cj.jdbc.ConnectionImpl@46c10083] will not be managed by Spring ==&gt; Preparing: SELECT id,USER_NAME,NAME,AGE FROM sys_user WHERE age &gt;= ? AND name IN (?,?,?) ==&gt; Parameters: 20(Integer), 李四(String), 王五(String), 赵六(String) &lt;== Columns: id, USER_NAME, NAME, AGE &lt;== Row: 2, lisi, 李四, 20 &lt;== Row: 3, wangwu, 王五, 28 &lt;== Row: 4, zhaoliu, 赵六, 21 &lt;== Total: 3 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@61149fa5] User(id=2, userName=lisi, name=李四, age=20) User(id=3, userName=wangwu, name=王五, age=28) User(id=4, userName=zhaoliu, name=赵六, age=21) 4.2 模糊查询 like LIKE '%值%' 例: like(&quot;name&quot;, &quot;王&quot;)---&gt;name like '%王%' notLike NOT LIKE '%值%' 例: notLike(&quot;name&quot;, &quot;王&quot;)---&gt;name not like '%王%' likeLeft LIKE '%值' 例: likeLeft(&quot;name&quot;, &quot;王&quot;)---&gt;name like '%王' likeRight LIKE '值%' 例: likeRight(&quot;name&quot;, &quot;王&quot;)---&gt;name like '王%' 测试用例： @Test public void testLike() { QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;(); //SELECT id,user_name,name,age FROM sys_user WHERE name LIKE ? //Parameters: %曹%(String) wrapper.like(&quot;name&quot;, &quot;曹&quot;); List&lt;User&gt; users = this.userMapper.selectList(wrapper); for (User user : users) { System.out.println(user); } } } 4.3 排序 orderBy 排序：ORDER BY 字段, ... 例: orderBy(true, true, &quot;id&quot;, &quot;name&quot;)---&gt;order by id ASC,name ASC orderByAsc 排序：ORDER BY 字段, ... ASC 例: orderByAsc(&quot;id&quot;, &quot;name&quot;)---&gt;order by id ASC,name ASC orderByDesc 排序：ORDER BY 字段, ... DESC 例: orderByDesc(&quot;id&quot;, &quot;name&quot;)---&gt;order by id DESC,name DESC 测试用例： @Test public void testOrderByAgeDesc() { QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;(); //SELECT id,user_name,name,age FROM sys_user ORDER BY age DESC wrapper.orderByDesc(&quot;age&quot;); List&lt;User&gt; users = this.userMapper.selectList(wrapper); for (User user : users) { System.out.println(user); } } } 4.4 逻辑查询 or 拼接 OR 主动调用or表示紧接着下一个方法不是用and连接!(不调用or则默认为使用and连接) and AND 嵌套 例: and(i -&gt; i.eq(&quot;name&quot;, &quot;李白&quot;).ne(&quot;status&quot;, &quot;活着&quot;))---&gt;and (name = '李白' and status &lt;&gt; '活着') 测试用例： @Test public void testOr() { QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;(); //SELECT id,user_name,name,age FROM sys_user WHERE //name = ? OR age = ? wrapper.eq(&quot;name&quot;,&quot;李四&quot;).or().eq(&quot;age&quot;, 24); List&lt;User&gt; users = this.userMapper.selectList(wrapper); for (User user : users) { System.out.println(user); } } } @Test public void testAnd() { QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;&gt;(); //SELECT id,USER_NAME,NAME,AGE FROM sys_user WHERE age = ? AND ( name = ? OR user_Name = ? ) wrapper.eq(&quot;age&quot;, 20) .and(obj -&gt; obj.eq(&quot;name&quot;,&quot;李四&quot;).or().eq(&quot;user_name&quot;, &quot;王五&quot;)); List&lt;User&gt; users = this.userMapper.selectList(wrapper); for (User user : users) { System.out.println(user); } } 4.5 分页查询 selectPage方法： /** * 根据 entity 条件，查询全部记录（并翻页） * @param page 分页查询条件（可以为 RowBounds.DEFAULT） * @param queryWrapper 实体对象封装操作类（可以为 null） */ IPage&lt;T&gt; selectPage(IPage&lt;T&gt; page, @Param(Constants.WRAPPER) Wrapper&lt;T&gt; queryWrapper); 配置分页插件： import com.baomidou.mybatisplus.extension.plugins.PaginationInterceptor; import org.mybatis.spring.annotation.MapperScan; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class MybatisPlusConfig { /** * 分页插件 */ @Bean public PaginationInterceptor paginationInterceptor() { PaginationInterceptor paginationInterceptor = new PaginationInterceptor(); // 设置请求的页面大于最大页后操作， true调回到首页，false 继续请求 默认false // paginationInterceptor.setOverflow(false); // 设置最大单页限制数量，默认 500 条，-1 不受限制 // paginationInterceptor.setLimit(500); // 开启 count 的 join 优化,只针对部分 left join paginationInterceptor.setCountSqlParser(new JsqlParserCountOptimize(true)); return paginationInterceptor; } } 测试用例： @Test public void testSelectPage() { QueryWrapper&lt;User&gt; wrapper = new QueryWrapper&lt;User&gt;(); wrapper.gt(&quot;age&quot;, 20); //年龄大于20岁 Page&lt;User&gt; page = new Page&lt;&gt;(1,1); //根据条件查询数据 IPage&lt;User&gt; iPage = this.userMapper.selectPage(page, wrapper); System.out.println(&quot;数据总条数：&quot; + iPage.getTotal()); System.out.println(&quot;总页数：&quot; + iPage.getPages()); List&lt;User&gt; users = iPage.getRecords(); for (User user : users) { System.out.println(&quot;user = &quot; + user); } } } 测试结果: JDBC Connection [HikariProxyConnection@1663774813 wrapping com.mysql.cj.jdbc.ConnectionImpl@44598ef7] will not be managed by Spring JsqlParserCountOptimize sql=SELECT id,USER_NAME,NAME,AGE FROM sys_user WHERE age &gt; ? ==&gt; Preparing: SELECT COUNT(1) FROM sys_user WHERE age &gt; ? ==&gt; Parameters: 20(Integer) &lt;== Columns: COUNT(1) &lt;== Row: 3 ==&gt; Preparing: SELECT id,USER_NAME,NAME,AGE FROM sys_user WHERE age &gt; ? LIMIT ?,? ==&gt; Parameters: 20(Integer), 0(Long), 1(Long) &lt;== Columns: id, USER_NAME, NAME, AGE &lt;== Row: 3, wangwu, 王五, 28 &lt;== Total: 1 Closing non transactional SqlSession [org.apache.ibatis.session.defaults.DefaultSqlSession@11d4d979] 数据总条数：3 总页数：3 user = User(id=3, userName=wangwu, name=王五, age=28) 4.6 修改和删除 前面都是以查询为例讲解条件构造器，那么在进行修改和删除操作时也可以带条件，和查询基本一样，这里不再讲解，后面用到时再说。 /** 根据wrapper封装的条件进行更新操作 */ int delete(@Param(&quot;ew&quot;) Wrapper&lt;T&gt; wrapper); /** 根据wrapper封装的条件进行删除操作 */ int update(@Param(&quot;et&quot;) T entity, @Param(&quot;ew&quot;) Wrapper&lt;T&gt; updateWrapper); 4.7 lambda ​ 获取 LambdaWrapper ​ 在QueryWrapper中是获取LambdaQueryWrapper ​ 在UpdateWrapper中是获取LambdaUpdateWrapper ​ 强烈使用lambda表达式构建wrapper，无需再担心字段写错 4.7.1 测试用例 @Test public void testLambdaSelect(){ LambdaQueryWrapper lambdaQueryWrapper = new LambdaQueryWrapper&lt;User&gt;().eq(User::getUserName,&quot;zhangsan&quot;); //QueryWrapper&lt;User&gt; queryWrapper = new QueryWrapper&lt;&gt;(); //queryWrapper.lambda().eq(User::getName, &quot;zhangsan&quot;); int result = this.userMapper.selectCount(lambdaQueryWrapper); System.out.println(&quot;result = &quot; + result); } 5 Mybatis-Plus的Service封装 Mybatis-Plus为了开发更加快捷，对业务层也进行了封装，直接提供了相关的接口和实现类。我们在进行业务层开发时，可以继承它提供的接口和实现类，使得编码更加高效。 com.baomidou.mybatisplus.extension.service.IService接口 该接口是一个泛型接口，里面提供了很多方法，包括基本的增删改查。 com.baomidou.mybatisplus.extension.service.impl.ServiceImpl类 该类实现了上面接口中的所有方法。 测试用例 1）自定义业务层接口，继承IService： public interface UserService extends IService&lt;User&gt; { } 2）自定义业务层实现类，继承ServiceImpl： @Service public class UserServiceImpl extends ServiceImpl&lt;UserMapper,User&gt; implements UserService { } 3）测试类： @RunWith(SpringRunner.class) @SpringBootTest public class TestUserService { @Autowired private UserService userService; @Test public void testInsert() { User user = new User(); user.setAge(301); user.setUserName(&quot;caocao1&quot;); user.setName(&quot;曹操1&quot;); userService.save(user); //获取自增长后的id值, 自增长后的id值会回填到user对象中 System.out.println(&quot;id =&gt; &quot; + user.getId()); } @Test public void testSelectById() { User user = userService.getById(2); System.out.println(user); } @Test public void testUpdateById() { User user = new User(); user.setId(1L); //条件，根据id更新 user.setAge(19); //更新的字段 userService.updateById(user); } @Test public void testDeleteById(){ // 根据id删除数据 userService.removeById(2L); } } 6 oracle 主键 Sequence 在mysql中，主键往往是自增长的，这样使用起来是比较方便的，如果使用的是Oracle数据库，那么就不能使用自增长了，就得使用Sequence 序列生成id值了。 6.1修改application.properties mybatis-plus: # 设置Mapper接口所对应的XML文件位置，如果你在Mapper接口中有自定义方法，需要进行该配置 mapper-locations: classpath*:mybatis/*.xml # 设置别名包扫描路径，通过该属性可以给包中的类注册别名 type-aliases-package: com.ludangxin.mp.pojo configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl # id 生成策略 global-config: db-config: id-type: input 6.2 MybatisPlusConfig 增加序列生成器配置 /*** 序列生成器 */ @Bean public OracleKeyGenerator oracleKeyGenerator(){ return new OracleKeyGenerator(); } 7 逻辑删除 开发系统时，有时候在实现功能时，删除操作需要实现逻辑删除，所谓逻辑删除就是将数据标记为删除，而并非真正的物理删除（非DELETE操作），查询时需要携带状态条件，确保被标记的数据不被查询到。这样做的目的就是避免数据被真正的删除。 7.1 增加字段 ALTER TABLE sys_user ADD COLUMN deleted int(1) NULL DEFAULT 0 COMMENT '1代表删除，0代表未删除'; 7.2 修改pojo @TableLogic private Integer deleted; 7.3 修改application.yml mybatis-plus: # 设置Mapper接口所对应的XML文件位置，如果你在Mapper接口中有自定义方法，需要进行该配置 mapper-locations: classpath*:mybatis/*.xml # 设置别名包扫描路径，通过该属性可以给包中的类注册别名 type-aliases-package: com.ludangxin.mp.pojo configuration: # 控制台sql打印 log-impl: org.apache.ibatis.logging.stdout.StdOutImpl global-config: db-config: # 逻辑删除值为1 logic-delete-value: 1 # 逻辑未删除值为 0 logic-not-delete-value: 0 7.4 测试用例 @Test public void testDeleteById2() { this.userMapper.deleteById(3L); } 7.5 测试结果 JDBC Connection [HikariProxyConnection@2098830440 wrapping com.mysql.cj.jdbc.ConnectionImpl@63411512] will not be managed by Spring ==&gt; Preparing: UPDATE sys_user SET deleted=1 WHERE id=? AND deleted=0 ==&gt; Parameters: 3(Long) &lt;== Updates: 1 8 乐观锁 主要适用场景 意图： 当要更新一条记录的时候，希望这条记录没有被别人更新 乐观锁实现方式： 取出记录时，获取当前version 更新时，带上这个version 执行更新时， set version = newVersion where version = oldVersion 如果version不对，就更新失败 乐观锁配置需要2步 记得两步 8.1 增加字段 ALTER TABLE `sys_user` ADD COLUMN `version` int(10) NULL COMMENT '乐观锁' ; 8.2 修改pojo @Version private Integer version; 8.3 增加乐观锁配置 /** * 乐观锁配置 * @return */ @Bean public OptimisticLockerInterceptor optimisticLockerInterceptor() { return new OptimisticLockerInterceptor(); } 8.4 测试用例 @Test public void testUpdate(){ User user = new User(); user.setAge(30); user.setId(2L); //获取到version为1 user.setVersion(1); int result = this.userMapper.updateById(user); System.out.println(&quot;result = &quot; + result); } 8.5 测试结果 JDBC Connection [HikariProxyConnection@2032547119 wrapping com.mysql.cj.jdbc.ConnectionImpl@5bc63e20] will not be managed by Spring ==&gt; Preparing: UPDATE sys_user SET AGE=?, version=? WHERE id=? AND version=? AND deleted=0 ==&gt; Parameters: 30(Integer), 2(Integer), 2(Long), 1(Integer) &lt;== Updates: 0 注: 操作记录数为0说明已经有人update了 9 自动填充功能 示例工程： 👉 mybatis-plus-sample-auto-fill-metainfo 9.1 添加字段 ALTER TABLE `sys_user` ADD COLUMN `create_by` VARCHAR(50) NULL COMMENT '创建人' ; ALTER TABLE `sys_user` ADD COLUMN `update_by` VARCHAR(50) NULL COMMENT '修改人' ; 9.2 修改pojo @TableField(fill = FieldFill.INSERT) private String createBy; @TableField(fill = FieldFill.UPDATE) private String updateBy; 9.2.1 FieldFill提供了多种模式选择 public enum FieldFill { /** * 默认不处理 */ DEFAULT, /** * 插入填充字段 */ INSERT, /** * 更新填充字段 */ UPDATE, /** * 插入和更新填充字段 */ INSERT_UPDATE } 自定义实现类 MyMetaObjectHandler import com.baomidou.mybatisplus.core.handlers.MetaObjectHandler; import lombok.extern.slf4j.Slf4j; import org.apache.ibatis.reflection.MetaObject; import org.springframework.stereotype.Component; @Slf4j @Component public class MyMetaObjectHandler implements MetaObjectHandler { @Override public void insertFill(MetaObject metaObject) { // Object createTime = getFieldValByName(&quot;createTime&quot;, metaObject); // //字段为空，可以进行填充 // if (null == createTime) { // setFieldValByName(&quot;createTime&quot;, LocalDateTime.now(), metaObject); // } log.info(&quot;start insert fill ....&quot;); this.strictInsertFill(metaObject, &quot;createBy&quot;, String.class, this.getUserId()); } @Override public void updateFill (MetaObject metaObject){ log.info(&quot;start update fill ....&quot;); this.strictUpdateFill(metaObject, &quot;updateBy&quot;, String.class, this.getUserId()); } private String getUserId() { return &quot;001&quot;; } } 注意事项： 填充原理是直接给entity的属性设置值!!! 注解则是指定该属性在对应情况下必有值,如果无值则入库会是null MetaObjectHandler提供的默认方法的策略均为:如果属性有值则不覆盖,如果填充值为null则不填充 字段必须声明TableField注解,属性fill选择对应策略,该声明告知Mybatis-Plus需要预留注入SQL字段 填充处理器MyMetaObjectHandler在 Spring Boot 中需要声明@Component或@Bean注入 要想根据注解FieldFill.xxx和字段名以及字段类型来区分必须使用父类的strictInsertFill或者strictUpdateFill方法 不需要根据任何来区分可以使用父类的fillStrategy方法 9.3 执行新增操作日志 JDBC Connection [HikariProxyConnection@897358809 wrapping com.mysql.cj.jdbc.ConnectionImpl@7aea704c] will not be managed by Spring ==&gt; Preparing: INSERT INTO sys_user ( USER_NAME, NAME, AGE, create_by ) VALUES ( ?, ?, ?, ? ) ==&gt; Parameters: caocao(String), 曹操(String), 301(Integer), 001(String) &lt;== Updates: 1 10 多数据源配置 简介 dynamic-datasource-spring-boot-starter 是一个基于springboot的快速集成多数据源的启动器。 其支持 Jdk 1.7+, SpringBoot 1.4.x 1.5.x 2.x.x。 示例项目 可参考项目下的samples目录。 特性 支持 数据源分组 ，适用于多种场景 纯粹多库 读写分离 一主多从 混合模式。 支持数据库敏感配置信息 加密 ENC()。 支持每个数据库独立初始化表结构schema和数据库database。 支持 自定义注解 ，需继承DS(3.2.0+)。 提供对Druid，Mybatis-Plus，P6sy，Jndi的快速集成。 简化Druid和HikariCp配置，提供 全局参数配置 。配置一次，全局通用。 提供 自定义数据源来源 方案。 提供项目启动后 动态增加移除数据源 方案。 提供Mybatis环境下的 纯读写分离 方案。 提供使用 spel动态参数 解析数据源方案。内置spel，session，header，支持自定义。 支持 多层数据源嵌套切换 。（ServiceA &gt;&gt;&gt; ServiceB &gt;&gt;&gt; ServiceC）。 提供对shiro，sharding-jdbc,quartz等第三方库集成的方案,注意事项和示例。 提供 基于seata的分布式事务方案。 附：不支持原生spring事务。 约定 本框架只做 切换数据源 这件核心的事情，并不限制你的具体操作，切换了数据源可以做任何CRUD。 配置文件所有以下划线 _ 分割的数据源 首部 即为组的名称，相同组名称的数据源会放在一个组下。 切换数据源可以是组名，也可以是具体数据源名称。组名则切换时采用负载均衡算法切换。 默认的数据源名称为 master ，你可以通过 spring.datasource.dynamic.primary 修改。 方法上的注解优先于类上注解。 强烈建议只在service的类和方法上添加注解，不建议在mapper上添加注解。 使用方法 引入dynamic-datasource-spring-boot-starter。 &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;dynamic-datasource-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;${version}&lt;/version&gt; &lt;/dependency&gt; 配置数据源。 spring: datasource: dynamic: primary: master #设置默认的数据源或者数据源组,默认值即为master strict: false #设置严格模式,默认false不启动. 启动后在未匹配到指定数据源时候会抛出异常,不启动则使用默认数据源. datasource: master: url: jdbc:mysql://xx.xx.xx.xx:3306/dynamic username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver # 3.2.0开始支持SPI可省略此配置 slave_1: url: jdbc:mysql://xx.xx.xx.xx:3307/dynamic username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver slave_2: url: ENC(xxxxx) # 内置加密,使用请查看详细文档 username: ENC(xxxxx) password: ENC(xxxxx) driver-class-name: com.mysql.jdbc.Driver schema: db/schema.sql # 配置则生效,自动初始化表结构 data: db/data.sql # 配置则生效,自动初始化数据 continue-on-error: true # 默认true,初始化失败是否继续 separator: &quot;;&quot; # sql默认分号分隔符 #......省略 #以上会配置一个默认库master，一个组slave下有两个子库slave_1,slave_2 # 多主多从 纯粹多库（记得设置primary） 混合配置 spring: spring: spring: datasource: datasource: datasource: dynamic: dynamic: dynamic: datasource: datasource: datasource: master_1: mysql: master: master_2: oracle: slave_1: slave_1: sqlserver: slave_2: slave_2: postgresql: oracle_1: slave_3: h2: oracle_2: 使用 @DS 切换数据源。 @DS 可以注解在方法上和类上，同时存在方法注解优先于类上注解。 强烈建议只注解在service实现上。 注解 结果 没有@DS 默认数据源 @DS(&quot;dsName&quot;) dsName可以为组名也可以为具体某个库的名称 @Service @DS(&quot;slave&quot;) public class UserServiceImpl implements UserService { @Autowired private JdbcTemplate jdbcTemplate; public List selectAll() { return jdbcTemplate.queryForList(&quot;select * from user&quot;); } @Override @DS(&quot;slave_1&quot;) public List selectByCondition() { return jdbcTemplate.queryForList(&quot;select * from user where age &gt;10&quot;); } } #赶紧集成体验一下吧！ 如果需要更多功能请点击下面链接查看详细文档！ 常见问题请点我 分布式事务，加密,Druid集成，MybatisPlus集成，动态增减数据源，自定义切换规则,纯读写分离插件等等更多更细致的文档在这里 ","link":"http://blog.ludangxin.club/post/mybatis-plus/"},{"title":"SpringBoot  集成 任务调度","content":"为什么要使用任务调度 定时任务的场景可以说非常广泛，比如某些视频网站，购买会员后，每天会给会员送成长值，每月会给会员送一些电影券；比如在保证最终一致性的场景中，往往利用定时任务调度进行一些比对工作；比如一些定时需要生成的报表、邮件；比如一些需要定时清理数据的任务等。 @Scheduled springboot scheduling 官方教程 快速上手 需求: 每个五秒打印一次日志 引入所需依赖 因spring-boot-starter中默认引入了scheduler依赖,所以不用额外添加 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- lombok 工具类 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 修改启动类 import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.scheduling.annotation.EnableScheduling; // 开启Scheduler @EnableScheduling @SpringBootApplication public class SpringbootApplication { public static void main(String[] args) { SpringApplication.run(SpringbootApplication.class, args); } } 创建日志打印任务 import lombok.extern.slf4j.Slf4j; import org.springframework.scheduling.annotation.Scheduled; import org.springframework.stereotype.Component; import java.text.SimpleDateFormat; import java.util.Date; @Slf4j @Component public class PrintTask { private static final SimpleDateFormat DATE_FORMAT = new SimpleDateFormat(&quot;HH:mm:ss&quot;); /** * 每隔5秒打印一次日志 */ @Scheduled(fixedRate = 5000) public void reportCurrentTime() { log.info(&quot;The time is now {}&quot;, DATE_FORMAT.format(new Date())); } } 输出结果 2020-06-04 21:33:06.130 INFO 1244 --- [ scheduling-1] com.ldx.springboot.scheduler.PrintTask : The time is now 21:33:06 2020-06-04 21:33:11.131 INFO 1244 --- [ scheduling-1] com.ldx.springboot.scheduler.PrintTask : The time is now 21:33:11 2020-06-04 21:33:16.133 INFO 1244 --- [ scheduling-1] com.ldx.springboot.scheduler.PrintTask : The time is now 21:33:16 2020-06-04 21:33:21.135 INFO 1244 --- [ scheduling-1] com.ldx.springboot.scheduler.PrintTask : The time is now 21:33:21 2020-06-04 21:33:26.137 INFO 1244 --- [ scheduling-1] com.ldx.springboot.scheduler.PrintTask : The time is now 21:33:26 2020-06-04 21:33:31.139 INFO 1244 --- [ scheduling-1] com.ldx.springboot.scheduler.PrintTask : The time is now 21:33:31 2020-06-04 21:33:36.140 INFO 1244 --- [ scheduling-1] com.ldx.springboot.scheduler.PrintTask : The time is now 21:33:36 2020-06-04 21:33:41.142 INFO 1244 --- [ scheduling-1] com.ldx.springboot.scheduler.PrintTask : The time is now 21:33:41 配置TaskScheduler线程池 在实际项目中，我们一个系统可能会定义多个定时任务。那么多个定时任务之间是可以相互独立且可以并行执行的。 通过查看org.springframework.scheduling.config.ScheduledTaskRegistrar源代码，发现spring默认会创建一个单线程池。这样对于我们的多任务调度可能会是致命的，当多个任务并发（或需要在同一时间）执行时，任务调度器就会出现时间漂移，任务执行时间将不确定。 源码 protected void scheduleTasks() { if (this.taskScheduler == null) { this.localExecutor = Executors.newSingleThreadScheduledExecutor(); this.taskScheduler = new ConcurrentTaskScheduler(this.localExecutor); } //省略... } 自定义线程池 import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.scheduling.TaskScheduler; import org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler; @Configuration public class ScheduleConfig { @Bean public TaskScheduler taskScheduler() { //org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler ThreadPoolTaskScheduler threadPoolTaskScheduler = new ThreadPoolTaskScheduler(); threadPoolTaskScheduler.setPoolSize(20); return threadPoolTaskScheduler; } } 注解参数介绍 参数 作用 fixedRate 该属性的含义是上一个调用开始后再次调用的延时（不用等待上一次调用完成），这样就会存在重复执行的问题，所以不是建议使用，但数据量如果不大时在配置的间隔时间内可以执行完也是可以使用的。 fixedDelay 该属性的功效与上面的fixedRate则是相反的，配置了该属性后会等到方法执行完成后延迟配置的时间再次执行该方法. initialDelay 该属性跟上面的fixedDelay、fixedRate有着密切的关系，为什么这么说呢？该属性的作用是第一次执行延迟时间，只是做延迟的设定，并不会控制其他逻辑，所以要配合fixedDelay或者fixedRate来使用 cron cron就不做赘述了。传送门 zone 指定解析cron表达式的时区 特点 优点: 足够简单 , 易上手 缺点: 无法实现复杂的业务场景 如果服务器宕机 , 那么内存中的定时任务就会释放,无法支持misfire 分布式部署会出现重复调用的问题等... Quartz Quartz是纯Java实现，而且作为Spring的默认调度框架，由于Quartz的强大的调度功能、灵活的使用方式、还具有分布式集群能力，可以说Quartz出马，可以搞定一切定时任务调度！ Quartz 中主要对象 Scheduler：调度任务的主要API ScheduleBuilder：用于构建Scheduler，例如其简单实现类SimpleScheduleBuilder Job：调度任务执行的接口，也即定时任务执行的方法 JobDetail：定时任务作业的实例 JobBuilder：关联具体的Job，用于构建JobDetail Trigger：定义调度执行计划的组件，即定时执行 TriggerBuilder：构建Trigger 快速上手 添加所需依赖 &lt;!-- spring boot --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- quartz 任务调度 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-quartz&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- mysql依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- lombok 工具类 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 配置application.yml spring: datasource: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/test?useUnicode=true&amp;zeroDateTimeBehavior=convertToNull&amp;autoReconnect=true&amp;characterEncoding=utf-8 username: root password: root hikari: minimum-idle: 5 idle-timeout: 600000 maximum-pool-size: 10 auto-commit: true pool-name: MyHikariCP max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1 quartz: # 相关属性配置 properties: org: quartz: scheduler: # 实例名称 instanceName: TestScheduler # 实例id instanceId: AUTO jobStore: class: org.quartz.impl.jdbcjobstore.JobStoreTX driverDelegateClass: org.quartz.impl.jdbcjobstore.StdJDBCDelegate tablePrefix: QRTZ_ useProperties: false # 开启集群 isClustered: true clusterCheckinInterval: 15000 threadPool: class: org.quartz.simpl.SimpleThreadPool threadCount: 20 threadPriority: 8 threadsInheritContextClassLoaderOfInitializingThread: true # 初始化后是否自动启动调度程序 auto-startup: true # 数据库方式 memory 内存 ; jdbc 数据库 job-store-type: jdbc # 初始化表结构 jdbc: # 项目启动时初始化数据库 never 从不 ; always 每次启动都初始化 initialize-schema: always # 是否覆盖已经持久化的job overwrite-existing-jobs: true quartz官方配置文档 创建Job import lombok.extern.slf4j.Slf4j; import org.quartz.JobExecutionContext; import org.quartz.JobExecutionException; import org.springframework.scheduling.quartz.QuartzJobBean; import java.text.SimpleDateFormat; import java.util.Date; @Slf4j public class LogJob extends QuartzJobBean { private static final SimpleDateFormat DATE_FORMAT = new SimpleDateFormat(&quot;HH:mm:ss&quot;); @Override protected void executeInternal(JobExecutionContext jobExecutionContext) throws JobExecutionException { log.info(&quot;The time is now {}&quot;, DATE_FORMAT.format(new Date())); } } 注册Job信息 import org.quartz.*; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration public class QuartzConfig { @Bean public JobDetail logJobDetail(){ return JobBuilder.newJob(LogJob.class).storeDurably().build(); } @Bean public Trigger logTrigger(){ SimpleScheduleBuilder scheduleBuilder = SimpleScheduleBuilder.simpleSchedule() //每一秒执行一次 .withIntervalInSeconds(1) //永久重复，一直执行下去 .repeatForever(); return TriggerBuilder.newTrigger() .forJob(logJobDetail()) .withSchedule(scheduleBuilder) .build(); } } 启动项目,测试 2020-06-06 17:04:50.904 INFO 9920 --- [eduler_Worker-1] com.ldx.springboot.quartz.LogJob : The time is now 17:04:50 2020-06-06 17:04:50.914 INFO 9920 --- [eduler_Worker-2] com.ldx.springboot.quartz.LogJob : The time is now 17:04:50 2020-06-06 17:04:51.791 INFO 9920 --- [eduler_Worker-3] com.ldx.springboot.quartz.LogJob : The time is now 17:04:51 2020-06-06 17:04:52.791 INFO 9920 --- [eduler_Worker-4] com.ldx.springboot.quartz.LogJob : The time is now 17:04:52 2020-06-06 17:04:53.792 INFO 9920 --- [eduler_Worker-5] com.ldx.springboot.quartz.LogJob : The time is now 17:04:53 2020-06-06 17:04:54.791 INFO 9920 --- [eduler_Worker-6] com.ldx.springboot.quartz.LogJob : The time is now 17:04:54 2020-06-06 17:04:55.791 INFO 9920 --- [eduler_Worker-7] com.ldx.springboot.quartz.LogJob : The time is now 17:04:55 ","link":"http://blog.ludangxin.club/post/springboot-ji-cheng-ren-wu-diao-du/"},{"title":"OAuth2.0","content":"简介 OAUTH协议为用户资源的授权提供了一个安全的、开放而又简易的标准。与以往的授权方式不同之处是OAUTH的授权不会使第三方触及到用户的帐号信息（如用户名与密码），即第三方无需使用用户的用户名与密码就可以申请获得该用户资源的授权，因此OAUTH是安全的。oAuth是Open Authorization的简写。 OAuth2.0是OAuth协议的延续版本，但不向前兼容OAuth 1.0(即完全废止了OAuth1.0)。 OAuth 2.0关注客户端开发者的简易性。要么通过组织在资源拥有者和HTTP服务商之间的被批准的交互动作代表用户，要么允许第三方应用代表用户获得访问的权限。同时为Web应用，桌面应用和手机，和起居室设备提供专门的认证流程。 RFC文档 认证过程 +--------+ +---------------+ | |--(A)- Authorization Request -&gt;| Resource | | | | Owner | | |&lt;-(B)-- Authorization Grant ---| | | | +---------------+ | | | | +---------------+ | |--(C)-- Authorization Grant --&gt;| Authorization | | Client | | Server | | |&lt;-(D)----- Access Token -------| | | | +---------------+ | | | | +---------------+ | |--(E)----- Access Token ------&gt;| Resource | | | | Server | | |&lt;-(F)--- Protected Resource ---| | +--------+ +---------------+ 上图中所涉及到的对象分别为： Client 第三方应用，我们的应用就是一个Client Resource Owner 资源所有者，即用户 Authorization Server 授权服务器，即提供第三方登录服务的服务器，如Github Resource Server 拥有资源信息的服务器，通常和授权服务器属于同一应用 根据上图的信息，我们可以知道OAuth2的基本流程为： 第三方应用请求用户授权。 用户同意授权，并返回一个凭证（code） 第三方应用通过第二步的凭证（code）向授权服务器请求授权 授权服务器验证凭证（code）通过后，同意授权，并返回一个资源访问的凭证（Access Token）。 第三方应用通过第四步的凭证（Access Token）向资源服务器请求相关资源。 资源服务器验证凭证（Access Token）通过后，将第三方应用请求的资源返回。 OAuth2.0的具体实现 看完OAuth的基本流程后，大家实际上对到底如何做OAuth验证还是不太清楚，同时，也会产生疑问，为什么需要两次获取凭证，而不是直接用户授权拿到凭证后就直接获取资源呢？这和OAuth的具体实现有关，让我们来看看OAuth2的具体实现吧。 用户授权 在用户授权这一步中，我们将得到一个用户凭证（code），我们的应用可以通过该用户凭证（code）来和授权服务器交换一个资源访问凭证（Access Token）。 这里我们只讨论第三方登录功能的实现情况，经过分析，我们可以得出用户凭证（code）具有三个特性： 用户凭证（code）需要由用户授权，也就是说该行为是用户的主动行为， 此时为了保证用户身份正确，实际上也需要用户通过授权服务器的验证（登录操作或者已登录状态） 用户凭证（code）需要授权服务器颁发，因为最终用户凭证（code）是由授权服务器验证的，同时用户授权操作为了保证用户身份，也需要在授权服务器上进行操作，因此，用户凭证（code）是由授权服务器进行颁发的 用户凭证（code）需要由授权服务器传递给我们的第三方应用，很明显，由用户在资源服务器上拿到凭证再手动的提交至第三方应用太麻烦，因此，当用户主动授权行为发生后，资源服务器需要将用户凭证（code）发送给第三方应用。 我们以Github为例，看看主流的第三方登录是如何满足上述三个特性的。 第0步. 引导用户进行授权：github 当用户希望使用第三方登录进行登录时，第三方应用会通过类似下图&quot;快速登陆图标&quot;的方式将用户引导至授权页面，为了和OAuth基本流程一致，我们将这一步定义为第0步。 第0.5步. 用户身份验证 当我们点击Github的图标，我们会进入到Github应用下面，此时实际上进行了一次用户身份的验证，之前没有登录Github的用户需要输入Github的账号密码，已登录的用户Github会根据Session进行身份确认。此操作我们称为0.5步。接下来正式进入OAuth2的流程 第1步. 用户授权 用户身份确认后会进入下面这个页面，该页面由授权服务器提供，授权服务器会告诉用户该第三方在授权服务器中提交的相关信息（如果需要实现第三方登录功能，第三方应用需要向Github、微博等应用中提交应用的相关信息，不同服务可能会需要审核等不同的步骤），以及授权后第三方应用能够获取哪些资源。在Github中，最基础的认证可以访问用户的公共信息。如果用户同意授权，需要主动的点击【Authorize application】按钮。 第2步. 返回用户凭证（code） 当用户点击按钮同意授权后，授权服务器将生成一个用户凭证（code），此时授权服务器如何将用户凭证（code）传递给第三方应用呢？ 当我们向授权服务器提交应用信息时，通常需要填写一个redirect_uri，当我们引导用户进入授权页面时，也会附带一个redirect_uri的信息，当授权服务器验证两个URL一致时，会通知浏览器跳转到redirect_uri，同时，在redirect_uri后附加用户凭证（code）的相关信息，此时，浏览器返回第三方应用同时携带用户凭证（code）的相关信息。授权后访问的redirect_uri如下： https://www.csdn.net/oauth/github/callback?code=9e3efa6cea739f9aaab2&amp;state=XXX 这样，第二步返回用户凭证（code）就完成了。 授权服务器授权 从这一步开始，OAuth2 的授权将有两个重大变化的发生： 用户主动行为结束，用户理论上可以不需要再做任何主动的操作，作为第三方应用的我们可以在后台拿到资源服务器上的资源而对用户是不可见的，当用户的浏览器跳到下一个页面时，整个OAuth2的流程已经结束 浏览器端行为结束，从OAuth2 的基本流程可以看出，接下来的流程已经不需要和用户进行交互，接下来的行为都在第三方应用与授权服务器、资源服务器之间的交互。 我们知道浏览器端的行为实际上是不安全的，甚至安全凭证的传递都是通过URL直接传递的。但是由于用户凭证（code）不是那么敏感，其他攻击者拿到用户凭证（code）后依然无法获取到相应的用户资源，所以之前的行为是允许的。接下来我们看看服务器如何交互来安全的获得授权服务器授权。 第3步. 请求授权服务器授权 要拿到授权服务器的授权，需要以下几个信息： client_id 标识第三方应用的id，由授权服务器（Github）在第三方应用提交时颁发给第三方应用 client_secret 第三方应用和授权服务器之间的安全凭证，由授权服务器（Github）在第三方应用提交时颁发给第三方应用 code 第一步中返回的用户凭证redirect_uri 第一步生成用户凭证后跳转到第二步时的地址 state 由第三方应用给出的随机码 我们看到，上述信息还涉及到第三方应用的安全凭证（client_secret），因此要求OAuth要求该请求必须时POST请求，同时，还必须时HTTPS服务，以此保证获取到的验证凭证（Access Token）的安全性。 第4步. 拿到验证凭证（Access Token） 当授权服务器拿到第3步中的所有信息，验证通过后，会将Access Token返回给第三方应用。 访问资源 第5步. 请求访问用户资源 拿到验证凭证（Access Token）后，剩下的事情就很简单了，资源服务器会提供一系列关于用户资源的API，拿验证凭证（Access Token）访问相应的API即可，例如，在GIthub中，如果你想拿到用户信息，可以访问以下API： GET https://api.github.com/user?access_token=... 注意，此时的访问不是通过浏览器进行的，而是服务器直接发送HTTP请求，因此其安全性是可以保证的。 第6步. 返回资源 如果验证凭证（Access Token）是正确的，此时资源服务器就会返回资源信息，此时整个OAuth流程就结束了。 第三方登录 看完OAuth2的资源访问流程，我们的第三方登录是如何做的呢？首先我们需要知道两点： 用户授权信息在授权服务器中是有记录的，当用户第一次授权给相应的第三方应用后，不需要进行再次授权 每个用户在资源服务器中都有一个唯一的ID，第三方应用可以将其存储起来并与本地用户系统一一对应起来 这样，当用户第一次授权并且注册后（主动注册或者第三方应用使用用户信息默认注册），当再次点击第三方登录的按钮，浏览器跳转到授权服务器，授权服务器通过Session找到用户的授权信息，发现该用户已经授权给该第三方应用，将直接跳转到redirect_uri，此时第三方应用通过唯一的用户ID找到相应的本地用户，自动帮助其登录。 这样，就可以达到直接点击第三方登录按钮，不需要任何操作，经过几次跳转后自动登录的效果了。大家快去试试吧。 客户端授权模式 客户端必须得到用户的授权（authorization grant），才能获得令牌（access token）。oAuth 2.0 定义了四种授权方式。 implicit：简化模式 authorization code：授权码模式 resource owner password credentials：密码模式 client credentials：客户端模式 授权码模式 资源拥有者打开客户端，客户端要求资源拥有者给予授权，它将浏览器被重定向到授权服务器，重定向时会 附加客户端的身份信息。如：/uaa/oauth/authorize? client_id=c1&amp;response_type=code&amp;scope=all&amp;redirect_uri=http://www.baidu.com ​ 参数列表如下： ​ client_id：客户端准入标识。 ​ response_type：授权码模式固定为code。 ​ scope：客户端权限。 ​ redirect_uri：跳转uri，当授权码申请成功后会跳转到此地址，并在后边带上code参数（授权码）。 浏览器出现向授权服务器授权页面，之后将用户同意授权。 授权服务器将授权码（AuthorizationCode）转经浏览器发送给client(通过redirect_uri)。 客户端拿着授权码向授权服务器索要访问access_token，请求如下：/uaa/oauth/token? client_id=c1&amp;client_secret=secret&amp;grant_type=authorization_code&amp;code=5PgfcD&amp;redirect_uri=http://w ww.baidu.com ​ 参数列表如下 ​ client_id：客户端准入标识。 ​ client_secret：客户端秘钥。 ​ grant_type：授权类型，填写authorization_code，表示授权码模式 ​ code：授权码，就是刚刚获取的授权码，注意：授权码只使用一次就无效了，需要重新申请。 ​ redirect_uri：申请授权码时的跳转url，一定和申请授权码时用的redirect_uri一致。 授权服务器返回令牌**(access_token)** 这种模式是四种模式中最安全的一种模式。一般用于client是Web服务器端应用或第三方的原生App调用资源服务的时候。因为在这种模式中access_token不会经过浏览器或移动端的App，而是直接从服务端去交换，这样就最大限度的减小了令牌泄漏的风险。 简化模式 资源拥有者打开客户端，客户端要求资源拥有者给予授权，它将浏览器被重定向到授权服务器，重定向时会附加客户端的身份信息。如：/uaa/oauth/authorize? client_id=c1&amp;response_type=token&amp;scope=all&amp;redirect_uri=http://www.baidu.com 参数描述同授权码模式 ，注意response_type=token，说明是简化模式。 浏览器出现向授权服务器授权页面，之后将用户同意授权。 授权服务器将授权码将令牌（access_token）以Hash的形式存放在重定向uri的fargment中发送给浏览器。 注：fragment 主要是用来标识 URI 所标识资源里的某个资源，在 URI 的末尾通过 （#）作为 fragment 的开头，其中 # 不属于 fragment 的值。如https://domain/index#L18这个 URI 中 L18 就是 fragment 的值。大家只需要知道js通过响应浏览器地址栏变化的方式能获取到fragment 就行了。 一般来说，简化模式用于没有服务器端的第三方单页面应用，因为没有服务器端就无法接收授权码。 密码模式 资源拥有者将用户名、密码发送给客户端 客户端拿着资源拥有者的用户名、密码向授权服务器请求令牌（access_token），请求如下： /uaa/oauth/token? client_id=c1&amp;client_secret=secret&amp;grant_type=password&amp;username=shangsan&amp;password=123 ​ 参数列表如下： ​ client_id：客户端准入标识。 ​ client_secret：客户端秘钥。 ​ grant_type：授权类型，填写password表示密码模式 ​ username：资源拥有者用户名。 ​ password：资源拥有者密码。 授权服务器将令牌（access_token）发送给client 这种模式十分简单，但是却意味着直接将用户敏感信息泄漏给了client，因此这就说明这种模式只能用于client是我们自己开发的情况下。因此密码模式一般用于我们自己开发的，第一方原生App或第一方单页面应用。 客户端模式 客户端向授权服务器发送自己的身份信息，并请求令牌（access_token） 确认客户端身份无误后，将令牌（access_token）发送给client，请求如下：/uaa/oauth/token?client_id=c1&amp;client_secret=secret&amp;grant_type=client_credentials ​ 参数列表如下： ​ client_id：客户端准入标识。 ​ client_secret：客户端秘钥。 ​ grant_type：授权类型，填写client_credentials表示客户端模式 这种模式是最方便但最不安全的模式。因此这就要求我们对client完全的信任，而client本身也是安全的。因此这种模式一般用来提供给我们完全信任的服务器端服务。比如，合作方系统对接，拉取一组用户信息。 ","link":"http://blog.ludangxin.club/post/oauth20/"},{"title":"Spring Security 详解 及 快速上手","content":"什么是认证 用户认证就是判断一个用户的身份是否合法的过程，用户去访问系统资源时系统要求验证用户的身份信 息，身份合法方可继续访问，不合法则拒绝访问。常见的用户身份认证方式有：用户名密码登录，二维码登录，手机短信登录，指纹认证等方式。 系统为什么要认证？ 认证是为了保护系统的隐私数据与资源，用户的身份合法方可访问该系统的资源。 什么是会话 用户认证通过后，为了避免用户的每次操作都进行认证可将用户的信息保证在会话中。会话就是系统为了保持当前 用户的登录状态所提供的机制，常见的有基于session方式、基于token方式等。 session 会话 用户认证成功后，在服务端生成用户相关的数据保存在session(当前会话)中，发给客户端的 sesssion_id 存放到 cookie 中，这样用户客户端请求时带上 session_id 就可以验证服务器端是否存在 session 数 据，以此完成用户的合法校验，当用户退出系统或session过期销毁时,客户端的session_id也就无效了。 token 会话 用户认证成功后，服务端生成一个token发给客户端，客户端可以放到 cookie 或 localStorage等存储中，每次请求时带上 token，服务端收到token通过验证后即可确认用户身份。 基于session的认证方式由Servlet规范定制，服务端要存储session信息需要占用内存资源，客户端需要支持 cookie；基于token的方式则一般不需要服务端存储token，并且不限制客户端的存储方式。如今移动互联网时代 更多类型的客户端需要接入系统，系统多是采用前后端分离的架构进行实现，所以基于token的方式更适合。 什么是授权 授权是用户认证通过根据用户的权限来控制用户访问资源的过程，拥有资源的访问权限则正常访问，没有权限则拒绝访问。 为什么要授权？ 认证是为了保证用户身份的合法性，授权则是为了更细粒度的对隐私数据进行划分，授权是在认证通过后发生的，控制不同的用户能够访问不同的资源。 SpringSecurity Spring Security是一个能够为基于Spring的企业应用系统提供声明式的安全访问控制解决方案的安全框架。由于它是Spring生态系统中的一员，因此它伴随着整个Spring生态系统不断修正、升级，在spring boot项目中加入spring security更是十分简单，使用Spring Security 减少了为企业系统安全控制编写大量重复代码的工作。 快速上手 引入所需依赖 &lt;!-- spring security 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- web支持 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; 添加spring security 配置类 package com.ldx.springboot.config; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.security.config.annotation.method.configuration.EnableGlobalMethodSecurity; import org.springframework.security.config.annotation.web.builders.HttpSecurity; import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.crypto.password.NoOpPasswordEncoder; import org.springframework.security.crypto.password.PasswordEncoder; import org.springframework.security.provisioning.InMemoryUserDetailsManager; /** * springsecurity 配置类 * @author ludangxin * @Date 2020-06-01 **/ @Configuration @EnableGlobalMethodSecurity(securedEnabled = true,prePostEnabled = true) public class WebSecurityConfig extends WebSecurityConfigurerAdapter { /** * 定义用户信息服务（查询用户信息） */ @Bean @Override public UserDetailsService userDetailsService(){ //基于内存的userDetail InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager(); //用户zhangsan 拥有访问p1资源权限 manager.createUser(User.withUsername(&quot;zhangsan&quot;).password(&quot;123&quot;).authorities(&quot;p1&quot;).build()); //用户lisi 拥有访问p2资源权限 manager.createUser(User.withUsername(&quot;lisi&quot;).password(&quot;456&quot;).authorities(&quot;p2&quot;).build()); return manager; } /** * 密码编码器 */ @Bean public PasswordEncoder passwordEncoder(){ //无加密机制 return NoOpPasswordEncoder.getInstance(); } /** * 安全拦截机制（最重要） */ @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers(&quot;/r/r1&quot;).hasAuthority(&quot;p1&quot;) .antMatchers(&quot;/r/r2&quot;).hasAuthority(&quot;p2&quot;) //所有的请求必须通过认证 .anyRequest().authenticated() .and() //允许表单登录 .formLogin() //自定义登录成功的页面地址 .successForwardUrl(&quot;/login-success&quot;); } } 编写测试接口 import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class TestController { @RequestMapping(value = &quot;/login-success&quot;) public String loginSuccess(){ return &quot; 登录成功&quot;; } /** * 测试资源1 * @return */ @GetMapping(value = &quot;/r/r1&quot;) public String r1(){ return &quot; 访问资源1&quot;; } /** * 测试资源2 * @return */ @GetMapping(value = &quot;/r/r2&quot;) public String r2(){ return &quot; 访问资源2&quot;; } } 测试 测试登陆功能,访问 localhost:8080 输入 账号:zhangsan 密码: 123登陆成功 访问 /r/r1资源 访问r/r2资源, 403无权限 小结 通过快速上手，咱们使用Spring Security实现了认证和授权，Spring Security提供了基于账号和密码的认证方式，通过安全配置即可实现请求拦截，授权功能，Spring Security能完成的不仅仅是这些。 工作原理 结构总览 Spring Security所解决的问题就是安全访问控制，而安全访问控制功能其实就是对所有进入系统的请求进行拦截，校验每个请求是否能够访问它所期望的资源。 当初始化Spring Security时，会创建一个名为 SpringSecurityFilterChain 的Servlet过滤器，类型为 org.springframework.security.web.FilterChainProxy，它实现了javax.servlet.Filter，因此外部的请求会经过此类，下图是Spring Security过虑器链结构图： FilterChainProxy是一个代理，真正起作用的是FilterChainProxy中SecurityFilterChain所包含的各个Filter，同时这些Filter作为Bean被Spring管理，它们是Spring Security核心，各有各的职责，但他们并不直接处理用户的认证，也不直接处理用户的授权，而是把它们交给了认证管理（AuthenticationManager）和决策管理器（AccessDecisionManager）进行处理. 下面介绍过滤器链中主要的几个过滤器及其作用： SecurityContextPersistenceFilter : 这个Filter是整个拦截过程的入口和出口（也就是第一个和最后一个拦截器），会在请求开始时从配置好的 SecurityContextRepository 中获取 SecurityContext，然后把它设置给SecurityContextHolder。在请求完成后将 SecurityContextHolder 持有的 SecurityContext 再保存到配置好的 SecurityContextRepository，同时清除 securityContextHolder 所持有的SecurityContext； UsernamePasswordAuthenticationFilter : 用于处理来自表单提交的认证。该表单必须提供对应的用户名和密码，其内部还有登录成功或失败后进行处理的 AuthenticationSuccessHandler 和 AuthenticationFailureHandler，这些都可以根据需求做相关改变； FilterSecurityInterceptor : 是用于保护web资源的，使用AccessDecisionManager对当前用户进行授权访问； ExceptionTranslationFilter : 能够捕获来自 FilterChain 所有的异常，并进行处理。但是它只会处理两类异常：AuthenticationException 和 AccessDeniedException，其它的异常它会继续抛出。 认证 流程 用户提交用户名、密码被SecurityFilterChain中的 UsernamePasswordAuthenticationFilter 过滤器获取到，封装为请求Authentication，通常情况下是UsernamePasswordAuthenticationToken这个实现类。 然后过滤器将Authentication提交至认证管理器（AuthenticationManager）进行认证 认证成功后， AuthenticationManager 身份管理器返回一个被填充满了信息的（包括上面提到的权限信息，身份信息，细节信息，但密码通常会被移除） Authentication 实例。 SecurityContextHolder 安全上下文容器将第3步填充了信息的 Authentication ，通过SecurityContextHolder.getContext().setAuthentication(…)方法，设置到其中。可以看出AuthenticationManager接口（认证管理器）是认证相关的核心接口，也是发起认证的出发点，它 的实现类为ProviderManager。而Spring Security支持多种认证方式，因此ProviderManager维护着一个 List 列表，存放多种认证方式，最终实际的认证工作是由 AuthenticationProvider完成的。咱们知道web表单的对应的AuthenticationProvider实现类为 DaoAuthenticationProvider，它的内部又维护着一个UserDetailsService负责UserDetails的获取。最终AuthenticationProvider将UserDetails填充至Authentication。 AuthenticationProvider 通过前面的Spring Security认证流程我们得知，认证管理器（AuthenticationManager）委托AuthenticationProvider完成认证工作。 AuthenticationProvider是一个接口，定义如下： public interface AuthenticationProvider { Authentication authenticate(Authentication authentication) throws AuthenticationException; boolean supports(Class&lt;?&gt; var1); } authenticate()方法定义了认证的实现过程，它的参数是一个Authentication，里面包含了登录用户所提交的用户、密码等。而返回值也是一个Authentication，这个Authentication则是在认证成功后，将用户的权限及其他信息重新组装后生成。 Spring Security中维护着一个 List 列表，存放多种认证方式，不同的认证方式使用不同的AuthenticationProvider。如使用用户名密码登录时，使用AuthenticationProvider1，短信登录时使用AuthenticationProvider2等等这样的例子很多。 每个AuthenticationProvider需要实现supports()方法来表明自己支持的认证方式，如我们使用表单方式认证，在提交请求时Spring Security会生成UsernamePasswordAuthenticationToken，它是一个Authentication，里面封装着用户提交的用户名、密码信息。而对应的，哪个AuthenticationProvider来处理它？ 我们在DaoAuthenticationProvider的基类AbstractUserDetailsAuthenticationProvider发现以下代码： public boolean supports(Class&lt;?&gt; authentication) { return UsernamePasswordAuthenticationToken.class.isAssignableFrom(authentication); } 也就是说当web表单提交用户名密码时，Spring Security由DaoAuthenticationProvider处理。 最后，我们来看一下Authentication(认证信息)的结构，它是一个接口，我们之前提到的 UsernamePasswordAuthenticationToken就是它的实现之一： public interface Authentication extends Principal, Serializable { Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); Object getCredentials(); Object getDetails(); Object getPrincipal(); boolean isAuthenticated(); void setAuthenticated(boolean var1) throws IllegalArgumentException; } Authentication是spring security包中的接口，直接继承自Principal类，而Principal是位于 java.security包中的。它是表示着一个抽象主体身份，任何主体都有一个名称，因此包含一个getName()方法。 getAuthorities()，权限信息列表，默认是GrantedAuthority接口的一些实现类，通常是代表权限信息的一系列字符串。 getCredentials()，凭证信息，用户输入的密码字符串，在认证过后通常会被移除，用于保障安全。 getDetails()，细节信息，web应用中的实现接口通常为 WebAuthenticationDetails，它记录了访问者的ip地址和sessionId的值。 getPrincipal()，身份信息，大部分情况下返回的是UserDetails接口的实现类，UserDetails代表用户的详细信息，那从Authentication中取出来的UserDetails就是当前登录用户信息，它也是框架中的常用接口之一。 UserDetailsService 认识UserDetailsService 现在咱们现在知道DaoAuthenticationProvider处理了web表单的认证逻辑，认证成功后既得到一个 Authentication(UsernamePasswordAuthenticationToken实现)，里面包含了身份信息（Principal）。这个身份信息就是一个 Object ，大多数情况下它可以被强转为UserDetails对象。 DaoAuthenticationProvider中包含了一个UserDetailsService实例，它负责根据用户名提取用户信息UserDetails(包含密码)，而后DaoAuthenticationProvider会去对比UserDetailsService提取的用户密码与用户提交的密码是否匹配作为认证成功的关键依据，因此可以通过将自定义的 UserDetailsService 公开为spring bean来定义自定义身份验证。 public interface UserDetailsService { UserDetails loadUserByUsername(String username) throws UsernameNotFoundException; } 很多人把DaoAuthenticationProvider和UserDetailsService的职责搞混淆，其实UserDetailsService只负责从特定的地方（通常是数据库）加载用户信息，仅此而已。而DaoAuthenticationProvider的职责更大，它完成完整的认证流程，同时会把UserDetails填充至Authentication。上面一直提到UserDetails是用户信息，咱们看一下它的真面目： public interface UserDetails extends Serializable { Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); String getPassword(); String getUsername(); boolean isAccountNonExpired(); boolean isAccountNonLocked(); boolean isCredentialsNonExpired(); boolean isEnabled(); } 它和Authentication接口很类似，比如它们都拥有username，authorities。Authentication的getCredentials()与UserDetails中的getPassword()需要被区分对待，前者是用户提交的密码凭证，后者是用户实际存储的密码，认证其实就是对这两者的比对。Authentication中的getAuthorities()实际是由UserDetails的getAuthorities()传递而形成的。还记得Authentication接口中的getDetails()方法吗？其中的UserDetails用户详细信息便是经过了AuthenticationProvider认证之后被填充的。 通过实现UserDetailsService和UserDetails，我们可以完成对用户信息获取方式以及用户信息字段的扩展。 Spring Security提供的InMemoryUserDetailsManager(内存认证)，JdbcUserDetailsManager(jdbc认证)就是UserDetailsService的实现类，主要区别无非就是从内存还是从数据库加载用户。 2. 自定义UserDetailsService @Service public class SpringDataUserDetailsService implements UserDetailsService { @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { //登录账号 System.out.println(&quot;username=&quot;+username); //根据账号去数据库查询... //这里暂时使用静态数据 UserDetails userDetails = User.withUsername(username).password(&quot;123&quot;).authorities(&quot;p1&quot;).build(); return userDetails; } } PasswordEncoder 认识PasswordEncoder DaoAuthenticationProvider认证处理器通过UserDetailsService获取到UserDetails后，它是如何与请求Authentication中的密码做对比呢？ 在这里Spring Security为了适应多种多样的加密类型，又做了抽象，DaoAuthenticationProvider通过PasswordEncoder接口的matches方法进行密码的对比，而具体的密码对比细节取决于实现： public interface PasswordEncoder { String encode(CharSequence var1); boolean matches(CharSequence var1, String var2); default boolean upgradeEncoding(String encodedPassword) { return false; } } 而Spring Security提供很多内置的PasswordEncoder，能够开箱即用，使用某种PasswordEncoder只需要进行如下声明即可，如下： @Bean public PasswordEncoder passwordEncoder() { //NoOpPasswordEncoder采用字符串匹配方法，不对密码进行加密比较处理 return NoOpPasswordEncoder.getInstance(); } 密码比较流程如下 用户输入密码（明文 ） DaoAuthenticationProvider获取UserDetails（其中存储了用户的正确密码） DaoAuthenticationProvider使用PasswordEncoder对输入的密码和正确的密码进行校验，密码一致则校验通过，否则校验失败。 NoOpPasswordEncoder的校验规则拿 输入的密码和UserDetails中的正确密码进行字符串比较，字符串内容一致则校验通过，否则 校验失败。 实际项目中推荐使用BCryptPasswordEncoder, Pbkdf2PasswordEncoder, SCryptPasswordEncoder等，感兴趣的大家可以看看这些PasswordEncoder的具体实现。 使用BCryptPasswordEncoder 配置BCryptPasswordEncoder 在安全配置类中定义： @Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } 测试发现认证失败，提示：Encoded password does not look like BCrypt。 原因： 由于UserDetails中存储的是原始密码（比如：123），它不是BCrypt格式。跟踪 DaoAuthenticationProvider第33行代码查看 userDetails中的内容 ，跟踪第38行代码查看PasswordEncoder的类型。 ​ 2. 测试BCrypt 通过下边的代码测试BCrypt加密及校验的方法 编写测试方法： @RunWith(SpringRunner.class) public class TestBCrypt { @Test public void test1(){ //对原始密码加密 String hashpw = BCrypt.hashpw(&quot;123&quot;,BCrypt.gensalt()); System.out.println(hashpw); //校验原始密码和BCrypt密码是否一致 boolean checkpw = BCrypt.checkpw(&quot;123&quot;, &quot;$2a$10$NlBC84MVb7F95EXYTXwLneXgCca6/GipyWR5NHm8K0203bSQMLpvm&quot;); System.out.println(checkpw); } } 授权 流程 通过快速上手我们知道，Spring Security可以通过 http.authorizeRequests() 对web请求进行授权保护。Spring Security使用标准Filter建立了对web请求的拦截，最终实现对资源的授权访问。 Spring Security的授权流程如下： 拦截请求，已认证用户访问受保护的web资源将被SecurityFilterChain中的 FilterSecurityInterceptor 的子类拦截。 获取资源访问策略，FilterSecurityInterceptor会从 SecurityMetadataSource 的子类 DefaultFilterInvocationSecurityMetadataSource 获取要访问当前资源所需要的权限Collection 。 SecurityMetadataSource其实就是读取访问策略的抽象，而读取的内容，其实就是我们配置的访问规则， 读 取访问策略如： http.authorizeRequests() .antMatchers(&quot;/r/r1&quot;).hasAuthority(&quot;p1&quot;) .antMatchers(&quot;/r/r2&quot;).hasAuthority(&quot;p2&quot;) ... 最后，FilterSecurityInterceptor会调用 AccessDecisionManager 进行授权决策，若决策通过，则允许访问资源，否则将禁止访问。 AccessDecisionManager（访问决策管理器）的核心接口如下: public interface AccessDecisionManager { /** * 通过传递的参数来决定用户是否有访问对应受保护资源的权限 */ void decide(Authentication authentication , Object object, Collection&lt;ConfigAttribute&gt; configAttributes ) throws AccessDeniedException, InsufficientAuthenticationException; //略.. } 这里着重说明一下decide的参数： authentication：要访问资源的访问者的身份 object：要访问的受保护资源，web请求对应FilterInvocation confifigAttributes：是受保护资源的访问策略，通过SecurityMetadataSource获取。 decide接口就是用来鉴定当前用户是否有访问对应受保护资源的权限。 授权决策 AccessDecisionManager采用投票的方式来确定是否能够访问受保护资源。 AccessDecisionManager中包含的一系列AccessDecisionVoter将会被用来对Authentication是否有权访问受保护对象进行投票，AccessDecisionManager根据投票结果，做出最终决策。 AccessDecisionVoter是一个接口，其中定义有三个方法，具体结构如下所示。 public interface AccessDecisionVoter&lt;S&gt; { int ACCESS_GRANTED = 1; int ACCESS_ABSTAIN = 0; int ACCESS_DENIED = ‐1; boolean supports(ConfigAttribute var1); boolean supports(Class&lt;?&gt; var1); int vote(Authentication var1, S var2, Collection&lt;ConfigAttribute&gt; var3); } vote()方法的返回结果会是AccessDecisionVoter中定义的三个常量之一。ACCESS_GRANTED表示同意，ACCESS_DENIED表示拒绝，ACCESS_ABSTAIN表示弃权。如果一个AccessDecisionVoter不能判定当前Authentication是否拥有访问对应受保护对象的权限，则其vote()方法的返回值应当为弃权ACCESS_ABSTAIN。 Spring Security内置了三个基于投票的AccessDecisionManager实现类如下，它们分别是 AffirmativeBased、ConsensusBased和UnanimousBased，Spring security默认使用的是AffirmativeBased。 AffirmativeBased： 只要有AccessDecisionVoter的投票为ACCESS_GRANTED则同意用户进行访问； 如果全部弃权也表示通过； 如果没有一个人投赞成票，但是有人投反对票，则将抛出AccessDeniedException。 ConsensusBased： 如果赞成票多于反对票则表示通过。 反过来，如果反对票多于赞成票则将抛出AccessDeniedException。 如果赞成票与反对票相同且不等于0，并且属性allowIfEqualGrantedDeniedDecisions的值为true，则表示通过，否则将抛出异常AccessDeniedException。参数allowIfEqualGrantedDeniedDecisions的值默认为true。 如果所有的AccessDecisionVoter都弃权了，则将视参数allowIfAllAbstainDecisions的值而定，如果该值为true则表示通过，否则将抛出异常AccessDeniedException。参数allowIfAllAbstainDecisions的值默认为false。 UnanimousBased: UnanimousBased与另外两种实现有点不一样，另外两种会一次性把受保护对象的配置属性全部传递给AccessDecisionVoter进行投票，而UnanimousBased会一次只传递一个ConfifigAttribute给AccessDecisionVoter进行投票。这也就意味着如果我们的AccessDecisionVoter的逻辑是只要传递进来的 ConfifigAttribute中有一个能够匹配则投赞成票，但是放到UnanimousBased中其投票结果就不一定是赞成了。 如果受保护对象配置的某一个ConfifigAttribute被任意的AccessDecisionVoter反对了，则将抛出AccessDeniedException。 如果没有反对票，但是有赞成票，则表示通过。 如果全部弃权了，则将视参数allowIfAllAbstainDecisions的值而定，true则通过，false则抛出 AccessDeniedException。 Spring Security也内置一些投票者实现类如RoleVoter、AuthenticatedVoter和WebExpressionVoter等。 自定义认证 创建数据库表 CREATE DATABASE `test` CHARACTER SET 'utf8' COLLATE 'utf8_general_ci'; CREATE TABLE `t_user` ( `id` bigint(20) NOT NULL COMMENT '用户id', `username` varchar(64) NOT NULL, `password` varchar(64) NOT NULL, `fullname` varchar(255) NOT NULL COMMENT '用户姓名', `mobile` varchar(11) DEFAULT NULL COMMENT '手机号', PRIMARY KEY (`id`) USING BTREE ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC 添加所需依赖 &lt;!-- spring security 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- web支持 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- mysql依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- lombok 工具--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- 单元测试 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; 配置application.yml spring: datasource: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/test?useUnicode=true&amp;zeroDateTimeBehavior=convertToNull&amp;autoReconnect=true&amp;characterEncoding=utf-8 username: root password: root hikari: minimum-idle: 5 idle-timeout: 600000 maximum-pool-size: 10 auto-commit: true pool-name: MyHikariCP max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1 修改springboot 启动类 import org.mybatis.spring.annotation.MapperScan; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication @MapperScan(basePackages = &quot;com.ldx.springboot.dao&quot;) public class SpringbootSpringSecurityApplication { public static void main(String[] args) { SpringApplication.run(SpringbootSpringSecurityApplication.class, args); } } 创建securityConfig /** * springsecurity 配置类 * @author ludangxin * @Date 2020-06-01 **/ @Configuration @EnableGlobalMethodSecurity(securedEnabled = true,prePostEnabled = true) public class WebSecurityConfig extends WebSecurityConfigurerAdapter { /** * 密码编码器 */ @Bean public PasswordEncoder passwordEncoder() { return new BCryptPasswordEncoder(); } /** * 安全拦截机制（最重要） */ @Override protected void configure(HttpSecurity http) throws Exception { http. //屏蔽CSRF控制，即spring security不再限制CSRF csrf().disable(). authorizeRequests() .antMatchers(&quot;/r/r1&quot;).hasAuthority(&quot;p1&quot;) .antMatchers(&quot;/r/r2&quot;).hasAuthority(&quot;p2&quot;) //所有的请求必须通过认证 .anyRequest().authenticated() .and() //允许表单登录 .formLogin() //自定义登录成功的页面地址 .successForwardUrl(&quot;/login-success&quot;); } } 创建model import lombok.Data; @Data public class UserDto { private String id; private String username; private String password; private String fullname; private String mobile; } 创建controller import org.springframework.security.core.Authentication; import org.springframework.security.core.context.SecurityContextHolder; import org.springframework.web.bind.annotation.GetMapping; import org.springframework.web.bind.annotation.RequestMapping; import org.springframework.web.bind.annotation.RestController; @RestController public class LoginController { /** * 用户登录成功 */ @RequestMapping(value = &quot;/login-success&quot;) public String loginSuccess() { String username = getUsername(); return username + &quot; 登录成功&quot;; } /** * 获取当前登录用户名 */ private String getUsername() { Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (!authentication.isAuthenticated()) { return null; } Object principal = authentication.getPrincipal(); String username = null; if (principal instanceof org.springframework.security.core.userdetails.UserDetails) { username = ((org.springframework.security.core.userdetails.UserDetails) principal).getUsername(); } else { username = principal.toString(); } return username; } /** * 测试资源1 */ @GetMapping(value = &quot;/r/r1&quot;) public String r1() { String username = getUsername(); return username + &quot; 访问资源1&quot;; } /** * 测试资源2 */ @GetMapping(value = &quot;/r/r2&quot;) public String r2() { String username = getUsername(); return username + &quot; 访问资源2&quot;; } } 创建userdetailsService import com.ldx.springboot.dao.UserMapper; import com.ldx.springboot.model.UserDto; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.core.userdetails.UsernameNotFoundException; import org.springframework.stereotype.Service; @Service public class SpringDataUserDetailsService implements UserDetailsService { @Autowired UserMapper userMapper; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { //登录账号 System.out.println(&quot;username=&quot; + username); //根据账号去数据库查询... UserDto user = userMapper.getUserByUsername(username); if (user == null) { return null; } //这里暂时使用静态数据 UserDetails userDetails = User.withUsername(user.getFullname()).password(user.getPassword()).authorities(&quot;p1&quot;).build(); return userDetails; } } 创建mapper import com.ldx.springboot.model.UserDto; import org.apache.ibatis.annotations.Select; public interface UserMapper { @Select(&quot;select id,username,password,fullname from t_user where username = #{username}&quot;) UserDto getUserByUsername(String username); } 创建BCrypt密码测试类 import org.junit.Test; import org.junit.runner.RunWith; import org.springframework.security.crypto.bcrypt.BCrypt; import org.springframework.test.context.junit4.SpringRunner; @RunWith(SpringRunner.class) public class TestBCrypt { @Test public void test1(){ //对原始密码加密 String hashpw = BCrypt.hashpw(&quot;123&quot;,BCrypt.gensalt()); System.out.println(hashpw); //校验原始密码和BCrypt密码是否一致 boolean checkpw = BCrypt.checkpw(&quot;123&quot;, &quot;$2a$10$NlBC84MVb7F95EXYTXwLneXgCca6/GipyWR5NHm8K0203bSQMLpvm&quot;); System.out.println(checkpw); } } 测试结果 使用BCrypt密码测试类生成指定密码且将用户信息写入数据库用户表 启动项目访问localhost:8080 输入用户名密码进行测试 暂时使用静态权限数据,测试r/r1: 正常,r/r2:无权限 会话 用户认证通过后，为了避免用户的每次操作都进行认证可将用户的信息保存在会话中。spring security提供会话管理，认证通过后将身份信息放入SecurityContextHolder上下文，SecurityContext与当前线程进行绑定，方便获取用户身份。 获取当前用户名 /** * 获取当前登录用户名 */ private String getUsername() { Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (!authentication.isAuthenticated()) { return null; } Object principal = authentication.getPrincipal(); String username = null; if (principal instanceof org.springframework.security.core.userdetails.UserDetails) { username = ((org.springframework.security.core.userdetails.UserDetails) principal).getUsername(); } else { username = principal.toString(); } return username; } 会话控制 我们可以通过以下选项准确控制会话何时创建以及Spring Security如何与之交互： 机制 描述 always 如果没有session存在就创建一个 ifRequired 如果需要就创建一个Session（默认）登录时 never SpringSecurity 将不会创建Session，但是如果应用中其他地方创建了Session，那么SpringSecurity将会使用它。 stateles SpringSecurity将绝对不会创建Session，也不使用Session 通过以下配置方式对该选项进行配置： @Override protected void configure(HttpSecurity http) throws Exception { http.sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.IF_REQUIRED) } 默认情况下，Spring Security会为每个登录成功的用户会新建一个Session，就是ifRequired 。 若选用never，则指示Spring Security对登录成功的用户不创建Session了，但若你的应用程序在某地方新建了session，那么Spring Security会用它的。 若使用stateless，则说明Spring Security对登录成功的用户不会创建Session了，你的应用程序也不会允许新建session。并且它会暗示不使用cookie，所以每个请求都需要重新进行身份验证。这种无状态架构适用于REST API及其无状态认证机制。 会话超时 可以再sevlet容器中设置Session的超时时间，如下设置Session有效期为3600s； springboot配置: server.servlet.session.timeout=3600s session超时之后，可以通过Spring Security 设置跳转的路径。 http.sessionManagement() .expiredUrl(&quot;/login‐view?error=EXPIRED_SESSION&quot;) .invalidSessionUrl(&quot;/login‐view?error=INVALID_SESSION&quot;); expired指session过期，invalidSession指传入的sessionid无效。 安全会话cookie 我们可以使用httpOnly和secure标签来保护我们的会话cookie： httpOnly：如果为true，那么浏览器脚本将无法访问cookie secure：如果为true，则cookie将仅通过HTTPS连接发送 spring boot 配置文件： server.servlet.session.cookie.http‐only=true server.servlet.session.cookie.secure=true 退出 Spring security默认实现了logout退出，访问/logout实现退出操作。 这里也可以自定义退出成功的页面： 在WebSecurityConfifig的protected void confifigure(HttpSecurity http)中配置： .and() .logout() .logoutUrl(&quot;/logout&quot;) .logoutSuccessUrl(&quot;/login‐view?logout&quot;); 当退出操作出发时，将发生： 使HTTP Session 无效 清除 SecurityContextHolder 跳转到 /login-view?logout 但是，类似于配置登录功能，咱们可以进一步自定义退出功能： @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() //... .and() .logout() (1) .logoutUrl(&quot;/logout&quot;) (2) .logoutSuccessUrl(&quot;/login‐view?logout&quot;) (3) .logoutSuccessHandler(logoutSuccessHandler) (4) .addLogoutHandler(logoutHandler) (5) .invalidateHttpSession(true); (6) } （1）提供系统退出支持，使用 WebSecurityConfigurerAdapter 会自动被应用 （2）设置触发退出操作的URL (默认是 /logout ). （3）退出之后跳转的URL。默认是 /login?logout 。 （4）定制的 LogoutSuccessHandler ，用于实现用户退出成功时的处理。如果指定了这个选项那么logoutSuccessUrl() 的设置会被忽略。 （5）添加一个 LogoutHandler ，用于实现用户退出时的清理工作.默认 SecurityContextLogoutHandler 会被添加为最后一个 LogoutHandler 。 （6）指定是否在退出时让 HttpSession 无效。 默认设置为 true。 注意：如果让logout在GET请求下生效，必须关闭防止CSRF攻击csrf().disable()。如果开启了CSRF，必须使用post方式请求/logout logoutHandler： 一般来说， LogoutHandler 的实现类被用来执行必要的清理，因而他们不应该抛出异常。 下面是Spring Security提供的一些实现： PersistentTokenBasedRememberMeServices 基于持久化token的RememberMe功能的相关清理 TokenBasedRememberMeService 基于token的RememberMe功能的相关清理 CookieClearingLogoutHandler 退出时Cookie的相关清理 CsrfLogoutHandler 负责在退出时移除csrfToken SecurityContextLogoutHandler 退出时SecurityContext的相关清理 链式API提供了调用相应的 LogoutHandler 实现的快捷方式，比如deleteCookies()。 自定义授权 授权的方式包括 web授权和方法授权，web授权是通过 url拦截进行授权，方法授权是通过 方法拦截进行授权。他们都会调用accessDecisionManager进行授权决策，若为web授权则拦截器为FilterSecurityInterceptor；若为方法授权则拦截器为MethodSecurityInterceptor。如果同时通过web授权和方法授权则先执行web授权，再执行方法授权，最后决策通过，则允许访问资源，否则将禁止访问。 创建数据库表 # 角色表 CREATE TABLE `t_role` ( `id` varchar(32) NOT NULL, `role_name` varchar(255) DEFAULT NULL, `description` varchar(255) DEFAULT NULL, `create_time` datetime DEFAULT NULL, `update_time` datetime DEFAULT NULL, `status` char(1) NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `unique_role_name` (`role_name`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; insert into `t_role` (`id`,`role_name`,`description`,`create_time`,`update_time`,`status`) values ('1','管理员',NULL,NULL,NULL,''); # 用户角色关系表 CREATE TABLE `t_user_role` ( `user_id` varchar(32) NOT NULL, `role_id` varchar(32) NOT NULL, `create_time` datetime DEFAULT NULL, `creator` varchar(255) DEFAULT NULL, PRIMARY KEY (`user_id`,`role_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; insert into `t_user_role` (`user_id`,`role_id`,`create_time`,`creator`) values ('1','1',NULL,NULL); # 权限表 CREATE TABLE `t_permission`( `id` varchar(32) NOT NULL, `code` varchar(32) NOT NULL COMMENT '权限标识符', `description` varchar(64) DEFAULT NULL COMMENT '描述', `url` varchar(128) DEFAULT NULL COMMENT '请求地址', PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; insert into `t_permission` (`id`,`code`,`description`,`url`) values ('1','p1','测试资源 1','/r/r1'),('2','p3','测试资源2','/r/r2'); # 角色权限关系表 CREATE TABLE `t_role_permission` ( `role_id` varchar(32) NOT NULL, `permission_id` varchar(32) NOT NULL, PRIMARY KEY (`role_id`,`permission_id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; insert into `t_role_permission` (`role_id`,`permission_id`) values ('1','1'),('1','2'); 创建model import lombok.Data; @Data public class PermissionDto { private String id; private String code; private String description; private String url; } 修改userdatailsService import com.ldx.springboot.dao.PermissionMapper; import com.ldx.springboot.dao.UserMapper; import com.ldx.springboot.model.PermissionDto; import com.ldx.springboot.model.UserDto; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.security.core.userdetails.User; import org.springframework.security.core.userdetails.UserDetails; import org.springframework.security.core.userdetails.UserDetailsService; import org.springframework.security.core.userdetails.UsernameNotFoundException; import org.springframework.stereotype.Service; import java.util.List; import java.util.stream.Collectors; @Service public class SpringDataUserDetailsService implements UserDetailsService { @Autowired UserMapper userMapper; @Autowired PermissionMapper permissionMapper; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { //登录账号 System.out.println(&quot;username=&quot; + username); //根据账号去数据库查询... UserDto user = userMapper.getUserByUsername(username); if (user == null) { return null; } //查询用户权限 List&lt;PermissionDto&gt; permissions = permissionMapper.findPermissionsByUserId(user.getId()); List&lt;String&gt; permissionCodes = permissions.stream().map(PermissionDto::getCode).collect(Collectors.toList()); String[] permissionCodeArr = permissionCodes.toArray(new String[permissionCodes.size()]); //创建userDetails UserDetails userDetails = User.withUsername(user.getFullname()).password(user.getPassword()).authorities(permissionCodeArr).build(); return userDetails; } } 创建mapper import com.ldx.springboot.model.PermissionDto; import org.apache.ibatis.annotations.Select; import java.util.List; public interface PermissionMapper { @Select(&quot;SELECT * FROM t_permission WHERE id &quot; + &quot;IN(SELECT permission_id FROM t_role_permission WHERE role_id &quot; + &quot;IN(SELECT role_id FROM t_user_role WHERE user_id = #{id}))&quot;) List&lt;PermissionDto&gt; findPermissionsByUserId(String id); } 测试 启动项目访问localhost:8080 登陆用户 测试访问r/r1,r/r2 资源 web授权 在上面例子中我们完成了认证拦截，并对/r/**下的某些资源进行简单的授权保护，但是我们想进行灵活的授权控制该怎么做呢？通过给 http.authorizeRequests() 添加多个子节点来定制需求到我们的URL，如下代码： @Override protected void configure(HttpSecurity http) throws Exception { http .authorizeRequests() (1) .antMatchers(&quot;/r/r1&quot;) .hasAuthority(&quot;p1&quot;) (2) .antMatchers(&quot;/r/r2&quot;) .hasAuthority(&quot;p2&quot;) (3) .antMatchers(&quot;/r/r3&quot;) .access(&quot;hasAuthority('p1') and hasAuthority('p2')&quot;) (4) .antMatchers(&quot;/r/**&quot;) .authenticated() (5) .anyRequest().permitAll() (6) .and() .formLogin() // ... } （1） http.authorizeRequests() 方法有多个子节点，每个macher按照他们的声明顺序执行。 （2）指定&quot;/r/r1&quot;URL，拥有p1权限能够访问 （3）指定&quot;/r/r2&quot;URL，拥有p2权限能够访问 （4）指定了&quot;/r/r3&quot;URL，同时拥有p1和p2权限才能够访问 （5）指定了除了r1、r2、r3之外&quot;/r/**&quot;资源，同时通过身份认证就能够访问，这里使用SpEL（Spring Expression Language）表达式。。 （6）剩余的尚未匹配的资源，不做保护。 注意： 规则的顺序是重要的,更具体的规则应该先写.现在以/ admin开始的所有内容都需要具有ADMIN角色的身份验证用 户,即使是/ admin / login路径(因为/ admin / login已经被/ admin / **规则匹配,因此第二个规则被忽略). .antMatchers(&quot;/admin/**&quot;).hasRole(&quot;ADMIN&quot;) .antMatchers(&quot;/admin/login&quot;).permitAll() 因此,登录页面的规则应该在/ admin / **规则之前.例如. .antMatchers(&quot;/admin/login&quot;).permitAll() .antMatchers(&quot;/admin/**&quot;).hasRole(&quot;ADMIN&quot;) 保护URL常用的方法有： 方法 作用 authenticated() 保护URL，需要用户登录 permitAll() 指定URL无需保护，一般应用与静态资源文件 hasRole(String role) 限制单个角色访问，角色将被增加 “ROLE_” .所以”ADMIN” 将和 “ROLE_ADMIN”进行比较. hasAuthority(String authority) 限制单个权限访问 hasAnyRole(String… roles) 允许多个角色访问. hasAnyAuthority(String… authorities) 允许多个权限访问. access(String attribute) 该方法使用 SpEL表达式, 所以可以创建复杂的限制. hasIpAddress(String ipaddressExpression) 限制IP地址或子网 方法授权 现在我们已经掌握了使用如何使用 http.authorizeRequests() 对web资源进行授权保护，从Spring Security2.0版 本开始，它支持服务层方法的安全性的支持。本节学习@PreAuthorize,@PostAuthorize, @Secured三类注解。我们可以在任何 @Configuration 实例上使用 @EnableGlobalMethodSecurity 注释来启用基于注解的安全性。以下内容将启用Spring Security的 @Secured 注释。 @EnableGlobalMethodSecurity(securedEnabled = true) public class MethodSecurityConfig { // ... } 然后向方法（在类或接口上）添加注解就会限制对该方法的访问。 Spring Security的原生注释支持为该方法定义了一组属性。 这些将被传递给AccessDecisionManager以供它作出实际的决定： public interface BankService { @Secured(&quot;IS_AUTHENTICATED_ANONYMOUSLY&quot;) public Account readAccount(Long id); @Secured(&quot;IS_AUTHENTICATED_ANONYMOUSLY&quot;) public Account[] findAccounts(); @Secured(&quot;ROLE_TELLER&quot;) public Account post(Account account, double amount); } 以上配置标明readAccount、findAccounts方法可匿名访问，底层使用WebExpressionVoter投票器，可从 AffirmativeBased第23行代码跟踪。。 post方法需要有TELLER角色才能访问，底层使用RoleVoter投票器。 使用如下代码可启用prePost注解的支持 @EnableGlobalMethodSecurity(prePostEnabled = true) public class MethodSecurityConfig { // ... } 相应Java代码如下： public interface BankService { @PreAuthorize(&quot;isAnonymous()&quot;) public Account readAccount(Long id); @PreAuthorize(&quot;isAnonymous()&quot;) public Account[] findAccounts(); @PreAuthorize(&quot;hasAuthority('p_transfer') and hasAuthority('p_read_account')&quot;) public Account post(Account account, double amount); } 以上配置标明readAccount、findAccounts方法可匿名访问，post方法需要同时拥有p_transfer和p_read_account 权限才能访问，底层使用WebExpressionVoter投票器，可从AffirmativeBased第23行代码跟踪。 ","link":"http://blog.ludangxin.club/post/spring-security-xiang-jie-ji-kuai-su-shang-shou/"},{"title":"初识 Dubbo","content":"dubbo是什么 简介 Apache Dubbo是一款高性能的java RPC框架. 其前身是阿里巴巴公司开源的一个高性能,轻量级的开源java RPC 框架,可以和Spring框架无缝集成. Dubbo提供了三大核心能力: 面向接口的远程方法调用, 智能容错和负载均衡,以及服务注册和发现. 官方:http://dubbo.apache.org/zh-cn/ 架构 节点角色说明 节点 角色说明 Provider 暴露服务的服务提供方 Consumer 调用远程服务的服务消费方 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次数和调用时间的监控中心 Container 服务运行容器 调用关系说明 服务容器负责启动，加载，运行服务提供者。 服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者在启动时，向注册中心订阅自己所需的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 RPC RPC全称为remote procedure call. 即远程调用过程 ,过程其实就是方法, 所以可以把RPC理解为“远程方法调用”。 比如两台服务器A和B, A服务器上部署一个应用, B服务器上部署一个应用, A服务器上的应用想调用B服务器上的应用提供的方法,由于两个应用不在一个内存空间, 不能直接调用, 所以需要通过网络来表达调用的语义和传达调用的数据. 需要注意的是RPC并不是一个具体的技术, 而是指整个网络远程调用过程. 而不需要了解底层网络技术的协议,在面向对象的编程语言中, 远程过程调用即是 远程方法调用 智能容错 为了避免单点故障，现在的应用通常至少会部署在两台服务器上。对于一些负载比较高的服务，会部署更多的服务器。这样，在同一环境下的服务提供者数量会大于1。对于服务消费者来说，同一环境下出现了多个服务提供者。这时会出现一个问题，服务消费者需要决定选择哪个服务提供者进行调用。另外服务调用失败时的处理措施也是需要考虑的，是重试呢，还是抛出异常，亦或是只打印异常等。为了处理这些问题，Dubbo 定义了集群接口 Cluster 以及 Cluster Invoker。集群 Cluster 用途是将多个服务提供者合并为一个 Cluster Invoker，并将这个 Invoker 暴露给服务消费者。这样一来，服务消费者只需通过这个 Invoker 进行远程调用即可，至于具体调用哪个服务提供者，以及调用失败后如何处理等问题，现在都交给集群模块去处理。集群模块是服务提供者和服务消费者的中间层，为服务消费者屏蔽了服务提供者的情况，这样服务消费者就可以专心处理远程调用相关事宜。比如发请求，接受服务提供者返回的数据等。这就是集群的作用。 Dubbo 提供了多种集群实现，包含但不限于 Failover Cluster、Failfast Cluster 和 Failsafe Cluster 等。每种集群实现类的用途不同，接下来会一一进行分析。 在对集群相关代码进行分析之前，这里有必要先来介绍一下集群容错的所有组件。包含 Cluster、Cluster Invoker、Directory、Router 和 LoadBalance 等。 集群工作过程可分为两个阶段，第一个阶段是在服务消费者初始化期间，集群 Cluster 实现类为服务消费者创建 Cluster Invoker 实例，即上图中的 merge 操作。第二个阶段是在服务消费者进行远程调用时。以 FailoverClusterInvoker 为例，该类型 Cluster Invoker 首先会调用 Directory 的 list 方法列举 Invoker 列表（可将 Invoker 简单理解为服务提供者）。Directory 的用途是保存 Invoker，可简单类比为 List。其实现类 RegistryDirectory 是一个动态服务目录，可感知注册中心配置的变化，它所持有的 Invoker 列表会随着注册中心内容的变化而变化。每次变化后，RegistryDirectory 会动态增删 Invoker，并调用 Router 的 route 方法进行路由，过滤掉不符合路由规则的 Invoker。当 FailoverClusterInvoker 拿到 Directory 返回的 Invoker 列表后，它会通过 LoadBalance 从 Invoker 列表中选择一个 Invoker。最后 FailoverClusterInvoker 会将参数传给 LoadBalance 选择出的 Invoker 实例的 invoke 方法，进行真正的远程调用。 以上就是集群工作的整个流程，这里并没介绍集群是如何容错的。Dubbo 主要提供了这样几种容错方式： Failover Cluster - 失败自动切换 Failfast Cluster - 快速失败 Failsafe Cluster - 失败安全 Failback Cluster - 失败自动恢复 Forking Cluster - 并行调用多个服务提供者 Failover Cluster FailoverClusterInvoker 在调用失败时，会自动切换 Invoker 进行重试。默认配置下，Dubbo 会使用这个类作为缺省 Cluster Invoker 可通过 retries=&quot;2&quot; 来设置重试次数(不含第一次)。 重试次数配置如下： &lt;dubbo:service retries=&quot;2&quot; /&gt; 或 &lt;dubbo:reference retries=&quot;2&quot; /&gt; 或 &lt;dubbo:reference&gt; &lt;dubbo:method name=&quot;findFoo&quot; retries=&quot;2&quot; /&gt; &lt;/dubbo:reference&gt; Failfast Cluster FailfastClusterInvoker 只会进行一次调用，失败后立即抛出异常。适用于非幂等操作，比如新增记录。 Failsafe Cluster FailsafeClusterInvoker 是一种失败安全的 Cluster Invoker。所谓的失败安全是指，当调用过程中出现异常时，FailsafeClusterInvoker 仅会打印异常，而不会抛出异常。适用于写入审计日志等操作。 Failback Cluster FailbackClusterInvoker 会在调用失败后，返回一个空结果给服务消费者。并通过定时任务对失败的调用进行重传，适合执行消息通知等操作。 Forking Cluster ForkingClusterInvoker 会在运行时通过线程池创建多个线程，并发调用多个服务提供者。只要有一个服务提供者成功返回了结果，doInvoke 方法就会立即结束运行。ForkingClusterInvoker 的应用场景是在一些对实时性要求比较高读操作（注意是读操作，并行写操作可能不安全）下使用，但这将会耗费更多的资源。 服务治理和配置管理 服务治理 服务治理主要作用是改变运行时服务的行为和选址逻辑，达到限流，权重配置等目的，主要有以下几个功能： 应用级别的服务治理 在Dubbo2.6及更早版本中，所有的服务治理规则都只针对服务粒度，如果要把某条规则作用到应用粒度上，需要为应用下的所有服务配合相同的规则，变更，删除的时候也需要对应的操作，这样的操作很不友好，因此Dubbo2.7版本中增加了应用粒度的服务治理操作，对于条件路由(包括黑白名单)，动态配置(包括权重，负载均衡)都可以做应用级别的配置： 上图是条件路由的配置，可以按照应用名，服务名两个维度来填写，也可以按照这两个维度来查询。 标签路由 标签路由是Dubbo2.7引入的新功能，配置以应用作为维度，给不同的服务器打上不同名字的标签，配置如下图所示： 调用的时候，客户端可以通过setAttachment的方式，来设置不同的标签名称，比如本例中，setAttachment(tag1)，客户端的选址范围就在如图所示的三台机器中，可以通过这种方式来实现流量隔离，灰度发布等功能。 条件路由 条件路由是Dubbo一直以来就有的功能，目前可以配置服务和应用两个维度，条件路由为yaml格式，具体的规则体以及各种适用场景，请参考这里 黑白名单 黑白名单是条件路由的一部分，规则存储和条件路由放在一起，为了方便配置所以单独拿出来，同样可以通过服务和应用两个维度，指定黑名单和白名单: 动态配置 动态配置是和路由规则平行的另一类服务治理治理功能，主要作用是在不重启服务的情况下，动态改变调用行为，从Dubbo2.7版本开始，支持服务和应用两个维度的配置，采用yaml格式，界面如下： 具体的规则体说明请参考这里 权重调节 权重调节是动态配置的子功能，主要作用是改变服务端的权重，更大的权重会有更大的几率被客户端选中作为服务提供者，从而达到流量分配的目的： 负载均衡 负载均衡也是动态配置的子功能，主要作用是调整客户端的选址逻辑，目前可选的负载均衡策略有随机，轮训和最小活跃，关于各个策略的解释请参考这里 配置管理 配置管理也是配合Dubbo2.7新增的功能，在Dubbo2.7中，增加了全局和应用维度的配置，分别在全局和应用范围内生效，其中应用配置也可以指定该应用中的服务级别的配置，可以在控制台中查看，修改配置规则，默认展示全局维度的配置。 全局配置： 全局配置里可以指定注册中心，元数据中心的地址，服务端和客户端的超时时间等，这些配置在全局内生效。除了配置写入，也可以用来查看。如果使用zookeeper作为注册中心和元数据中心，还可以看到配置文件所在位置的目录结构。 应用， 服务配置 应用级别的配置可以为应用或者应用内的服务指定配置，在服务维度上，需要区分提供者和消费者。dubbo.reference.{serviceName}表示作为该服务消费者的配置，dubbo.provider.{servcieName}表示作为该服务提供者的配置。其中注册中心和元数据中心的地址，只能在全局配置中指定，这也是Dubbo2.7中推荐的使用方式。 优先级： 服务配置 &gt; 应用配置 &gt; 全局配置 既然有 HTTP 请求，为什么还要用 RPC 调用？ HTTP协议，以其中的Restful规范为代表，其优势很大。它可读性好，且可以得到防火墙的支持、跨语言的支持。而且，在去年的报告中，Restful大有超过RPC的趋势。 但是HTTP也有其缺点，这是与其优点相对应的。首先是有用信息占比少，毕竟HTTP工作在第七层，包含了大量的HTTP头等信息。其次是效率低，还是因为第七层的缘故。还有，其可读性似乎没有必要，因为我们可以引入网关增加可读性。此外，使用HTTP协议调用远程方法比较复杂，要封装各种参数名和参数值。 但需要再说一句，不是说RPC好，也不是说HTTP好，两者各有千秋，还在比拼中。 HTTP和RPC同一级别，还是被RPC包含？ Restful也属于RPC么？ 上图是一个比较完整的关系图，这时我们发现HTTP（图中蓝色框）出现了两次。其中一个是和RPC并列的，都是跨应用调用方法的解决方案；另一个则是被RPC包含的，是RPC通信过程的可选协议之一。 因此，**第一个问题的答案是都对。看指的是哪一个蓝色框。**从题主的提问看，既然题主在纠结这两者，应该是指与RPC并列的蓝色框。 第二个问题是在问远程过程调用（红色框）是不是包含了Restful（黄色框），这种理解的关键在于对RPC的理解。 RPC字面理解是远程过程调用，即在一个应用中调用另一个应用的方法。那Restful是满足的，通过它可以实现在一个应用中调用另一个应用的方法。 但是，上述理解使得RPC的定义过于宽泛。RPC通常特指在一个应用中调用另一个应用的接口而实现的远程调用，即红色框所指的范围。这样，RPC是不包含Restful的。 因此，第二个问题的答案是Restful不属于RPC，除非对RPC有着非常规的宽泛理解。 RPC的英文全称是Remote Procedure Call，翻译为中文叫“远程过程调用”。其中稍显晦涩的其实就是“过程”，过程其实就是方法。所以，可以把RPC理解为“远程方法调用”。 要了解远程过程调用，那先理解过程调用。非常简单，如下图，就是调用一个方法。这太常见了，不多解释。 而在分布式系统中，因为每个服务的边界都很小，很有可能调用别的服务提供的方法。这就出现了服务A调用服务B中方法的需求，即远程过程调用。 要想让服务A调用服务B中的方法，最先想到的就是通过HTTP请求实现。是的，这是很常见的，例如服务B暴露Restful接口，然后让服务A调用它的接口。基于Restful的调用方式因为可读性好（服务B暴露出的是Restful接口，可读性当然好）而且HTTP请求可以通过各种防火墙，因此非常不错。 然而，如前面所述，基于Restful的远程过程调用有着明显的缺点，主要是效率低、封装调用复杂。当存在大量的服务间调用时，这些缺点变得更为突出。 服务A调用服务B的过程是应用间的内部过程，牺牲可读性提升效率、易用性是可取的。基于这种思路，RPC产生了。 通常，RPC要求在调用方中放置被调用的方法的接口。调用方只要调用了这些接口，就相当于调用了被调用方的实际方法，十分易用。于是，调用方可以像调用内部接口一样调用远程的方法，而不用封装参数名和参数值等操作。 那要想实现这个过程该怎么办呢？别急，咱们一步一步来。 首先，调用方调用的是接口，必须得为接口构造一个假的实现。显然，要使用动态代理。这样，调用方的调用就被动态代理接收到了。 第二，动态代理接收到调用后，应该想办法调用远程的实际实现。这包括下面几步： 识别具体要调用的远程方法的IP、端口 将调用方法的入参进行序列化 通过通信将请求发送到远程的方法中 这样，远程的服务就接收到了调用方的请求。它应该： 反序列化各个调用参数 定位到实际要调用的方法，然后输入参数，执行方法 按照调用的路径返回调用的结果 整个过程如下所示: 调用方调用内部的一个方法，但是被RPC框架偷梁换柱为远程的一个方法。之间的通信数据可读性不需要好，只需要RPC框架能读懂即可，因此效率可以更高。通常使用UDP或者TCP作为通讯协议，当然也可以使用HTTP。 所以，不要被RPC吓到，它就是让一个应用调用另一个应用中方法的一种实现方式。与调用远程接口区别不大，条条大路通罗马。 再说一次，不是说RPC好，也不是说HTTP好，两者各有千秋。本质上，两者是可读性和效率之间的抉择，通用性和易用性之间的抉择。最终谁能发展更好，很难说。 要问我站谁？我根据业务场景，灵活站位…… 来源：知乎 链接：https://www.zhihu.com/question/41609070/answer/1030913797 ","link":"http://blog.ludangxin.club/post/chu-shi-dubbo/"},{"title":"初识 Zookeeper","content":"zookeeper是什么 zookeeper是一个开源的分布式协调服务, 提供分布式数据一致性解决方案,分布式应用程序可以实现数据统一配置管理、统一命名服务、分布式锁、集群管理等功能. ZooKeeper主要服务于分布式系统，使用分布式系统就无法避免对节点管理的问题(需要实时感知节点的状态、对节点进行统一管理等等)，而由于这些问题处理起来可能相对麻烦和提高了系统的复杂性，ZooKeeper作为一个能够通用解决这些问题的中间件就应运而生了。 zookeeper为什么能干这么多 从上面我们可以知道，可以用ZooKeeper来做：统一配置管理、统一命名服务、分布式锁、集群管理。 这里我们先不管统一配置管理、统一命名服务、分布式锁、集群管理每个具体的含义(后面会讲) 那为什么ZooKeeper可以干那么多事？来看看ZooKeeper究竟是何方神物，在Wiki中其实也有提到： ZooKeeper nodes store their data in a hierarchical name space, much like a file system or a tree data structure 译文: ZooKeeper节点将其数据存储在分层名称空间中，这与文件系统或树数据结构非常相似 Zookeeper 一个最常用的使用场景就是用于担任服务生产者和服务消费者的注册中心 。服务生产者将自己提供的服务注册到Zookeeper中心，服务的消费者在进行服务调用的时候先到Zookeeper中查找服务，获取到服务生产者的详细信息之后，再去调用服务生产者的内容与数据。如下图所示，在 Dubbo架构中 Zookeeper 就担任了注册中心这一角色。 数据结构 ZooKeeper的数据结构，跟Unix文件系统非常类似，可以看做是一颗树，每个节点叫做ZNode。每一个节点可以通过路径来标识，结构图如下： 那ZooKeeper这颗&quot;树&quot;有什么特点呢？？ZooKeeper的节点我们称之为Znode，Znode分为两种类型： 短暂/临时(Ephemeral)：当客户端和服务端断开连接后，所创建的Znode(节点)会自动删除 持久(Persistent)：当客户端和服务端断开连接后，所创建的Znode(节点)不会删除 ZooKeeper和Redis一样，也是C/S结构(分成客户端和服务端) 监听器 在上面我们已经简单知道了ZooKeeper的数据结构了，ZooKeeper还配合了监听器才能够做那么多事的。 常见的监听场景有以下两项： 监听Znode节点的数据变化 监听子节点的增减变化 没错，通过监听+Znode节点(持久/短暂[临时])，ZooKeeper就可以玩出这么多花样了。 zookeeper具体能干什么 统一配置管理 比如我们现在有三个系统A、B、C，他们有三份配置，分别是ASystem.yml、BSystem.yml、CSystem.yml，然后，这三份配置又非常类似，很多的配置项几乎都一样。 此时，如果我们要改变其中一份配置项的信息，很可能其他两份都要改。并且，改变了配置项的信息很可能就要重启系统 于是，我们希望把ASystem.yml、BSystem.yml、CSystem.yml相同的配置项抽取出来成一份公用的配置common.yml，并且即便common.yml改了，也不需要系统A、B、C重启。 做法：我们可以将common.yml这份配置放在ZooKeeper的Znode节点中，系统A、B、C监听着这个Znode节点有无变更，如果变更了，及时响应。 统一命名服务 统一命名服务的理解其实跟域名一样，是我们为这某一部分的资源给它取一个名字，别人通过这个名字就可以拿到对应的资源。 比如说，现在我有一个域名www.java3y.com，但我这个域名下有多台机器： 192.168.1.1 192.168.1.2 192.168.1.3 192.168.1.4 别人访问www.java3y.com即可访问到我的机器，而不是通过IP去访问。 分布式锁 我们可以使用ZooKeeper来实现分布式锁，那是怎么做的呢？？下面来看看： 系统A、B、C都去访问/locks节点 访问的时候会创建带顺序号的临时/短暂(EPHEMERAL_SEQUENTIAL)节点，比如，系统A创建了id_000000节点，系统B创建了id_000002节点，系统C创建了id_000001节点。 接着，拿到/locks节点下的所有子节点(id_000000,id_000001,id_000002)，判断自己创建的是不是最小的那个节点 如果是，则拿到锁。 释放锁：执行完操作后，把创建的节点给删掉 如果不是，则监听比自己要小1的节点变化 举个例子： 系统A拿到/locks节点下的所有子节点，经过比较，发现自己(id_000000)，是所有子节点最小的。所以得到锁 系统B拿到/locks节点下的所有子节点，经过比较，发现自己(id_000002)，不是所有子节点最小的。所以监听比自己小1的节点id_000001的状态 系统C拿到/locks节点下的所有子节点，经过比较，发现自己(id_000001)，不是所有子节点最小的。所以监听比自己小1的节点id_000000的状态 …... 等到系统A执行完操作以后，将自己创建的节点删除(id_000000)。通过监听，系统C发现id_000000节点已经删除了，发现自己已经是最小的节点了，于是顺利拿到锁 ….系统B如上 集群状态 经过上面几个例子，我相信大家也很容易想到ZooKeeper是怎么&quot;感知&quot;节点的动态新增或者删除的了。 还是以我们三个系统A、B、C为例，在ZooKeeper中创建临时节点即可： 只要系统A挂了，那/groupMember/A这个节点就会删除，通过监听groupMember下的子节点，系统B和C就能够感知到系统A已经挂了。(新增也是同理) 除了能够感知节点的上下线变化，ZooKeeper还可以实现动态选举Master的功能。(如果集群是主从架构模式下) 原理也很简单，如果想要实现动态选举Master的功能，Znode节点的类型是带顺序号的临时节点(EPHEMERAL_SEQUENTIAL)就好了。 Zookeeper会每次选举最小编号的作为Master，如果Master挂了，自然对应的Znode节点就会删除。然后让新的最小编号作为Master，这样就可以实现动态选举的功能了。 转自: Java3y-zookeeper ZAB 协议&amp;Paxos算法 paxos 算法 Paxos 算法应该可以说是 ZooKeeper 的灵魂了。但是，ZooKeeper 并没有完全采用 Paxos算法 ，而是使用 ZAB 协议作为其保证数据一致性的核心算法。另外，在ZooKeeper的官方文档中也指出，ZAB协议并不像 Paxos 算法那样，是一种通用的分布式一致性算法，它是一种特别为Zookeeper设计的崩溃可恢复的原子消息广播算法。 ZAB 协议介绍 ZAB（ZooKeeper Atomic Broadcast 原子广播） 协议是为分布式协调服务 ZooKeeper 专门设计的一种支持崩溃恢复的原子广播协议。 在 ZooKeeper 中，主要依赖 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各个副本之间的数据一致性。 ZAB 协议两种基本的模式：崩溃恢复和消息广播 ZAB协议包括两种基本的模式，分别是 崩溃恢复和消息广播。当整个服务框架在启动过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进人恢复模式并选举产生新的Leader服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该Leader服务器完成了状态同步之后，ZAB协议就会退出恢复模式。其中，所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和Leader服务器的数据状态保持一致。 当集群中已经有过半的Follower服务器完成了和Leader服务器的状态同步，那么整个服务框架就可以进人消息广播模式了。 当一台同样遵守ZAB协议的服务器启动后加人到集群中时，如果此时集群中已经存在一个Leader服务器在负责进行消息广播，那么新加人的服务器就会自觉地进人数据恢复模式：找到Leader所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。正如上文介绍中所说的，ZooKeeper设计成只允许唯一的一个Leader服务器来进行事务请求的处理。Leader服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播协议；而如果集群中的其他机器接收到客户端的事务请求，那么这些非Leader服务器会首先将这个事务请求转发给Leader服务器。 zookeeper环境搭建 单机环境 上传zookeeper到linux服务器 解压缩压缩包 tar -zxvf zookeeper-3.5.8.tar 进入zookeeper-3.5.8目录,创建data文件夹且创建cfg文件 mkdir data cd conf # zookeeper默认读取zoo.cfg的配置文件信息 cp zoo_sample.cfg zoo.cfg 修改zoo.cfg data目录 dataDir=/usr/local/zookeeper-3.5.8/data # zk服务器默认8080端口,为防止端口占用,增加serverPort配置 admin.serverPort=6666 到bin目录启动zookeeper ./zkServer.sh start 查看zookeeper状态 ./zkServer.sh status 集群环境 将zookeeper分别安装到三台服务器上并配置好基本信息(重复单机环境搭建过程) 在每个zookeeper的data目录下创建一个myid文件,内容分别是1,2,3 这个文件就是记录每个服务器的id # 192.168.1.110 服务器 echo 1 &gt; myid # 192.168.1.111 服务器 echo 2 &gt; myid # 192.168.1.112 服务器 echo 3 &gt; myid 在每一个zookeeper的zoo.cfg配置客户端访问端口和集群服务器ip列表 # server.服务器id=服务器ip地址:服务器之间通信端口:服务器之间投票选举端口 server.1=192.168.1.110:2181:3881 server.2=192.168.1.111:2181:3881 server.3=192.168.1.112:2181:3881 启动集群 依次启动三个zk实例,其中有一个leader和两个follower 通过./zkServer.sh status命令可以查看当前zk是 leader 还是 follower 可以通过./zkServer.sh stop命令停止zk服务来测试zk的选举模式 zookeeper基本使用 数据结构 zookeeper数据模型的结构与Unix文件系统很类似,整体上可以看作是一棵树,每个节点称作一个ZNode,每个ZNode都可以通过其路径唯一标识. 如图示 ZNode节点类型 持久化目录节点(PERSISTENT) 客户端与zookeeper断开连接后,该节点依旧存在 持久化顺序编号目录节点(PERSISTENT_SEQUENTIAL) 客户端与zookeeper断开连接后,该节点依旧存在,zookeeper会给该节点按照顺序编号 临时目录节点(EPHEMERAL) 客户端与zookeeper断开连接后,该节点被删除 临时顺序编号目录节点(EPHEMERAL_SEQUENTIAL) 客户端与zookeeper断开连接后,该节点被删除,zookeeper会给该节点按照顺序编号 命令行使用 在zookeeper bin目录中输入 ./zkCli.sh 进入客户端 输入help查看相关命令操作,结果如下 常用命令讲解: 节点目录操作 使用ls命令来查看当前znode中锁包含的内容 # ls [-s] [-w] [-R] path [zk: localhost:2181(CONNECTED) 3] ls / [ludangxin, zookeeper] 使用ls2查看当前节点数据并能看到更新次数等数据 # ls2 path [watch] 官方不推荐直接使用ls2查看, 使用 ls -s path 效果一样 [zk: localhost:2181(CONNECTED) 4] ls2 / 'ls2' has been deprecated. Please use 'ls [-s] path' instead. [ludangxin, zookeeper] cZxid = 0x0 ctime = Thu Jan 01 00:00:00 UTC 1970 mZxid = 0x0 mtime = Thu Jan 01 00:00:00 UTC 1970 pZxid = 0x2 cversion = 0 dataVersion = 0 aclVersion = 0 ephemeralOwner = 0x0 dataLength = 0 numChildren = 2 使用create创建节点 -s 含有序列 -e 临时 # create [-s] [-e] [-c] [-t ttl] path [data] [acl] # zk客户端不能递归创建目录,只能一级一级创建 [zk: localhost:2181(CONNECTED) 6] create /ludangxin/app1 Created /ludangxin/app1 使用set设置节点值 # set [-s] [-v version] path data [zk: localhost:2181(CONNECTED) 8] set /ludangxin/app1 helloworld 使用get获得节点的值 # get [-s] [-w] path [zk: localhost:2181(CONNECTED) 9] get /ludangxin/app1 helloworld 使用stat查看节点状态 # stat [-w] path [zk: localhost:2181(CONNECTED) 1] stat /ludangxin/app1 cZxid = 0x3 ctime = Sat May 23 13:03:07 UTC 2020 mZxid = 0x4 mtime = Sat May 23 13:05:56 UTC 2020 pZxid = 0x3 cversion = 0 dataVersion = 1 aclVersion = 0 ephemeralOwner = 0x0 dataLength = 10 numChildren = 0 使用delete删除节点 # delete [-v version] path # delete不能递归删除目录,只能一级一级删除 [zk: localhost:2181(CONNECTED) 3] delete /ludangxin/app1 使用rmr或deleteall递归删除节点 # rmr path 官方不推荐使用rmr 推荐使用deleteall [zk: localhost:2181(CONNECTED) 4] create /ludangxin/app1 Created /ludangxin/app1 [zk: localhost:2181(CONNECTED) 5] create /ludangxin/app1/test1 Created /ludangxin/app1/test1 [zk: localhost:2181(CONNECTED) 7] rmr /ludangxin The command 'rmr' has been deprecated. Please use 'deleteall' instead. [zk: localhost:2181(CONNECTED) 8] ls /ludangxin Node does not exist: /ludangxin [zk: localhost:2181(CONNECTED) 9] ls / [zookeeper] 监听操作 监听只能监听一次,触发后就销毁了 使用ls创建监听 # ls -w path 当监听的节点包括他的子节点发目录发生变化的时候才触发监听 # 例:当前监听 /a/b 如果删除b节点,或者创建 /a/b/c 的时候会触发监听且只能触发一次 [zk: localhost:2181(CONNECTED) 15] ls -w /ludangxin/app1 [] [zk: localhost:2181(CONNECTED) 16] set /ludangxin/app1 helloworld [zk: localhost:2181(CONNECTED) 17] create /ludangxin/app1/testwatch Created /ludangxin/app1/testwatch WATCHER:: WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/ludangxin/app1 使用get创建监听(只能当前节点监听节点值的变化) # get -w path get -w /ludangxin/app1 使用stat创建监听(当 当前节点的状态发生改变的时候触发) # stat -w path stat -w /ludangxin/app1 zookeeper api使用 引入依赖 注: 引入依赖的版本最好和安装的zk服务的版本一致 &lt;!-- zookeeper --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.5.8&lt;/version&gt; &lt;/dependency&gt; &lt;!-- lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 创建测试类 import lombok.extern.slf4j.Slf4j; import org.apache.zookeeper.*; import org.apache.zookeeper.data.Stat; import org.junit.jupiter.api.Test; import java.io.IOException; import java.util.List; @Slf4j public class ZkApiTest { public static final String URL = &quot;192.168.128.130:2181&quot;; public static final int SESSION_TIME_OUT = 20000; @Test public void test() throws IOException, KeeperException, InterruptedException { //1. 创建zookeeper连接 ZooKeeper zooKeeper = new ZooKeeper(URL,SESSION_TIME_OUT, watch -&gt; log.info(&quot;触发了&quot;+ watch.getType() +&quot;事件&quot;) ); //2. 创建父节点 //Ids.OPEN_ACL_UNSAFE 无权限 CreateMode.PERSISTENT 持久化节点 String testParentPath = zooKeeper.create(&quot;/testPath1&quot;, &quot;testParentValue&quot;.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); log.info(&quot;testParentPath===&quot;+testParentPath); //3. 创建子节点 String testChildPath = zooKeeper.create(testParentPath+&quot;/child1&quot;, &quot;testChildValue&quot;.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT); log.info(&quot;testChildPath===&quot;+testChildPath); //4. 获取节点中的值(父节点和子节点) byte[] parentData = zooKeeper.getData(testParentPath, false, null); byte[] childData = zooKeeper.getData(testChildPath, false, null); List&lt;String&gt; childrenNodes = zooKeeper.getChildren(testParentPath, false); log.info(&quot;parentData===&quot;+new String(parentData)); log.info(&quot;childData===&quot;+new String(childData)); for (String childrenNode : childrenNodes) { log.info(&quot;childrenNode===&quot;+childrenNode); } //5. 修改节点的值 //version 节点版本 -1 匹配任何版本 zooKeeper.setData(testParentPath, &quot;testValueUpdate&quot;.getBytes(), -1); byte[] parentNewData = zooKeeper.getData(testParentPath, false, null); log.info(&quot;parentNewData===&quot;+new String(parentNewData)); //6. 判断某个节点是否存在 Stat exists = zooKeeper.exists(testChildPath, false); log.info(exists.toString()); //7. 删除节点 zooKeeper.delete(testChildPath,-1); } } 输出结果 23:37:36.574 [main-EventThread] INFO com.ldx.springboot.ZkApiTest - 触发了None事件 23:37:36.581 [main] INFO com.ldx.springboot.ZkApiTest - testParentPath===/testPath1 23:37:36.585 [main] INFO com.ldx.springboot.ZkApiTest - testChildPath===/testPath1/child1 23:37:36.595 [main] INFO com.ldx.springboot.ZkApiTest - parentData===testParentValue 23:37:36.595 [main] INFO com.ldx.springboot.ZkApiTest - childData===testChildValue 23:37:36.595 [main] INFO com.ldx.springboot.ZkApiTest - childrenNode===child1 23:37:36.603 [main] INFO com.ldx.springboot.ZkApiTest - parentNewData===testValueUpdate 23:37:36.606 [main] INFO com.ldx.springboot.ZkApiTest - 111,111,1590248257090,1590248257090,0,0,0,0,14,0,111 ","link":"http://blog.ludangxin.club/post/chu-shi-zookeeper/"},{"title":"浅谈 分布式 集群 微服务","content":"概念 集群是个物理形态，分布式是系统部署方式，微服务是架构设计方式。 集群是啥? 单机处理到达瓶颈的时候，你就把单机复制几份，这样就构成了一个“集群”。集群中每台服务器就叫做这个集群的一个“节点”，所有节点构成了一个集群。每个节点都提供相同的服务，那么这样系统的处理能力就相当于提升了好几倍（有几个节点就相当于提升了这么多倍）。从单机结构到集群结构，你的代码基本无需要作任何修改。你要做的仅仅是多部署几台服务器，每台服务器上运行相同的代码就行了。 分布式是啥？ 分布式服务顾名思义服务是分散部署在不同的机器上的，一个服务可能负责几个功能，是一种面向SOA架构的，服务之间也是通过rpc来交互或者是webservice来交互的。逻辑架构设计完后就该做物理架构设计，系统应用部署在超过一台服务器或虚拟机上，且各分开部署的部分彼此通过各种通讯协议交互信息，就可算作分布式部署，生产环境下的微服务肯定是分布式部署的，分布式部署的应用不一定是微服务架构的，比如集群部署，它是把相同应用复制到不同服务器上，但是逻辑功能上还是单体应用。 微服务又是啥? 简单来说微服务就是很小的服务，小到一个服务只对应一个单一的功能，只做一件事。 这个服务可以单独部署运行，服务之间可以通过RPC来相互交互，每个微服务都是由独立的小团队开发，测试，部署，上线，负责它的整个生命周期。 微服务架构又又是啥？ 在做架构设计的时候，先做逻辑架构，再做物理架构，当你拿到需求后，估算过最大用户量和并发量后，计算单个应用服务器能否满足需求。 如果用户量只有几百人的小应用，单体应用就能搞定，即所有应用部署在一个应用服务器里，如果是很大用户量，且某些功能会被频繁访问，或者某些功能计算量很大，建议将应用拆解为多个子系统，各自负责各自功能，这就是微服务架构。 区别 分布式是指将不同的业务分布在不同的地方。 集群指的是将几台服务器集中在一起，实现同一业务。 简单说，分布式是以缩短单个任务的执行时间来提升效率的，而集群则是通过提高单位时间内执行的任务数来提升效率。 微服务与分布式的细微差别是，微服务的应用不一定是分散在多个服务器上，他也可以是同一个服务器。微服务相比分布式服务来说，它的粒度更小，服务之间耦合度更低，由于每个微服务都由独立的小团队负责，因此它敏捷性更高，分布式服务最后都会向微服务架构演化，这是一种趋势， 不过服务微服务化后带来的挑战也是显而易见的，例如服务粒度小，数量大，后期运维将会很难 图示: 架构的演变过程 下面我们来简单模拟一个架构演变过程。 我们以 javaweb 为例，来搭建一个简单的电商系统，从这个系统中来看系统的演变过程。要注意的是接下来的演示模型， 关注的是数据量、访问量提升，网站结构的变化， 而不关注具体业务的功能点。其次，这个过程是为了让大家能更好的了解网站演进过程中的一些问题和应对策略。 假如我们系统具备以下功能: 用户模块:用户注册和管理。 商品模块:商品展示和管理。 交易模块:创建交易及支付结算。 阶段一：单应用架构 这个阶段是网站的初期，也可以认为是互联网发展的早期，系统架构如上图所示。我们经常会在单台服务器上运行我们所有的程序和软件。 把所有软件和应用都部署在一台机器上，这样就完成一个简单系统的搭建，这个阶段的讲究的是效率。效率决定生死。 阶段二：应用服务器和数据库服务器分离 随着网站的上线，访问量逐步上升，服务器的负载慢慢提高，我们应该在服务器还没有超载的时候就做好规划、提升网站的负载能力。假若此时已经没办法在代码层面继续优化提高，那么在单台机器的性能遇到瓶颈的时候，增加机器是一个比较简单好用的方式，投入产出比相当高。这个阶段增加机器的主要目的是将 web 服务器和 数据库服务器拆分开来，这样做的话不仅提高了单机的负载能力，也提高了整个系统的容灾能力。 这个阶段的系统架构如上图所示，应用服务器和数据库服务器完全隔离开来，相互互不影响，大大减少了网站宕机的风险，此阶段我们已经开始关注到应用服务器的管理了。 阶段三：应用服务器集群 这个阶段，随着访问量的继续不断增加，单台应用服务器已经无法满足我们的需求。 假设我的数据库服务器还没有遇到性能问题，那我们可以通过增加应用服务器的方式来将应用服务器集群化，这样就可以将用户请求分流到各个服务器中，从而达到继续提升系统负载能力的目的。此时各个应用服务器之间没有直接的交互，他们都是依赖数据库各自对外提供服务。 系统架构发展到这个阶段，各种问题也会接踵而至： 用户请求交由谁来转发到具体的应用服务器上(谁来负责负载均衡) 用户如果每次访问到的服务器不一样，那么如何维护session，达到session共享的目的。 那么此时，系统架构又会变成如下方式： 负载均衡又可以分为软负载和硬负载。软负载我们可以选择Nginx、Apache等，硬负载我们可以选择F5等。而session共享问题我们可以通过配置tomcat的session共享解决。 阶段四：数据库压力变大，数据库读写分离 架构演变到上面的阶段，并不是终点。通过上面的设计，应用层的性能被我们拉上来了， 但数据库的负载也在逐渐增大，那如何去提高数据库层面的性能呢？有了前面的设计思路以后，我们自然也会想到通过增加服务器来提高性能。但假如我们单纯的把数据库一分为二，然后对于数据库的请求，分别负载到两台数据库服务器上，那必定会造成数据库数据不统一的问题。 所以我们一般先考虑将数据库读写分离。 这个架构设计的变化会带来如下几个问题： 主从数据库之间的数据需要同步(可以使用 mysql 自带的 master-slave 方式实现主从复制 ) 应用中需要根据业务进行对应数据源的选择( 采用第三方数据库中间件，例如 mycat ) 阶段五：使用搜索引擎缓解读库的压力 我们都知道数据库常常对模糊查找效率不是很高，像电商类的网站，搜索是非常核心的功能，即使是做了读写分离，这个问题也不能得到有效解决。那么这个时候我们就需要引入搜索引擎了，使用搜索引擎能够大大提升我们系统的查询速度，但同时也会带来一 些附加的问题，比如维护索引的构建、数据同步到搜索引擎等。 阶段六：引入缓存机制缓解数据库的压力 然后，随着访问量的持续不断增加，逐渐会出现许多用户访问同一内容的情况，那么对于这些热点数据，没必要每次都从数据库重读取，这时我们可以使用到缓存技术，比如 redis、memcache 来作为我们应用层的缓存。另外在某些场景下，如我们对用户的某些 IP 的访问频率做限制， 那这个放内存中就又不合适，放数据库又太麻烦了，那这个时候可以使用 Nosql 的方式比如 mongDB 来代替传统的关系型数据库。 阶段七：数据库的水平/垂直拆分 我们的网站演进的变化过程，交易、商品、用户的数据都还在同一 个数据库中，尽管采取了增加缓存，读写分离的方式，但是随着数 据库的压力持续增加，数据库的瓶颈仍然是个最大的问题。因此我 们可以考虑对数据的垂直拆分和水平拆分。 垂直拆分:把数据库中不同业务数据拆分到不同的数据库。 水平拆分:把同一个表中的数据拆分到两个甚至更多的数据库中，水平拆分的原因是某些业务数据量已经达到了单个数据库的瓶颈，这时可以采取将表拆分到多个数据库中。 阶段八：应用的拆分 随着业务的发展，业务量越来越大，应用的压力越来越大。工程规模也越来越庞大。这个时候就可以考虑将应用拆分，按照领域模型将我们的用户、商品、交易拆分成多个子系统。 这样拆分以后，可能会有一些相同的代码，比如用户操作，在商品和交易都需要查询，所以会导致每个系统都会有用户查询访问相关操作。这些相同的操作一定是要抽象出来，否则就是一个坑。所以通过走服务化路线的方式来解决。 那么服务拆分以后，各个服务之间如何进行远程通信呢? 通过 RPC 技术，比较典型的有:dubbo、webservice、hessian、http、RMI 等等。前期通过这些技术能够很好的解决各个服务之间通信问题，但是， 互联网的发展是持续的，所以架构的演变和优化也还在持续。 转自:领悟.海洋-分布式架构的总结 CAP理论概述 一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance）这三项中的两项。 CAP的定义 Consistency 一致性 一致性指“all nodes see the same data at the same time”，即所有节点在同一时间的数据完全一致。 一致性是因为多个数据拷贝下并发读写才有的问题，因此理解时一定要注意结合考虑多个数据拷贝下并发读写的场景。 对于一致性，可以分为从客户端和服务端两个不同的视角。 客户端 从客户端来看，一致性主要指的是多并发访问时更新过的数据如何获取的问题。 服务端 从服务端来看，则是更新如何分布到整个系统，以保证数据最终一致。 对于一致性，可以分为强/弱/最终一致性三类 从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了不同的一致性。 强一致性 对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。 弱一致性 如果能容忍后续的部分或者全部访问不到，则是弱一致性。 最终一致性 如果经过一段时间后要求能访问到更新后的数据，则是最终一致性。 Availability 可用性 可用性指“Reads and writes always succeed”，即服务在正常响应时间内一直可用。 好的可用性主要是指系统能够很好的为用户服务，不出现用户操作失败或者访问超时等用户体验不好的情况。可用性通常情况下可用性和分布式数据冗余，负载均衡等有着很大的关联。 Partition Tolerance分区容错性 分区容错性指“the system continues to operate despite arbitrary message loss or failure of part of the system”，即分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性或可用性的服务。 CAP的证明 上图是我们证明CAP的基本场景，网络中有两个节点N1和N2，可以简单的理解N1和N2分别是两台计算机，他们之间网络可以连通，N1中有一个应用程序A，和一个数据库V，N2也有一个应用程序B2和一个数据库V。现在，A和B是分布式系统的两个部分，V是分布式系统的数据存储的两个子数据库。 在满足一致性的时候，N1和N2中的数据是一样的，V0=V0。在满足可用性的时候，用户不管是请求N1或者N2，都会得到立即响应。在满足分区容错性的情况下，N1和N2有任何一方宕机，或者网络不通的时候，都不会影响N1和N2彼此之间的正常运作。 上图是分布式系统正常运转的流程，用户向N1机器请求数据更新，程序A更新数据库Vo为V1，分布式系统将数据进行同步操作M，将V1同步的N2中V0，使得N2中的数据V0也更新为V1，N2中的数据再响应N2的请求。 这里，可以定义N1和N2的数据库V之间的数据是否一样为一致性；外部对N1和N2的请求响应为可用性；N1和N2之间的网络环境为分区容错性。 这是正常运作的场景，也是理想的场景，然而现实是残酷的，当错误发生的时候，一致性和可用性还有分区容错性，是否能同时满足，还是说要进行取舍呢？ 作为一个分布式系统，它和单机系统的最大区别，就在于网络，现在假设一种极端情况，N1和N2之间的网络断开了，我们要支持这种网络异常，相当于要满足分区容错性，能不能同时满足一致性和响应性呢？还是说要对他们进行取舍。 假设在N1和N2之间网络断开的时候，有用户向N1发送数据更新请求，那N1中的数据V0将被更新为V1，由于网络是断开的，所以分布式系统同步操作M，所以N2中的数据依旧是V0；这个时候，有用户向N2发送数据读取请求，由于数据还没有进行同步，应用程序没办法立即给用户返回最新的数据V1，怎么办呢？ 有二种选择，第一，牺牲数据一致性，响应旧的数据V0给用户；第二，牺牲可用性，阻塞等待，直到网络连接恢复，数据更新操作M完成之后，再给用户响应最新的数据V1。 这个过程，证明了要满足分区容错性的分布式系统，只能在一致性和可用性两者中，选择其中一个。 CAP权衡 通过CAP理论，我们知道无法同时满足一致性、可用性和分区容错性这三个特性，那要舍弃哪个呢？ CA without P：如果不要求P（不允许分区），则C（强一致性）和A（可用性）是可以保证的。但其实分区不是你想不想的问题，而是始终会存在，因此CA的系统更多的是允许分区后各子系统依然保持CA。 CP without A：如果不要求A（可用），相当于每个请求都需要在Server之间强一致，而P（分区）会导致同步时间无限延长，如此CP也是可以保证的。很多传统的数据库分布式事务都属于这种模式。 AP wihtout C：要高可用并允许分区，则需放弃一致性。一旦分区发生，节点之间可能会失去联系，为了高可用，每个节点只能用本地数据提供服务，而这样会导致全局数据的不一致性。现在众多的NoSQL都属于此类。 对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到N个9，即保证P和A，舍弃C（退而求其次保证最终一致性）。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。 对于涉及到钱财这样不能有一丝让步的场景，C必须保证。网络发生故障宁可停止服务，这是保证CA，舍弃P。貌似这几年国内银行业发生了不下10起事故，但影响面不大，报道也不多，广大群众知道的少。还有一种是保证CP，舍弃A。例如网络故障事只读不写。 孰优孰略，没有定论，只能根据场景定夺，适合的才是最好的。 ","link":"http://blog.ludangxin.club/post/fen-bu-shi-ji-qun-wei-fu-wu/"},{"title":"SpringBoot 集成 表单验证 和 异常统一处理","content":"表单验证注解清单 注解 说明 @Null 限制只能为null @NotNull 限制必须不为null @AssertFalse 限制必须为false @AssertTrue 限制必须为true @DecimalMax(value) 限制必须为一个不大于指定值的数字 @DecimalMin(value) 限制必须为一个不小于指定值的数字 @Digits(integer,fraction) 限制必须为一个小数，且整数部分的位数不能超过integer，小数部分的位数不能超过fraction @Future 限制必须是一个将来的日期 @Max(value) 限制必须为一个不大于指定值的数字 @Min(value) 限制必须为一个不小于指定值的数字 @Past 限制必须是一个过去的日期 @Pattern(value) 限制必须符合指定的正则表达式 @Size(max,min) 限制字符长度必须在min到max之间 @Past 验证注解的元素值（日期类型）比当前时间早 @NotEmpty 验证注解的元素值不为null且不为空（字符串长度不为0、集合大小不为0） @NotBlank 验证注解的元素值不为空（不为null、去除首位空格后长度为0），不同于@NotEmpty，@NotBlank @Email 验证注解的元素值是Email，也可以通过正则表达式和flag指定自定义的email格式 项目结构图示 引入所需依赖 &lt;!-- SpringBoot Web容器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 表单验证 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 创建Validator配置类 import lombok.extern.slf4j.Slf4j; import org.hibernate.validator.HibernateValidator; import org.springframework.boot.autoconfigure.EnableAutoConfiguration; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.validation.beanvalidation.MethodValidationPostProcessor; import javax.validation.Validation; import javax.validation.Validator; import javax.validation.ValidatorFactory; /** * 配置 Hibernate 参数校验 * @author ludangxin */ @Slf4j @Configuration @EnableAutoConfiguration public class ValidatorConfig { @Bean public MethodValidationPostProcessor methodValidationPostProcessor() { MethodValidationPostProcessor postProcessor = new MethodValidationPostProcessor(); //快速校验，只要有错马上返回 postProcessor.setValidator(validator()); return postProcessor; } @Bean public Validator validator(){ ValidatorFactory validatorFactory = Validation.byProvider( HibernateValidator.class ) .configure() .addProperty( &quot;hibernate.validator.fail_fast&quot;, &quot;true&quot; ) .buildValidatorFactory(); Validator validator = validatorFactory.getValidator(); return validator; } } 创建实体类 这里着重讲一下注解中groups是用来干什么的? 因为一个实体不可能只干一种操作,一个实体必然存在增删改查操作,那么问题就来了 如果我要根据id进行更新操作,那么id肯定不能为空 这时候我还要进行新增操作,因为id是新增数据库操作才产生的,接受数据的时候我肯定是没有id的 所以就产生矛盾了 那么groups这个参数就起作用了,它可以表示我这个注解属于哪个组,这样就解决这个尴尬的问题了. 注: 当在controller中校验表单数据时,如果使用了groups,那么没有在这个分组下的属性是不会校验的 import lombok.*; import javax.validation.constraints.*; import java.io.Serializable; /** * 用户信息管理 * @Author: ludangxin * @Date: 2020/5/20 16:09 */ @Data @Builder @AllArgsConstructor @NoArgsConstructor public class SysUser implements Serializable { private static final long serialVersionUID = 1L; /** * 主键 */ @NotNull(message = &quot;id不能为空&quot;,groups = {ValidationInterface.update.class}) private Long id; /** * 用户名 */ @NotEmpty(message = &quot;用户名称不能为空&quot; , groups = {ValidationInterface.update.class,ValidationInterface.add.class}) private String username; /** * 密码 */ @Size(min = 6, max = 16, message = &quot;密码长度必须在6-16之间&quot; , groups = {ValidationInterface.update.class,ValidationInterface.add.class}) private String password; /** * 邮箱地址 */ @Email(message = &quot;邮箱地址不合法&quot; , groups = {ValidationInterface.update.class,ValidationInterface.add.class , ValidationInterface.select.class}) @NotEmpty(message = &quot;邮箱不能为空&quot;,groups = ValidationInterface.add.class) private String email; /** * 电话 */ @Size(min = 11, max = 11, message = &quot;手机号不合法&quot; , groups = {ValidationInterface.update.class, ValidationInterface.add.class , ValidationInterface.select.class}) @NotEmpty(message = &quot;手机号不能为空&quot;,groups = {ValidationInterface.add.class}) private String phone; } 创建表单验证的通用分组接口 如果还有其它特殊的分组要求 直接在BO中创建interface即可 例:如果还有个需要验证username 和 password(只有这两个参数) 的 select操作 直接在SysUser中创建UsernamePasswordValidView 的接口即可 /** * 用于表单验证的通用分组接口 * @Author: ludangxin * @Date: 2020/5/20 17:07 */ public interface ValidationInterface { /** * 新增分组 */ interface add{} /** * 删除分组 */ interface delete{} /** * 查询分组 */ interface select{} /** * 更新分组 */ interface update{} } 创建业务异常类 /** * 业务异常 * @author ludangxin */ public class BusinessException extends RuntimeException{ private static final long serialVersionUID = 1L; protected final String message; public BusinessException(String message) { this.message = message; } public BusinessException(String message, Throwable e) { super(message, e); this.message = message; } @Override public String getMessage() { return message; } } 创建全局异常处理器 import com.ldx.springboot.util.AjaxResult; import lombok.extern.slf4j.Slf4j; import org.springframework.validation.BindException; import org.springframework.web.HttpRequestMethodNotSupportedException; import org.springframework.web.bind.annotation.ExceptionHandler; import org.springframework.web.bind.annotation.RestControllerAdvice; import javax.servlet.http.HttpServletRequest; import javax.validation.ConstraintViolation; import javax.validation.ConstraintViolationException; import javax.validation.ValidationException; import java.util.Set; /** * 全局异常处理器 * */ @RestControllerAdvice @Slf4j public class GlobalExceptionHandler { /** * 参数绑定异常类 用于表单验证时抛出的异常处理 */ @ExceptionHandler(BindException.class) public AjaxResult validatedBindException(BindException e){ log.error(e.getMessage(), e); String message = &quot;[&quot; + e.getAllErrors().get(0).getDefaultMessage() + &quot;]&quot;; return AjaxResult.error(message); } /** * 参数绑定异常类 用于Json数据绑定验证时抛出的异常处理 */ @ExceptionHandler(MethodArgumentNotValidException.class) public AjaxResult methodArgumentNotValidException(MethodArgumentNotValidException e){ log.error(e.getMessage(), e); String message = &quot;[&quot; + e.getBindingResult().getAllErrors().get(0).getDefaultMessage() + &quot;]&quot;; return AjaxResult.error(message); } /** * 参数绑定异常类 用于方法形参中参数校验时抛出的异常处理 * @param e * @return */ @ExceptionHandler(ConstraintViolationException.class) public AjaxResult handle(ValidationException e) { log.error(e.getMessage(), e); String errorInfo = &quot;&quot;; if(e instanceof ConstraintViolationException){ ConstraintViolationException exs = (ConstraintViolationException) e; Set&lt;ConstraintViolation&lt;?&gt;&gt; violations = exs.getConstraintViolations(); for (ConstraintViolation&lt;?&gt; item : violations) { errorInfo = errorInfo + &quot;[&quot; + item.getMessage() + &quot;]&quot;; } } return AjaxResult.error(errorInfo); } /** * 请求方式不支持 */ @ExceptionHandler({ HttpRequestMethodNotSupportedException.class }) public AjaxResult handleException(HttpRequestMethodNotSupportedException e){ log.error(e.getMessage(), e); return AjaxResult.error(&quot;不支持' &quot; + e.getMethod() + &quot;'请求&quot;); } /** * 拦截未知的运行时异常 */ @ExceptionHandler(RuntimeException.class) public AjaxResult notFount(RuntimeException e) { log.error(&quot;运行时异常:&quot;, e); return AjaxResult.error(&quot;运行时异常:&quot; + e.getMessage()); } /** * 系统异常 */ @ExceptionHandler(Exception.class) public AjaxResult handleException(Exception e) { log.error(e.getMessage(), e); return AjaxResult.error(&quot;服务器错误，请联系管理员&quot;); } /** * 业务异常 */ @ExceptionHandler(BusinessException.class) public AjaxResult businessException(HttpServletRequest request, BusinessException e) { log.error(e.getMessage()); return AjaxResult.error(e.getMessage()); } } 创建controller 类上的 @Validated 主要是为了使方法形参中的验证生效. 如果只是用实体类上的参数绑定校验,那么就不用在类上标注该注解 import com.ldx.springboot.exception.BusinessException; import com.ldx.springboot.model.SysUser; import com.ldx.springboot.model.ValidationInterface; import com.ldx.springboot.util.AjaxResult; import org.springframework.validation.annotation.Validated; import org.springframework.web.bind.annotation.*; import javax.validation.constraints.Email; import javax.validation.constraints.NotEmpty; @RequestMapping(&quot;sysuser&quot;) @RestController @Validated public class SysUserController { /** * 根据手机号和邮箱查询用户信息 * @param sysUser 用户信息 * @return */ @GetMapping(&quot;selectByPhoneOrEmail&quot;) public AjaxResult selectByPhoneOrEmail(@Validated(value = ValidationInterface.select.class) SysUser sysUser){ return AjaxResult.success(&quot;查询成功&quot;); } /** * 根据手机号和邮箱查询用户信息 * @param phone 手机号 * @param email 邮箱 * @return */ @GetMapping(&quot;selectByPhoneOrEmail2&quot;) public AjaxResult selectByPhoneOrEmail2(@NotEmpty(message = &quot;手机号不能为空&quot;) String phone ,@NotEmpty(message = &quot;邮箱不能为空&quot;)@Email(message = &quot;邮箱信息不合法&quot;) String email){ return AjaxResult.success(&quot;查询成功&quot;); } /** * 新增用户信息 * @param sysUser 用户信息 * @return */ @PostMapping(&quot;add&quot;) public AjaxResult add(@Validated(value = ValidationInterface.add.class) SysUser sysUser){ return AjaxResult.success(&quot;新增成功&quot;); } /** * 新增用户信息 * @param sysUser 用户信息 * @return */ @PostMapping(&quot;add1&quot;) public AjaxResult add1(@Validated(value = ValidationInterface.add.class) @RequestBody SysUser sysUser){ return AjaxResult.success(&quot;新增成功&quot;); } /** * 更具Id更新用户信息 * @param sysUser 用户信息 * @return */ @PutMapping(&quot;updateById&quot;) public AjaxResult updateById(@Validated(value = ValidationInterface.update.class) SysUser sysUser){ return AjaxResult.success(&quot;更新成功&quot;); } /** * 根据Id删除用户信息 * @param id * @return */ @DeleteMapping(&quot;deleteById/{id}&quot;) public AjaxResult deleteById( @PathVariable Long id){ return AjaxResult.success(&quot;删除成功&quot;); } /** * 测试业务异常 * @return */ @GetMapping(&quot;testException&quot;) public AjaxResult testException(String name){ if(!&quot;张三&quot;.equals(name)){ throw new BusinessException(&quot;只有张三才可以访问&quot;); } return AjaxResult.success(); } } 创建操作消息提醒类 import lombok.Data; import lombok.NoArgsConstructor; /** * 操作消息提醒 */ @Data @NoArgsConstructor public class AjaxResult { /** * 状态类型 */ public enum Type{ /** 成功 */ SUCCESS(200), /** 警告 */ WARN(301), /** 错误 */ ERROR(500), /*token失效*/ UNAUTHORIZED(401) ; private final int value; Type(int value){ this.value = value; } public int value(){ return this.value; } } /** 状态码 */ private int code; /** 返回内容 */ private String msg; /** 数据对象 */ private Object data; /** * 初始化一个新创建的 AjaxResult 对象 * * @param type 状态类型 * @param msg 返回内容 */ public AjaxResult(Type type, String msg) { this.code = type.value; this.msg = msg; } /** * 初始化一个新创建的 AjaxResult 对象 * * @param type 状态类型 * @param msg 返回内容 * @param data 数据对象 */ public AjaxResult(Type type, String msg, Object data) { this.code = type.value; this.msg = msg; if (data != null) { this.data = data; } } /** * 返回成功消息 * * @return 成功消息 */ public static AjaxResult success() { return AjaxResult.success(&quot;操作成功&quot;); } /** * 返回成功数据 * * @return 成功消息 */ public static AjaxResult success(Object data) { return AjaxResult.success(&quot;操作成功&quot;, data); } /** * 返回成功消息 * * @param msg 返回内容 * @return 成功消息 */ public static AjaxResult success(String msg) { return AjaxResult.success(msg, null); } /** * 返回成功消息 * * @param msg 返回内容 * @param data 数据对象 * @return 成功消息 */ public static AjaxResult success(String msg, Object data) { return new AjaxResult(Type.SUCCESS, msg, data); } /** * 返回警告消息 * * @param msg 返回内容 * @return 警告消息 */ public static AjaxResult warn(String msg) { return AjaxResult.warn(msg, null); } /** * 返回警告消息 * * @param msg 返回内容 * @param data 数据对象 * @return 警告消息 */ public static AjaxResult warn(String msg, Object data) { return new AjaxResult(Type.WARN, msg, data); } /** * 返回错误消息 * * @return */ public static AjaxResult error() { return AjaxResult.error(&quot;操作失败&quot;); } /** * 返回错误消息 * * @param msg 返回内容 * @return 警告消息 */ public static AjaxResult error(String msg) { return AjaxResult.error(msg, null); } /** * 返回错误消息 * * @param msg 返回内容 * @param data 数据对象 * @return 警告消息 */ public static AjaxResult error(String msg, Object data) { return new AjaxResult(Type.ERROR, msg, data); } /** * 返回错误消息 * * @param msg 返回内容 * @return 警告消息 */ public static AjaxResult unauthorized(String msg) { return AjaxResult.unauthorized(msg, null); } /** * 返回错误消息 * * @param msg 返回内容 * @param data 数据对象 * @return 警告消息 */ public static AjaxResult unauthorized(String msg, Object data) { return new AjaxResult(Type.UNAUTHORIZED, msg, data); } } 效果演示 访问selectByPhoneOrEmail接口 访问selectByPhoneOrEmail2接口 访问add接口 访问testException接口测试业务异常提示 ","link":"http://blog.ludangxin.club/post/springboot-ji-cheng-biao-dan-yan-zheng-he-yi-chang-tong-yi-chu-li/"},{"title":"Nginx","content":"nginx简介 nginx概述 Nginx (&quot;engine x&quot;) 是一个高性能的 HTTP 和反向代理服务器,特点是占有内存少，并发能 力强，事实上 nginx 的并发能力确实在同类型的网页服务器中表现较好，中国大陆使用 nginx 网站用户有：百度、京东、新浪、网易、腾讯、淘宝等 nginx作为web服务器 Nginx 可以作为静态页面的 web 服务器，同时还支持 CGI 协议的动态语言，比如 perl、php 等。但是不支持 java。Java 程序只能通过与 tomcat 配合完成。Nginx 专为性能优化而开发， 性能是其最重要的考量,实现上非常注重效率 ，能经受高负载的考验,有报告表明能支持高 达 50,000 个并发连接数。 https://lnmp.org/nginx.html 正向代理 Nginx 不仅可以做反向代理，实现负载均衡。还能用作正向代理来进行上网等功能。 正向代理：如果把局域网外的 Internet 想象成一个巨大的资源库，则局域网中的客户端要访 问 Internet，则需要通过代理服务器来访问，这种代理服务就称为正向代理。 反向代理 反向代理，其实客户端对代理是无感知的，因为客户端不需要任何配置就可以访问，我们只 需要将请求发送到反向代理服务器，由反向代理服务器去选择目标服务器获取数据后，在返 回给客户端，此时反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器 地址，隐藏了真实服务器 IP 地址。 负载均衡 客户端发送多个请求到服务器，服务器处理请求，有一些可能要与数据库进行交互，服务器处理完毕后，再将结果返回给客户端。 这种架构模式对于早期的系统相对单一，并发请求相对较少的情况下是比较适合的，成本也低。但是随着信息数量的不断增长，访问量和数据量的飞速增长，以及系统业务的复杂度增加，这种架构会造成服务器相应客户端的请求日益缓慢，并发量特别大的时候，还容易造成服务器直接崩溃。很明显这是由于服务器性能的瓶颈造成的问题，那么如何解决这种情况呢？ 我们首先想到的可能是升级服务器的配置，比如提高 CPU 执行频率，加大内存等提高机器的物理性能来解决此问题，但是我们知道摩尔定律的日益失效，硬件的性能提升已经不能满足日益提升的需求了。最明显的一个例子，天猫双十一当天，某个热销商品的瞬时访问量是极其庞大的，那么类似上面的系统架构，将机器都增加到现有的顶级物理配置，都是不能够满足需求的。那么怎么呢？ 上面的分析我们去掉了增加服务器物理配置来解决问题的办法，也就是说纵向解决问题的办法行不通了，那么横向增加服务器的数量呢？这时候集群的概念产生了，单个服务器解决不了，我们增加服务器的数量，然后将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同的服务器，也就是我们所说的负载均衡 动静分离 为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度。降低原来单个服务器的压力。 nginx 安装 素材介绍 PCRE PCRE库支持正则表达式。如果我们在配置文件nginx.conf中使用了正则表达式，那么在编译Nginx时就必须把PCRE库编译进Nginx，因为Nginx的HTTP模块需要靠它来解析正则表达式。另外，pcre-devel是使用PCRE做二次开发时所需要的开发库，包括头文件等，这也是编译Nginx所必须使用的. zlib zlib库用于对HTTP包的内容做gzip格式的压缩，如果我们在nginx.conf中配置了gzip on，并指定对于某些类型（content-type）的HTTP响应使用gzip来进行压缩以减少网络传输量，则在编译时就必须把zlib编译进Nginx。zlib-devel是二次开发所需要的库. openSSL 如果服务器不只是要支持HTTP，还需要在更安全的SSL协议上传输HTTP，那么需要拥有OpenSSL。另外，如果我们想使用MD5、SHA1等散列函数，那么也需要安装它。 nginx安装包 开始安装 安装pcre cd /usr/local/ : 到安装目录下 wget https://sourceforge.net/projects/pcre/files/pcre/8.44/pcre-8.44.tar.gz:下载pcre tar -zxvf pcre-8.44.tar.gz: 解压 cd pcre-8.44:切换到文件夹下 ./configure:执行配置文件 make &amp;&amp; make install:编译安装pcre 特别注意:make 命令执行不了的同学 ./configure后 最后一行会出现 configure: error: You need a C++ compiler for C++ support. 安装一下这个即可：yum install -y gcc gcc-c++ （安装完毕后在执行 ./configure 在执行make 就OK了 我就是这样） 安装openssl和zlib yum -y install make zlib zlib-devel gcc-c++ libtool openssl openssl-devel:一键安装 安装nginx cd /usr/local/ : 到安装目录下并且把tar文件放到该目录中 tar -zxvf nginx-1.16.1.tar.gz : 解压文件 cd nginx-1.16.1: 切换到文件目录下 ./configure: 执行安装配置文件 make &amp;&amp; make install: 编译安装 cd /usr/local/nginx/sbin/: 进去nginx可执行文件目录中 ./nginx:启动nginx服务 访问系统80端口查看服务是否启动 特别注意: 在 windows 系统中访问linux 中 nginx，默认不能访问的，因为防火墙问题 查看开放的端口号 firewall-cmd --list-all 设置开放的端口号 firewall-cmd --add-service=http –permanent firewall-cmd --add-port=80/tcp --permanent 重启防火墙 firewall-cmd –reload nginx 常用命令和配置文件 常用命令 cd /usr/local/nginx/sbin: 进入nginx目录中 ./nginx -v:查看nginx版本号 ./nginx: 启动nginx ./nginx -s stop: 停止nginx ./nginx -s reload:重新加载nginx(不是重启) 配置文件 cd /usr/local/nginx/conf/nginx.conf : 配置文件的目录 配置文件中的内容 全局块 worker_processes; * 从配置文件开始到 events 块之间的内容，主要会设置一些影响 nginx 服务器整体运行的配置指令，主要包括配置运行 Nginx 服务器的用户（组）、允许生成的 worker process 数，进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。比如上面第一行配置的 `worker_processes 1;` 这是 Nginx 服务器并发处理服务的关键配置，worker_processes 值越大，可以支持的并发处理量也越多，但是会受到硬件、软件等设备的制约. * events块 * ``````json events { worker_connections 1024; } `````` * events 块涉及的指令主要影响 Nginx 服务器与用户的网络连接，常用的设置包括是否开启对多 work process 下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个 word process 可以同时支持的最大连接数等。 上述例子就表示每个 work process 支持的最大连接数为 1024. 这部分的配置对 Nginx 的性能影响较大，在实际中应该灵活配置。 * http块 * ``````json http { include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' # '$status $body_bytes_sent &quot;$http_referer&quot; ' # '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server { listen 80; server_name localhost; `````` * 这算是 Nginx 服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。需要注意的是：http 块也可以包括 **http 全局块**、**server 块** * http全局块 * http 全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求数上限等。 * server块 * 这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。每个 http 块可以包括多个server 块，而每个 server 块就相当于一个虚拟主机。而每个 server 块也分为全局server 块，以及可以同时包含多个 locaton 块。 * 全局server块 * 最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或 IP 配置。 * location块 * 一个 server 块可以配置多个 location 块。 这块的主要作用是基于 Nginx 服务器接收到的请求字符串（例如 server_name/uri-string），对虚拟 主机名称（也可以是 IP 别名）之外的字符串（例如 前面的 /uri-string）进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行。 location 指令说明 该指令用于匹配URL 语法如下 location [ = | ~ | ~* | ^~] uri { } = : 用于不含正则表达式的 uri 前，要求请求字符串与 uri 严格匹配，如果匹配成功，就停止继续向下搜索并立即处理该请求 ~ : 用于表示 uri 包含正则表达式，并且区分大小写 ~* : 用于表示 uri 包含正则表达式，并且不区分大小写 ^~ : 用于不含正则表达式的 uri 前，要求 Nginx 服务器找到标识 uri 和请求字符串匹配度最高的 location 后，立即使用此 location 处理请求，而不再使用 location 块中的正则 uri 和请求字符串做匹配 *注意 : ** 如果 uri 包含正则表达式，则必须要有 ~ 或者 ~ 标识 nginx配置实例-反向代理 反向代理实例一 实现效果:使用nginx反向代理,访问www.123.com直接跳转到127.0.0.1:8080 实现过程: 启动一个tomcat,浏览器地址栏输入127.0.0.1:8080,启动访问正常后 修改本地hostC:\\Windows\\System32\\drivers\\etc\\hosts文件,将www.123.com映射到127.0.0.1 配置完成之后，我们便可以通过 www.123.com:8080 访问到第一步出现的 Tomcat 初始界面。那么如何只需要输入 www.123.com 便可以跳转到 Tomcat 初始界面呢？便用到 nginx的反向代理。 在 nginx.conf 配置文件中增加如下配置 server { listen 80; server_name www.123.com; location / { proxy_pass http://127.0.0.1:8080; index index.html index.htm index.jsp; } } 如上配置，我们监听 80 端口，访问域名为 www.123.com，不加端口号时默认为 80 端口，故 访问该域名时会跳转到 127.0.0.1:8080 路径上。在浏览器端输入 www.123.com 会看到tomcat index.jsp 页面： 反向代理实例二 实现效果：使用 nginx 反向代理，根据访问的路径跳转到不同端口的服务中nginx 监听端口为 9001， 访问 http://127.0.0.1:9001/edu/ 直接跳转到 127.0.0.1:8081 访问 http://127.0.0.1:9001/vod/ 直接跳转到 127.0.0.1:8082 实现过程 准备两个 tomcat，一个 8001 端口，一个 8002 端口，并准备好测试的页面 修改 nginx 的配置文件 ,在 http 块中添加 server{} server { listen 9001; server_name localhost; location ~ /edu/ { proxy_pass http://localhost:8001; } location ~ /vod/ { proxy_pass http://localhost:8002; } } 访问测试 nginx 配置实例-负载均衡 实现效果: 浏览器地址栏输入地址 http://192.168.17.129/edu/a.html，负载均衡效果,平均8080和 8081 端口中 实现过程 准备两个同时启动的tomcat,一台8080,一台8081 在两台 tomcat里面 webapps目录中，创建名称 edu 文件夹，在 edu 文件夹中创建页面 a.html，用于测试 在nginx的配置文件中进行负载均衡的配置 upstream myserver { server 192.168.17.129:8080; server 192.168.17.129:8081; } server { listen 80; server_name 192.168.17.129; location /{ proxy_pass http://myserver; root html; index index.html index.htm; } } 地址栏中访问测试http://192.168.17.129/edu/a.html nginx负载均衡 分配策略 轮询（默认） 每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。 weight weight 代表权,重默认为 1,权重越高被分配的客户端越多 指定轮询几率，weight 和访问比率成正比，用于后端服务器性能不均的情况。例如: upstream server_pool{ server 192.168.5.21 weight=5; server 192.168.5.22 weight=10; } ip_hash 每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题。 例如： upstream server_pool{ ip_hash; server 192.168.5.21:80; server 192.168.5.22:80; } fair (第三方) 按后端服务器的响应时间来分配请求，响应时间短的优先分配。 upstream server_pool{ server 192.168.5.21:80; server 192.168.5.22:80; fair; } nginx 配置实例-动静分离 Nginx 动静分离简单来说就是把动态跟静态请求分开，不能理解成只是单纯的把动态页面和静态页面物理分离。严格意义上说应该是动态请求跟静态请求分开，可以理解成使用 Nginx处理静态页面，Tomcat 处理动态页面。动静分离从目前实现角度来讲大致分为两种， ​ 一种是纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案； ​ 另外一种方法就是动态跟静态文件混合在一起发布，通过 nginx 来分开。通过 location 指定不同的后缀名实现不同的请求转发。通过 expires 参数设置，可以使浏览器缓存过期时间，减少与服务器之前的请求和流量。具体 Expires 定义：是给一个资源设定一个过期时间，也就是说无需去服务端验证，直接通过浏览器自身确认是否过期即可，所以不会产生额外的流量。此种方法非常适合不经常变动的资源。（如果经常更新的文件，不建议使用Expires 来缓存），我这里设置 3d，表示在这 3 天之内访问这个 URL，发送一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码304，如果有修改，则直接从服务器重新下载，返回状态码 200。 实现过程 现在系统中准备静态资源,用于访问 在linux 跟目录中创建image和www文件夹,并给文件夹下放入静态资源 具体配置 server { listen 80; server_name 192.168.17.129; location /www/ { root /data/; index index.html index.htm; } location /image/ { root /data/; autoindex on; } } 浏览器中输入地址http://192.168.17.129/image/01.jpg,http://192.168.17.129/www/a.html 特别注意: 因为配置文件中配置了 autoindex on;所以在浏览器中访问http://192.168.17.129/image/结果如下: nginx 处理跨域请求 当出现403跨域错误的时候 No 'Access-Control-Allow-Origin' header is present on the requested resource，需要给Nginx服务器配置响应的header参数： 解决方案 location / { add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS'; add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization'; if ($request_method = 'OPTIONS') { return 204; } } 解释 1. Access-Control-Allow-Origin 服务器默认是不被允许跨域的。给Nginx服务器配置`Access-Control-Allow-Origin *`后，表示服务器可以接受所有的请求源（Origin）,即接受所有跨域的请求。 2. Access-Control-Allow-Headers 是为了防止出现以下错误： Request header field Content-Type is not allowed by Access-Control-Allow-Headers in preflight response. 这个错误表示当前请求Content-Type的值不被支持。其实是我们发起了&quot;application/json&quot;的类型请求导致的。这里涉及到一个概念：预检请求（preflight request）,请看下面&quot;预检请求&quot;的介绍。 3. Access-Control-Allow-Methods 是为了防止出现以下错误： Content-Type is not allowed by Access-Control-Allow-Headers in preflight response. 4.给OPTIONS 添加 204的返回，是为了处理在发送POST请求时Nginx依然拒绝访问的错误 发送&quot;预检请求&quot;时，需要用到方法 OPTIONS ,所以服务器需要允许该方法。 预检请求（preflight request） 其实上面的配置涉及到了一个W3C标准：CROS,全称是跨域资源共享 (Cross-origin resource sharing)，它的提出就是为了解决跨域请求的。 跨域资源共享(CORS)标准新增了一组 HTTP 首部字段，允许服务器声明哪些源站有权限访问哪些资源。另外，规范要求，对那些可能对服务器数据产生副作用的HTTP 请求方法（特别是 GET 以外的 HTTP 请求，或者搭配某些 MIME 类型的 POST 请求），浏览器必须首先使用 OPTIONS 方法发起一个预检请求（preflight request），从而获知服务端是否允许该跨域请求。服务器确认允许之后，才发起实际的 HTTP 请求。在预检请求的返回中，服务器端也可以通知客户端，是否需要携带身份凭证（包括 Cookies 和 HTTP 认证相关数据）。 那么, 允许跨域, 不就是服务端(例如Nginx或者后端代码)设置Access-Control-Allow-Origin: *就可以了吗? 普通的请求确实是这样子的, 除此之外, 还一种叫请求叫Preflighted Request（带预检的跨域请求） Preflighted Request在发送真正的请求前, 会先发送一个方法为OPTIONS的预请求(Preflighted Request), 用于试探服务端是否能接受真正的请求. 如果options获得的回应是拒绝性质的，比如404\\403\\500等http状态，就会停止post、get等请求的发出。 那么, 什么情况下请求会变成Preflighted Request呢? 翻看了MDN的文档发现如下：(文档地址：https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS#The_HTTP_request_headers) 请求方法不是GET/HEAD/POST POST请求的Content-Type并非application/x-www-form-urlencoded, multipart/form-data, 或text/plain 请求设置了自定义的header字段 举个例子, 如果POST请求要传输的数据为 XML文档, Content-Type为application/xml或text/xml, 则发送这个请求前会发送一个预请求，或者自定义的header字段也是一样的道理。 有了上面的知识点, 再去看项目中ajax调用 可以看出, 跨域请求中设置了自定义的header字段, 所以该请求是preflighted request, 则请求前一定会发送一个OPTIONS作为预请求. 所以说, 在项目中ajax对后台API的调用, OPTIONS请求是没办法去掉的, 除非后台接口不再需要在请求header中设置openId但是由于该项目中用户信息是采用的JWT的方式，所以只好作罢。 但是由于该项目在后台中自定义了请求频率限制的拦截器，例如限制同一个客户端一秒内对某一个接口只能访问1次。如果超过限制，则第二次会返回状态码500，不予处理。如果每次请求前都带着一次OPTIONS请求，则该拦截器无法正常实现功能，反正会导致大批接口调用失败的情况。 鉴于上述分析，既然前端发起请求时OPTIONS请求没有办法去除，那么是否可以考虑从后台拦截器进行改造。 改造后的代码如下： 如果拦截到的请求不是项目中常规的GET或者POST请求，则该拦截器直接放行。至此，问题完美解决。 nginx 原理 master-workers 的机制的好处 首先，对于每个 worker 进程来说，独立的进程，不需要加锁，所以省掉了锁带来的开销， 同时在编程以及问题查找时，也会方便很多。其次，采用独立的进程，可以让互相之间不会 影响，一个进程退出后，其它进程还在工作，服务不会中断，master 进程则很快启动新的 worker 进程。当然，worker 进程的异常退出，肯定是程序有 bug 了，异常退出，会导致当 前 worker 上的所有请求失败，不过不会影响到所有请求，所以降低了风险。 需要设置多少个worker Nginx 同 redis 类似都采用了 io 多路复用机制，每个 worker 都是一个独立的进程，但每个进程里只有一个主线程，通过异步非阻塞的方式来处理请求， 即使是千上万个请求也不在话下。每个 worker 的线程可以把一个 cpu 的性能发挥到极致。所以 worker 数和服务器的cpu数相等是最为适宜的。设少了会浪费 cpu，设多了会造成 cpu 频繁切换上下文带来的损耗。 设置 worker 数量 worker_processes 4 #work 绑定 cpu(4 work 绑定 4cpu)。 worker_cpu_affinity 0001 0010 0100 1000 #work 绑定 cpu (4 work 绑定 8cpu 中的 4 个) 。 worker_cpu_affinity 0000001 00000010 00000100 00001000 连接数 worker_connection 这个值是表示每个 worker 进程所能建立连接的最大值，所以，一个 nginx 能建立的最大连接数，应该是 worker_connections * worker_processes 当然，这里说的是最大连接数，对于HTTP 请 求 本 地 资 源 来 说 ， 能 够 支 持 的 最 大 并 发 数 量 是 worker_connections * worker_processes 如果是支持 http1.1 的浏览器每次访问要占两个连接，所以普通的静态访问最大并发数是： worker_connections * worker_processes /2 而如果是 HTTP 作 为反向代理来说，最大并发数量应该是 worker_connections * worker_processes/4 因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接。 ","link":"http://blog.ludangxin.club/post/nginx/"},{"title":"SpringBoot  集成redis","content":"简介 Redis 是完全开源免费的，遵守BSD协议，是一个高性能的key-value非关系性数据库(NoSql)。 Redis 与其他 key - value 缓存产品有以下三个特点： Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 数据结构介绍 Redis可以存储键与5种不同数据结构类型之间的映射，这5种数据结构类型分别为String（字符串）、List（列表）、Set（集合）、Hash（散列）和 Zset（有序集合）。 结构类型 结构存储的值 读写能力 String 可以是字符串、整数或者浮点数 对整个字符串或者字符串的其中一部分执行操作；对象和浮点数执行自增(increment)或者自减(decrement) List 一个链表，链表上的每个节点都包含了一个字符串 从链表的两端推入或者弹出元素；根据偏移量对链表进行修剪(trim)；读取单个或者多个元素；根据值来查找或者移除元素 Set 包含字符串的无序收集器(unorderedcollection)，并且被包含的每个字符串都是独一无二的、各不相同 添加、获取、移除单个元素；检查一个元素是否存在于某个集合中；计算交集、并集、差集；从集合里卖弄随机获取元素 Hash 包含键值对的无序散列表 添加、获取、移除单个键值对；获取所有键值对 Zset 字符串成员(member)与浮点数分值(score)之间的有序映射，元素的排列顺序由分值的大小决定 添加、获取、删除单个元素；根据分值范围(range)或者成员来获取元素 redis 为什么这么快 完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)； 数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的； 采用单进程单线程(这也解释为什么redis可以处理高并发问题)，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗； 使用多路I/O复用模型(最后有介绍)； 使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求； 注解介绍 @Cacheable @Cacheable(value=&quot;myCache&quot;)，这个注释的意思是，当调用这个方法的时候，会从一个名叫myCache 的缓存中查询，如果没有，则执行实际的方法（即查询数据库），并将执行的结果存入缓存中，否则返回缓存中的对象。 @CachePut @CachePut 的作用 主要针对方法配置，能够根据方法的请求参数对其结果进行缓存，和 @Cacheable 不同的是，它每次都会触发真实方法的调用. @CacheEvict @CachEvict 的作用 主要针对方法配置，能够根据一定的条件对缓存进行清空 @CacheConfig @Cacheable()里面都有一个value＝“xxx”的属性，这显然如果方法多了，写起来也是挺累的，如果可以一次性声明完 那就省事了， 所以，有了@CacheConfig这个配置，@CacheConfig is a class-level annotation that allows to share the cache names，如果你在你的方法写别的名字，那么依然以方法的名字为准。 @Caching @Caching可以使注解组合使用,比如根据id查询用户信息,查询完的结果为{key = id,value = userInfo},但我们现在为了方遍,想用用户的手机号,邮箱等缓存对应用户的信息,这时候我们就要使用@Caching。例: @Caching(put = { @CachePut(value = &quot;user&quot;, key = &quot;#user.id&quot;), @CachePut(value = &quot;user&quot;, key = &quot;#user.username&quot;), @CachePut(value = &quot;user&quot;, key = &quot;#user.email&quot;) }) public User getUserInfo(User user){ ... return user; } 项目结构图示 引入所需依赖 &lt;!-- redis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- lettuce pool --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- aop 本项目中为了方便记录日志 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- SpringBoot Web容器 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- lombok 工具类--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;!-- 单元测试依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.junit.vintage&lt;/groupId&gt; &lt;artifactId&gt;junit-vintage-engine&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; 配置application.yml spring: # redis 配置 redis: # 地址 host: localhost # 端口，默认为6379 port: 6379 # 密码 password: # 连接超时时间 timeout: 10s lettuce: pool: # 连接池中的最小空闲连接 min-idle: 0 # 连接池中的最大空闲连接 max-idle: 8 # 连接池的最大数据库连接数 max-active: 8 # #连接池最大阻塞等待时间（使用负值表示没有限制） max-wait: -1ms 添加项目配置信息 创建redis配置类 import org.springframework.cache.annotation.EnableCaching; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.data.redis.connection.RedisConnectionFactory; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer; import org.springframework.data.redis.serializer.StringRedisSerializer; import com.fasterxml.jackson.annotation.JsonAutoDetect; import com.fasterxml.jackson.annotation.PropertyAccessor; import com.fasterxml.jackson.databind.ObjectMapper; /** * redis配置类 * @author ludangxin */ @Configuration @EnableCaching public class RedisConfig { @Bean @SuppressWarnings(&quot;all&quot;) public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) { RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;String, Object&gt;(); template.setConnectionFactory(factory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); StringRedisSerializer stringRedisSerializer = new StringRedisSerializer(); // key采用String的序列化方式 template.setKeySerializer(stringRedisSerializer); // hash的key也采用String的序列化方式 template.setHashKeySerializer(stringRedisSerializer); // value序列化方式采用jackson template.setValueSerializer(jackson2JsonRedisSerializer); // hash的value序列化方式采用jackson template.setHashValueSerializer(jackson2JsonRedisSerializer); template.afterPropertiesSet(); return template; } } 创建redis util /** * spring redis 工具类 * * @author ludangxin **/ @SuppressWarnings(value = { &quot;unchecked&quot;, &quot;rawtypes&quot; }) @Component public class RedisUtil { @Autowired public RedisTemplate redisTemplate; /** * 缓存基本的对象，Integer、String、实体类等 * * @param key 缓存的键值 * @param value 缓存的值 * @return 缓存的对象 */ public &lt;T&gt; ValueOperations&lt;String, T&gt; setCacheObject(String key, T value) { ValueOperations&lt;String, T&gt; operation = redisTemplate.opsForValue(); operation.set(key, value); return operation; } /** * 缓存基本的对象，Integer、String、实体类等 * * @param key 缓存的键值 * @param value 缓存的值 * @param timeout 时间 * @param timeUnit 时间颗粒度 * @return 缓存的对象 */ public &lt;T&gt; ValueOperations&lt;String, T&gt; setCacheObject(String key, T value, Integer timeout, TimeUnit timeUnit) { ValueOperations&lt;String, T&gt; operation = redisTemplate.opsForValue(); operation.set(key, value, timeout, timeUnit); return operation; } /** * 获得缓存的基本对象。 * * @param key 缓存键值 * @return 缓存键值对应的数据 */ public &lt;T&gt; T getCacheObject(String key) { ValueOperations&lt;String, T&gt; operation = redisTemplate.opsForValue(); return operation.get(key); } /** * 删除单个对象 * * @param key */ public void deleteObject(String key) { redisTemplate.delete(key); } /** * 删除集合对象 * * @param collection */ public void deleteObject(Collection collection) { redisTemplate.delete(collection); } /** * 缓存List数据 * * @param key 缓存的键值 * @param dataList 待缓存的List数据 * @return 缓存的对象 */ public &lt;T&gt; ListOperations&lt;String, T&gt; setCacheList(String key, List&lt;T&gt; dataList) { ListOperations listOperation = redisTemplate.opsForList(); if (null != dataList) { int size = dataList.size(); for (int i = 0; i &lt; size; i++) { listOperation.leftPush(key, dataList.get(i)); } } return listOperation; } /** * 获得缓存的list对象 * * @param key 缓存的键值 * @return 缓存键值对应的数据 */ public &lt;T&gt; List&lt;T&gt; getCacheList(String key) { List&lt;T&gt; dataList = new ArrayList&lt;T&gt;(); ListOperations&lt;String, T&gt; listOperation = redisTemplate.opsForList(); Long size = listOperation.size(key); for (int i = 0; i &lt; size; i++) { dataList.add(listOperation.index(key, i)); } return dataList; } /** * 缓存Set * * @param key 缓存键值 * @param dataSet 缓存的数据 * @return 缓存数据的对象 */ public &lt;T&gt; BoundSetOperations&lt;String, T&gt; setCacheSet(String key, Set&lt;T&gt; dataSet) { BoundSetOperations&lt;String, T&gt; setOperation = redisTemplate.boundSetOps(key); Iterator&lt;T&gt; it = dataSet.iterator(); while (it.hasNext()) { setOperation.add(it.next()); } return setOperation; } /** * 获得缓存的set * * @param key * @return */ public &lt;T&gt; Set&lt;T&gt; getCacheSet(String key) { Set&lt;T&gt; dataSet = new HashSet&lt;T&gt;(); BoundSetOperations&lt;String, T&gt; operation = redisTemplate.boundSetOps(key); dataSet = operation.members(); return dataSet; } /** * 缓存Map * * @param key * @param dataMap * @return */ public &lt;T&gt; HashOperations&lt;String, String, T&gt; setCacheMap(String key, Map&lt;String, T&gt; dataMap) { HashOperations hashOperations = redisTemplate.opsForHash(); if (null != dataMap) { for (Map.Entry&lt;String, T&gt; entry : dataMap.entrySet()) { hashOperations.put(key, entry.getKey(), entry.getValue()); } } return hashOperations; } /** * 获得缓存的Map * * @param key * @return */ public &lt;T&gt; Map&lt;String, T&gt; getCacheMap(String key) { Map&lt;String, T&gt; map = redisTemplate.opsForHash().entries(key); return map; } /** * 获得缓存的基本对象列表 * * @param pattern 字符串前缀 * @return 对象列表 */ public Collection&lt;String&gt; keys(String pattern) { return redisTemplate.keys(pattern); } } 创建 aop log 切面 方便记录日志 import lombok.extern.slf4j.Slf4j; import org.aspectj.lang.JoinPoint; import org.aspectj.lang.annotation.After; import org.aspectj.lang.annotation.Aspect; import org.aspectj.lang.annotation.Pointcut; import org.springframework.stereotype.Component; /** * 设置日志切面 * @author ludangxin */ @Slf4j @Aspect @Component public class LogAspect { @Pointcut(&quot;execution(public * com.ldx.springboot.service.impl.UserServiceImpl.*(..))&quot;)//切入点描述 public void userServiceLog(){}//签名，可以理解成这个切入点的一个名称 @After(&quot;userServiceLog()&quot;) //在切入点的方法run之前要干的 public void logBeforeController(JoinPoint joinPoint) { //下面这个getSignature().getDeclaringTypeName()是获取包+类名的 然后后面的joinPoint.getSignature.getName()获取了方法名 log.info(&quot;################执行方法 : &quot; + joinPoint.getSignature().getDeclaringTypeName() + &quot;.&quot; + joinPoint.getSignature().getName()); } } 创建缓存常量信息 public class CacheConstant { /** 用户信息cache */ public static final String USER_CACHE_NAME = &quot;user_cache&quot;; /** 用户cache key 前缀 */ public static final String USER_CACHE_KEY_PREFIX = &quot;user_&quot;; } 创建实体类 import lombok.AllArgsConstructor; import lombok.Data; import lombok.NoArgsConstructor; import java.io.Serializable; @Data @AllArgsConstructor @NoArgsConstructor public class User implements Serializable { private static final long serialVersionUID = 1L; private int id; private String name; private String sex; private int age; private double height; } 创建service package com.ldx.springboot.service; import com.ldx.springboot.model.User; import java.util.List; /** * 用户管理 * @author ludangxin */ public interface UserService { /** * 查询所有用户信息 * @return */ List&lt;User&gt; selectAll(); /** * 根据名称模糊查询 * @param name * @return */ List&lt;User&gt; selectByNameLike(String name); /** * 根据id查询用户信息 * @param id * @return */ User getById(int id); /** * 新增用户信息 * @param user * @return */ List&lt;User&gt; add(User user); /** * 更新用户信息 * @param user * @return */ List&lt;User&gt; updateById(User user); /** * 根据id删除用户信息 * @return */ List&lt;User&gt; deleteById(int id); /** * 删除全部用户信息 * @return */ void deleteAll(); } 创建实现类 package com.ldx.springboot.service.impl; import com.ldx.springboot.constant.CacheConstant; import com.ldx.springboot.model.User; import com.ldx.springboot.service.UserService; import lombok.extern.slf4j.Slf4j; import org.springframework.cache.annotation.*; import org.springframework.stereotype.Service; import java.util.ArrayList; import java.util.Iterator; import java.util.List; import java.util.stream.Collectors; /** * 用户管理实现类 * @author ludangxin */ @Slf4j @CacheConfig(cacheNames = CacheConstant.USER_CACHE_NAME) @Service(value = &quot;userService&quot;) public class UserServiceImpl implements UserService { //数据源 static List&lt;User&gt; users = new ArrayList&lt;&gt;(); static{ User user1 = new User(1,&quot;张三&quot;,&quot;男&quot;,18,178.5); User user2 = new User(2,&quot;李四&quot;,&quot;男&quot;,16,172.3); User user3 = new User(3,&quot;王五&quot;,&quot;男&quot;,22,180); User user4 = new User(4,&quot;王麻子&quot;,&quot;男&quot;,33,185); User user5 = new User(5,&quot;小红&quot;,&quot;女&quot;,18,160); User user6 = new User(6,&quot;小绿&quot;,&quot;女&quot;,17,160); User user7 = new User(7,&quot;小蓝&quot;,&quot;女&quot;,19,160); users.add(user1); users.add(user2); users.add(user3); users.add(user4); users.add(user5); users.add(user6); users.add(user7); } @Cacheable(key = &quot;'&quot;+CacheConstant.USER_CACHE_KEY_PREFIX+&quot;all'&quot;) @Override public List&lt;User&gt; selectAll() { return users; } @Cacheable(key = &quot;'&quot;+CacheConstant.USER_CACHE_KEY_PREFIX+&quot;'+#name&quot;) @Override public List&lt;User&gt; selectByNameLike(String name) { List&lt;User&gt; listUser = users.stream().filter(obj -&gt; obj.getName().contains(name)).collect(Collectors.toList()); return listUser; } @Cacheable(key = &quot;'&quot;+CacheConstant.USER_CACHE_KEY_PREFIX+&quot;'+#id&quot;) @Override public User getById(int id) { User user = users.stream().filter(obj -&gt; obj.getId() == id).findFirst().get(); return user; } @CachePut(key = &quot;'&quot;+CacheConstant.USER_CACHE_KEY_PREFIX+&quot;all'&quot;) @Override public List&lt;User&gt; add(User user) { users.add(user); return users; } @Caching(put = {@CachePut(key = &quot;'&quot;+CacheConstant.USER_CACHE_KEY_PREFIX+&quot;all'&quot;)}, evict = {@CacheEvict(key = &quot;'&quot;+CacheConstant.USER_CACHE_KEY_PREFIX+&quot;'+#user.id&quot;)} ) @Override public List&lt;User&gt; updateById(User user) { for (int i = 0; i &lt; users.size(); i++) { if(users.get(i).getId() == user.getId()){ users.set(i,user); } } return users; } @Caching(put = {@CachePut(key = &quot;'&quot;+CacheConstant.USER_CACHE_KEY_PREFIX+&quot;all'&quot;)}, evict = {@CacheEvict(key= &quot;'&quot;+CacheConstant.USER_CACHE_KEY_PREFIX+&quot;'+#id&quot;)} ) @Override public List&lt;User&gt; deleteById(int id) { Iterator&lt;User&gt; iterator = users.iterator(); while(iterator.hasNext()) { User user = iterator.next(); if(user.getId() == id){ iterator.remove(); } } return users; } @CacheEvict(allEntries = true) @Override public void deleteAll() { users = new ArrayList&lt;&gt;(); } } 创建测试类 import com.ldx.springboot.model.User; import lombok.extern.slf4j.Slf4j; import org.junit.jupiter.api.Test; import org.junit.runner.RunWith; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.context.junit4.SpringRunner; import javax.annotation.Resource; import java.util.List; @Slf4j @RunWith(SpringRunner.class) @SpringBootTest class UserServiceTest { @Resource(name = &quot;userService&quot;) UserService userService; @Test void selectAll() { List&lt;User&gt; users = userService.selectAll(); users.forEach(System.out::println); } @Test void selectByNameLike() { String keywork = &quot;小&quot;; List&lt;User&gt; users = userService.selectByNameLike(keywork); users.forEach(System.out::println); } @Test void getById() { int id = 3; User user = userService.getById(id); log.info(user.toString()); } @Test void add() { User user = new User(6,&quot;小粉&quot;,&quot;女&quot;,16,155); userService.add(user); selectAll(); } @Test void updateById() { User user = new User(3,&quot;小粉&quot;,&quot;女&quot;,16,155); userService.updateById(user); selectAll(); } @Test void deleteById() { userService.deleteById(5); } @Test void deleteAll() { userService.deleteAll(); } } redis 安装 安装gcc 由于 redis 是用 C 语言开发，安装之前必先确认是否安装 gcc 环境（gcc -v），如果没有安装，执行以下命令进行安装 yum install -y gcc 下载并解压安装包 wget http://download.redis.io/releases/redis-5.0.3.tar.gz tar -zxvf redis-5.0.3.tar.gz 执行编译 cd redis-5.0.3 make 安装并指定安装目录 make install PREFIX=/usr/local/redis 启动服务 前台启动 cd /usr/local/redis/bin/ ./redis-server 后台启动 从redis的源码目录中复制redis.conf到redis的安装目录 cp /usr/local/redis-5.0.3/redis.conf /usr/local/redis/bin/ 修改redis.conf 文件，把 daemonize no 改为 daemonize yes vi redis.conf ################################# GENERAL ##################################### # By default Redis does not run as a daemon. Use 'yes' if you need it. # Note that Redis will write a pid file in /var/run/redis.pid when daemonized. daemonize yes 后台启动 ./redis-server redis.conf # 查看redis进程状态 ps -ef | grep redis 设置开机启动 添加开机启动服务 vi /etc/systemd/system/redis.service 添加以下内容 [Unit] Description=redis-server After=network.target [Service] Type=forking ExecStart=/usr/local/redis/bin/redis-server /usr/local/redis/bin/redis.conf PrivateTmp=true [Install] WantedBy=multi-user.target 注意 : ExecStart配置成自己的路径 设置开机启动 systemctl daemon-reload systemctl start redis.service systemctl enable redis.service 创建redis命令软链接 ln -s /usr/local/redis/bin/redis-cli /usr/bin/redis 测试 直接输入redis [root@iZ2ze ~]# redis 127.0.0.1:6379&gt; 服务操作命令 systemctl start redis.service #启动redis服务 systemctl stop redis.service #停止redis服务 systemctl restart redis.service #重新启动服务 systemctl status redis.service #查看服务当前状态 systemctl enable redis.service #设置开机自启动 systemctl disable redis.service #停止开机自启动 缓存雪崩 缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。 解决方案 缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。 或者设置热点数据永远不过期，有更新操作就更新缓存就好了（比如运维更新了首页商品，那你刷下缓存就完事了，不要设置过期时间），电商首页的数据也可以用这个操作，保险。 缓存击穿 对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。 缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。 解决方案 设置热点数据永远不过期或使用互斥锁(mutex key) 业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。 SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。 缓存穿透 缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。 解决方案 布隆过滤对所有的可能查询的参数以hash形式存储,在控制器层先进行校验,不符合则丢弃,从而避免了对底层存储系统的查询压力。bloomfilter就类似于一个hash set，用于快速判某个元素是否存在于集合中，其典型的应用场景就是快速判断一个key是否存在于某容器，不存在就直接返回。举例:将真实正确Id在添加完成之后便加入到过滤器当中，每次再进行查询时，先确认要查询的Id是否在过滤器中，如果不在，则说明Id为非法Id。 缓存空对象当从数据库查询不到值，就把参数和控制缓存起来，设置一个简短的过期时间(因为缓存是需要内存的，如果有过多空值key，占用内存多),在该时间段如果有携带此参数再次请求，就可以直接返回。可能导致该段时间缓存层和数据库数据不一致，对于需要保持一致性的业务有影响。 什么是多路I/O复用模型? 通俗易懂的例子: 假设你是一个老师，让30个学生解答一道题目，然后检查学生做的是否正确，你有下面几个选择： 第一种选择：按顺序逐个检查，先检查A，然后是B，之后是C、D。。。这中间如果有一个学生卡主，全班都会被耽误。这种模式就好比，你用循环挨个处理socket，根本不具有并发能力。 第二种选择：你创建30个分身，每个分身检查一个学生的答案是否正确。 这种类似于为每一个用户创建一个进程或者线程处理连接。 第三种选择，你站在讲台上等，谁解答完谁举手。这时C、D举手，表示他们解答问题完毕，你下去依次检查C、D的答案，然后继续回到讲台上等。此时E、A又举手，然后去处理E和A。。。 这种就是IO复用模型，Linux下的select、poll和epoll就是干这个的。将用户socket对应的fd注册进epoll，然后epoll帮你监听哪些socket上有消息到达，这样就避免了大量的无用操作。此时的socket应该采用非阻塞模式。这样，整个过程只在调用select、poll、epoll这些调用的时候才会阻塞，收发客户消息是不会阻塞的，整个进程或者线程就被充分利用起来，这就是事件驱动，所谓的reactor模式。 转自柴小猫 再次加深理解 首先，要从你常用的IO操作谈起，比如read和write，通常IO操作都是阻塞I/O的，也就是说当你调用read时，如果没有数据收到，那么线程或者进程就会被挂起，直到收到数据。 这样，当服务器需要处理1000个连接的的时候，而且只有很少连接忙碌的，那么会需要1000个线程或进程来处理1000个连接，而1000个线程大部分是被阻塞起来的。由于CPU的核数或超线程数一般都不大，比如4,8,16,32,64,128，比如4个核要跑1000个线程，那么每个线程的时间槽非常短，而线程切换非常频繁。 这样是有问题的： 线程是有内存开销的，1个线程可能需要512K（或2M）存放栈，那么1000个线程就要512M（或2G）内 存。 线程的切换，或者说上下文切换是有CPU开销的，当大量时间花在上下文切换的时候，分配给真正的操作的CPU就要少很多。 那么，我们就要引入非阻塞I/O的概念，非阻塞IO很简单，通过fcntl（POSIX）或ioctl（Unix）设为非阻塞模式，这时，当你调用read时，如果有数据收到，就返回数据，如果没有数据收到，就立刻返回一个错误，如EWOULDBLOCK。这样是不会阻塞线程了，但是你还是要不断的轮询来读取或写入。 于是，我们需要引入IO多路复用的概念。多路复用是指使用一个线程来检查多个文件描述符（Socket）的就绪状态，比如调用select和poll函数，传入多个文件描述符，如果有一个文件描述符就绪，则返回，否则阻塞直到超时。得到就绪状态后进行真正的操作可以在同一个线程里执行，也可以启动线程执行（比如使用线程池）。 这样在处理1000个连接时，只需要1个线程监控就绪状态，对就绪的每个连接开一个线程处理就可以了，这样需要的线程数大大减少，减少了内存开销和上下文切换的CPU开销。 转自用心阁 ","link":"http://blog.ludangxin.club/post/springboot-ji-cheng-redis/"},{"title":"Docker","content":"为什么需要 docker 概述 作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势。 更高效的利用系统资源 由于容器不需要进行硬件虚拟以及运行完整操作系统等额外开销，Docker 对系统资源的利用率更高。无论是应用执行速度、内存损耗或者文件存储速度，都要比传统虚拟机技术更高效。因此，相比虚拟机技术，一个相同配置的主机，往往可以运行更多数量的应用。 更快速的启动时间 传统的虚拟机技术启动应用服务往往需要数分钟，而 Docker 容器应用，由于直接运行于宿主内核，无需启动完整的操作系统，因此可以做到秒级、甚至毫秒级的启动时间。大大的节约了开发、测试、部署的时间。 一致的运行环境 开发过程中一个常见的问题是环境一致性问题。由于开发环境、测试环境、生产环境不一致，导致有些 bug 并未在开发过程中被发现。而 Docker 的镜像提供了除内核外完整的运行时环境，确保了应用运行环境一致性，从而不会再出现 「这段代码在我机器上没问题啊」 这类问题。 持续交付和部署 对开发和运维(DevOps)人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。 使用 Docker 可以通过定制应用镜像来实现持续集成、持续交付、部署。开发人员可以通过 Dockerfile 来进行镜像构建，并结合持续集成(Continuous Integration)系统进行集成测试，而运维人员则可以直接在生产环境中快速部署该镜像，甚至结合 持续部署(Continuous Delivery/Deployment) 系统进行自动部署。 而且使用 Dockerfile 使镜像构建透明化，不仅仅开发团队可以理解应用运行环境，也方便运维团队理解应用运行所需条件，帮助更好的生产环境中部署该镜像。 更轻松的迁移 由于 Docker 确保了执行环境的一致性，使得应用的迁移更加容易。Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。因此用户可以很轻易的将在一个平台上运行的应用，迁移到另一个平台上，而不用担心运行环境的变化导致应用无法正常运行的情况。 更轻松的维护和扩展 Docker 使用的分层存储以及镜像的技术，使得应用重复部分的复用更为容易，也使得应用的维护更新更加简单，基于基础镜像进一步扩展镜像也变得非常简单。此外，Docker 团队同各个开源项目团队一起维护了一大批高质量的官方镜像，既可以直接在生产环境使用，又可以作为基础进一步定制，大大的降低了应用服务的镜像制作成本。 对比传统虚拟机总结 特性 容器 虚拟机 启动 秒级 分钟级 硬盘使用 一般为 MB 一般为 GB 性能 接近原生 弱于 系统支持量 单机支持上千个容器 一般几十个 安装docker Ubuntu apt-get remove docker docker-engine docker.io containerd runc : 卸载旧版本docker apt-get update: 更新数据源 apt-get -y install apt-transport-https ca-certificates curl software-properties-common: 安装所需依赖 curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -:安装GPG证书(防止下载时被人篡改) add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot; : 新增数据源lsb_release -cs为系统变量,即当前系统的codeName apt-get update &amp;&amp; apt-get install -y docker-ce: 更新并安装docker CE docker version:验证安装是否成功 其它安装方法 安装命令 sudo apt install docker.io 解决普通用户不能直接使用 docker 命令 docker ps Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.39/containers/json: dial unix /var/run/docker.sock: connect: permission denied # 创建 docker 用户组 sudo groupadd docker # 添加当前用户到 docker 组 sudo usermod -aG docker $USER # 重启 docker sudo systemctl restart docker newgrp - docker # 重启系统 sudo reboo 配置docker镜像加速器 阿里云加速器(推荐) 阿里云docker镜像服务 配置加速器 一配置阿里云加速器为例,首先登陆阿里云,搜索 容器镜像服务 找到专属加速器 通过修改daemon配置文件etc/docker/daemon.json来使用加速器 sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF' { &quot;registry-mirrors&quot;: [&quot;https://rwlvh3oh.mirror.aliyuncs.com&quot;] } EOF # 重启docker sudo systemctl daemon-reload sudo systemctl restart docker 验证配置是否成功 docker info # 输出内容如下 查看 Registry Mirrors Client: Debug Mode: false Server: Containers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 0 Server Version: 19.03.8 Storage Driver: overlay2 Backing Filesystem: &lt;unknown&gt; Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins: Volume: local Network: bridge host ipvlan macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog Swarm: inactive Runtimes: runc Default Runtime: runc Init Binary: docker-init containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd init version: fec3683 Security Options: apparmor seccomp Profile: default Kernel Version: 4.15.0-91-generic Operating System: Ubuntu 18.04.4 LTS OSType: linux Architecture: x86_64 CPUs: 2 Total Memory: 1.924GiB Name: ubuntu ID: ZGXE:UIHK:ZE57:G66R:37US:RT7C:CPHN:IS7Y:AAIG:POEL:UOHA:DBQ3 Docker Root Dir: /var/lib/docker Debug Mode: false Registry: https://index.docker.io/v1/ Labels: Experimental: false Insecure Registries: 127.0.0.0/8 Registry Mirrors: https://rwlvh3oh.mirror.aliyuncs.com/ Live Restore Enabled: false docker 概述 Docker 引擎 Docker 引擎是一个包含以下主要组件的客户端服务器应用程序。 一种服务器，它是一种称为守护进程并且长时间运行的程序。 REST API 用于指定程序可以用来与守护进程通信的接口，并指示它做什么。 一个有命令行界面 (CLI) 工具的客户端。 Docker 架构 Docker 使用客户端 - 服务器 (C/S) 架构模式，使用远程 API 来管理和创建 Docker 容器。 Docker 容器通过 Docker 镜像来创建。 容器与镜像的关系类似于面向对象编程中的对象与类。 Docker 面向对象 容器 对象 镜像 类 标题 说明 镜像(Images) Docker 镜像是用于创建 Docker 容器的模板。 容器(Container) 容器是独立运行的一个或一组应用。 客户端(Client) Docker 客户端通过命令行或者其他工具使用 Docker API https://docs.docker.com/reference/api/docker_remote_api 与 Docker 的守护进程通信。 主机(Host) 一个物理或者虚拟的机器用于执行 Docker 守护进程和容器。 仓库(Registry) Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库。Docker Hubhttps://hub.docker.com提供了庞大的镜像集合供使用。 Docker Machine Docker Machine是一个简化Docker安装的命令行工具，通过一个简单的命令行即可在相应的平台上安装Docker，比如VirtualBox、 Digital Ocean、Microsoft Azure。 操作镜像 获取镜像 之前提到过，Docker Hub上有大量的高质量的镜像可以用，这里我们就说一下怎么获取这些镜像。 从 Docker 镜像仓库获取镜像的命令是 docker pull。其命令格式为： docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] 具体的选项可以通过 docker pull --help 命令看到，这里我们说一下镜像名称的格式。 镜像仓库地址： 地址的格式一般是 &lt;域名/IP&gt;[:端口号]。默认地址是 Docker Hub。 仓库名： 如之前所说，这里的仓库名是两段式名称，即 &lt;用户名&gt;/&lt;软件名&gt;。对于 Docker Hub，如果不给出用户名，则默认为 library，也就是官方镜像。 docker pull nginx # 输出如下 Using default tag: latest latest: Pulling from library/nginx fc7181108d40: Pull complete c4277fc40ec2: Pull complete 780053e98559: Pull complete Digest: sha256:bdbf36b7f1f77ffe7bd2a32e59235dff6ecf131e3b6b5b96061c652f30685f3a Status: Downloaded newer image for nginx:latest 列出镜像 要想列出已经下载下来的镜像，可以使用 docker image ls 命令。 docker image ls # 输出如下 REPOSITORY TAG IMAGE ID CREATED SIZE redis latest 5f515359c7f8 5 days ago 183 MB nginx latest 05a60462f8ba 5 days ago 181 MB mongo 3.2 fe9198c04d62 5 days ago 342 MB &lt;none&gt; &lt;none&gt; 00285df0df87 5 days ago 342 MB ubuntu 16.04 f753707788c5 4 weeks ago 127 MB ubuntu latest f753707788c5 4 weeks ago 127 MB ubuntu 14.04 1e0c3dd64ccd 4 weeks ago 188 MB 列表包含了 仓库名、标签、镜像 ID、创建时间 以及 所占用的空间。 其中仓库名、标签在之前的基础概念章节已经介绍过了。镜像 ID 则是镜像的唯一标识，一个镜像可以对应多个标签。因此，在上面的例子中，我们可以看到 ubuntu:16.04 和 ubuntu:latest 拥有相同的 ID，因为它们对应的是同一个镜像。 镜像体积 如果仔细观察，会注意到，这里标识的所占用空间和在 Docker Hub 上看到的镜像大小不同。比如，ubuntu:16.04 镜像大小，在这里是 127 MB，但是在 Docker Hub 显示的却是 50 MB。这是因为 Docker Hub 中显示的体积是压缩后的体积。在镜像下载和上传过程中镜像是保持着压缩状态的，因此 Docker Hub 所显示的大小是网络传输中更关心的流量大小。而 docker image ls 显示的是镜像下载到本地后，展开的大小，准确说，是展开后的各层所占空间的总和，因为镜像到本地后，查看空间的时候，更关心的是本地磁盘空间占用的大小。 另外一个需要注意的问题是，docker image ls 列表中的镜像体积总和并非是所有镜像实际硬盘消耗。由于 Docker 镜像是多层存储结构，并且可以继承、复用，因此不同镜像可能会因为使用相同的基础镜像，从而拥有共同的层。由于 Docker 使用 Union FS，相同的层只需要保存一份即可，因此实际镜像硬盘占用空间很可能要比这个列表镜像大小的总和要小的多。 你可以通过以下命令来便捷的查看镜像、容器、数据卷所占用的空间。 docker system df # 输出如下 TYPE TOTAL ACTIVE SIZE RECLAIMABLE Images 24 0 1.992GB 1.992GB (100%) Containers 1 0 62.82MB 62.82MB (100%) Local Volumes 9 0 652.2MB 652.2MB (100%) Build Cache 0B 0B 虚悬镜像 上面的镜像列表中，还可以看到一个特殊的镜像，这个镜像既没有仓库名，也没有标签，均为 &lt;none&gt; &lt;none&gt; &lt;none&gt; 00285df0df87 5 days ago 342 MB 这个镜像原本是有镜像名和标签的，原来为 mongo:3.2，随着官方镜像维护，发布了新版本后，重新 docker pull mongo:3.2 时，mongo:3.2 这个镜像名被转移到了新下载的镜像身上，而旧的镜像上的这个名称则被取消，从而成为了 &lt;none&gt;。除了 docker pull 可能导致这种情况，docker build 也同样可以导致这种现象。由于新旧镜像同名，旧镜像名称被取消，从而出现仓库名、标签均为 &lt;none&gt; 的镜像。这类无标签镜像也被称为 虚悬镜像(dangling image) ，可以用下面的命令专门显示这类镜像： docker image ls -f dangling=true # 输出如下 REPOSITORY TAG IMAGE ID CREATED SIZE &lt;none&gt; &lt;none&gt; 00285df0df87 5 days ago 342 MB 一般来说，虚悬镜像已经失去了存在的价值，是可以随意删除的，可以用下面的命令删除。 docker image prune 中间层镜像 为了加速镜像构建、重复利用资源，Docker 会利用 中间层镜像。所以在使用一段时间后，可能会看到一些依赖的中间层镜像。默认的 docker image ls 列表中只会显示顶层镜像，如果希望显示包括中间层镜像在内的所有镜像的话，需要加 -a 参数。 docker image ls -a 这样会看到很多无标签的镜像，与之前的虚悬镜像不同，这些无标签的镜像很多都是中间层镜像，是其它镜像所依赖的镜像。这些无标签镜像不应该删除，否则会导致上层镜像因为依赖丢失而出错。实际上，这些镜像也没必要删除，因为之前说过，相同的层只会存一遍，而这些镜像是别的镜像的依赖，因此并不会因为它们被列出来而多存了一份，无论如何你也会需要它们。只要删除那些依赖它们的镜像后，这些依赖的中间层镜像也会被连带删除。 删除镜像 如果要删除本地的镜像，可以使用 docker image rm 命令，其格式为： docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...] 用 ID、镜像名、摘要删除镜像 其中，&lt;镜像&gt; 可以是 镜像短 ID、镜像长 ID、镜像名 或者 镜像摘要。 比如我们有这么一些镜像： docker image ls # 输出如下 REPOSITORY TAG IMAGE ID CREATED SIZE centos latest 0584b3d2cf6d 3 weeks ago 196.5 MB redis alpine 501ad78535f0 3 weeks ago 21.03 MB docker latest cf693ec9b5c7 3 weeks ago 105.1 MB nginx latest e43d811ce2f4 5 weeks ago 181.5 MB 我们可以用镜像的完整 ID，也称为 长 ID，来删除镜像。使用脚本的时候可能会用长 ID，但是人工输入就太累了，所以更多的时候是用 短 ID 来删除镜像。docker image ls 默认列出的就已经是短 ID 了，一般取前 3 个字符以上，只要足够区分于别的镜像就可以了。 比如这里，如果我们要删除 redis:alpine 镜像，可以执行： docker image rm 501 # 输出如下 Untagged: redis:alpine Untagged:redis@sha256:f1ed3708f538b537eb9c2a7dd50dc90a706f7debd7e1196c9264edeea521a86dDeleted:sha256:501ad78535f015d88872e13fa87a828425117e3d28075d0c117932b05bf189b7 Deleted:sha256:96167737e29ca8e9d74982ef2a0dda76ed7b430da55e321c071f0dbff8c2899b Deleted:sha256:32770d1dcf835f192cafd6b9263b7b597a1778a403a109e2cc2ee866f74adf23 Deleted:sha256:127227698ad74a5846ff5153475e03439d96d4b1c7f2a449c7a826ef74a2d2fa Deleted:sha256:1333ecc582459bac54e1437335c0816bc17634e131ea0cc48daa27d32c75eab3 Deleted: sha256:4fc455b921edf9c4aea207c51ab39b10b06540c8b4825ba57b3feed1668fa7c7 我们也可以用镜像名，也就是 &lt;仓库名&gt;:&lt;标签&gt;，来删除镜像。 docker image rm centos # 输出如下 Untagged: centos:latest Untagged:centos@sha256:b2f9d1c0ff5f87a4743104d099a3d561002ac500db1b9bfa02a783a46e0d366c Deleted:sha256:0584b3d2cf6d235ee310cf14b54667d889887b838d3f3d3033acd70fc3c48b8a Deleted: sha256:97ca462ad9eeae25941546209454496e1d66749d53dfa2ee32bf1faabd239d38 当然，更精确的是使用 镜像摘要 删除镜像。 docker image ls --digests # 输出如下 REPOSITORY TAG DIGEST IMAGE ID CREATED SIZE node slim sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228 6e0c4c8e3913 3 weeks ago 214 MB docker image rm node@sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228 # 输出如下 Untagged: node@sha256:b4f0e0bdeb578043c1ea6862f0d40cc4afe32a4a582f3be235a3b164422be228 用 docker image ls 命令来配合 像其它可以承接多个实体的命令一样，可以使用 docker image ls -q 来配合使用 docker image rm，这样可以成批的删除希望删除的镜像。我们在“镜像列表”章节介绍过很多过滤镜像列表的方式都可以拿过来使用。 比如，我们需要删除所有仓库名为 redis 的镜像： docker image rm $(docker image ls -q redis) 或者删除所有在 mongo:3.2 之前的镜像： docker image rm $(docker image ls -q -f before=mongo:3.2) 充分利用你的想象力和 Linux 命令行的强大，你可以完成很多非常赞的功能。 扩展阅读 列出部分镜像 不加任何参数的情况下，docker image ls 会列出所有顶级镜像，但是有时候我们只希望列出部分镜像。docker image ls 有好几个参数可以帮助做到这个事情。 根据仓库名列出镜像 docker image ls ubuntu # 输出如下 REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu 16.04 f753707788c5 4 weeks ago 127 MB ubuntu latest f753707788c5 4 weeks ago 127 MB ubuntu 14.04 1e0c3dd64ccd 4 weeks ago 188 MB 列出特定的某个镜像，也就是说指定仓库名和标签 docker image ls ubuntu:16.04 # 输出如下 REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu 16.04 f753707788c5 4 weeks ago 127 MB 除此以外，docker image ls 还支持强大的过滤器参数 --filter，或者简写 -f。之前我们已经看到了使用过滤器来列出虚悬镜像的用法，它还有更多的用法。比如，我们希望看到在 mongo:3.2 之后建立的镜像，可以用下面的命令： docker image ls -f since=mongo:3.2 # 输出如下 REPOSITORY TAG IMAGE ID CREATED SIZE redis latest 5f515359c7f8 5 days ago 183 MB nginx latest 05a60462f8ba 5 days ago 181 MB 想查看某个位置之前的镜像也可以，只需要把 since 换成 before 即可。 此外，如果镜像构建时，定义了 LABEL，还可以通过 LABEL 来过滤。 docker image ls -f label=com.example.version=0.1 以特定格式显示 默认情况下，docker image ls 会输出一个完整的表格，但是我们并非所有时候都会需要这些内容。比如，刚才删除虚悬镜像的时候，我们需要利用 docker image ls 把所有的虚悬镜像的 ID 列出来，然后才可以交给 docker image rm 命令作为参数来删除指定的这些镜像，这个时候就用到了 -q 参数。 docker image ls -q # 输出如下 5f515359c7f8 05a60462f8ba fe9198c04d62 00285df0df87 f753707788c5 f753707788c5 1e0c3dd64ccd --filter 配合 -q 产生出指定范围的 ID 列表，然后送给另一个 docker 命令作为参数，从而针对这组实体成批的进行某种操作的做法在 Docker 命令行使用过程中非常常见，不仅仅是镜像，将来我们会在各个命令中看到这类搭配以完成很强大的功能。因此每次在文档看到过滤器后，可以多注意一下它们的用法。 另外一些时候，我们可能只是对表格的结构不满意，希望自己组织列；或者不希望有标题，这样方便其它程序解析结果等，这就用到了 Go 的模板语法。 比如，下面的命令会直接列出镜像结果，并且只包含镜像 ID 和仓库名： docker image ls --format &quot;{{.ID}}: {{.Repository}}&quot; # 输出如下 5f515359c7f8: redis 05a60462f8ba: nginx fe9198c04d62: mongo 00285df0df87: &lt;none&gt; f753707788c5: ubuntu f753707788c5: ubuntu 1e0c3dd64ccd: ubuntu 或者打算以表格等距显示，并且有标题行，和默认一样，不过自己定义列： docker image ls --format &quot;table {{.ID}}\\t{{.Repository}}\\t{{.Tag}}&quot; # 输出如下 IMAGE ID REPOSITORY TAG 5f515359c7f8 redis latest 05a60462f8ba nginx latest fe9198c04d62 mongo 3.2 00285df0df87 &lt;none&gt; &lt;none&gt; f753707788c5 ubuntu 16.04 f753707788c5 ubuntu latest 1e0c3dd64ccd ubuntu 14.04 操作容器 启动容器 所需要的命令主要为 docker run。例如，下面的命令输出一个 “Hello World”，之后终止容器。 docker run ubuntu:16.04 /bin/echo 'Hello world' Hello world docker run -p 8080:8080 --name myTomcat -d tomcat # 启动一个tomcat(镜像名字) 宿主机端口为8080 容器端口8080 起名为myTomcat 8dd9addeee5960d6818a3744d897a3b2200815f954f0dc0e6f63e647bc1574ea 当利用 docker run 来创建容器时，Docker 在后台运行的标准操作包括： 检查本地是否存在指定的镜像，不存在就从公有仓库下载 利用镜像创建并启动一个容器 分配一个文件系统，并在只读的镜像层外面挂载一层可读写层 从宿主主机配置的网桥接口中桥接一个虚拟接口到容器中去 从地址池配置一个 ip 地址给容器 执行用户指定的应用程序 执行完毕后容器被终止 终止容器 可以使用 docker container stop [container ID or NAMES] 来终止一个运行中的容器。此外，当 Docker 容器中指定的应用终结时，容器也自动终止。 例如对于只启动了一个终端的容器，用户通过 exit 命令或 ctrl + d 来退出终端时，所创建的容器立刻终止。终止状态的容器可以用 docker container ls -a 命令看到。例如 docker container ls -a # 输出如下 CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ba267838cc1b ubuntu:14.04 &quot;/bin/bash&quot; 30 minutes ago Exited (0) About a minute ago trusting_newton 98e5efa7d997 training/webapp:latest &quot;python app.py&quot; About an hour ago Exited (0) 34 minutes ago backstabbing_pike 启动已终止容器 处于终止状态的容器，可以通过 docker container start 命令来重新启动。此外，docker container restart 命令会将一个运行态的容器终止，然后再重新启动它。 docker container start [container ID or NAMES] 守护态运行 更多的时候，需要让 Docker 在后台运行而不是直接把执行命令的结果输出在当前宿主机下。此时，可以通过添加 -d 参数来实现。如果不使用 -d 参数运行容器。 docker run ubuntu:16.04 /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot; # 输出如下 hello world hello world hello world hello world 容器会把输出的结果 (STDOUT) 打印到宿主机上面，如果使用了 -d 参数运行容器。 docker run -d ubuntu:17.10 /bin/sh -c &quot;while true; do echo hello world; sleep 1; done&quot; # 输出如下 77b2dc01fe0f3f1265df143181e7b9af5e05279a884f4776ee75350ea9d8017a 此时容器会在后台运行并不会把输出的结果 (STDOUT) 打印到宿主机上面(输出结果可以用 docker logs 查看)。 注意： 容器是否会长久运行，是和 docker run 指定的命令有关，和 -d 参数无关。 容器日志 要获取容器的输出信息，可以通过 docker container logs 命令。 docker container logs [container ID or NAMES] # 输出如下 hello world hello world hello world 进入容器 在使用 -d 参数时，容器启动后会进入后台。某些时候需要进入容器进行操作，docker exec 命令能让我们以交互的方式进入容器。 docker exec 后边可以跟多个参数，这里主要说明 -i -t 参数。只用 -i 参数时，由于没有分配伪终端，界面没有我们熟悉的 Linux 命令提示符，但命令执行结果仍然可以返回。当 -i -t 参数一起使用时，则可以看到我们熟悉的 Linux 命令提示符。 docker exec -it 69d1 bash root@69d137adef7a:/# 如果从这个 stdin 中 exit，不会导致容器的停止。更多参数说明请使用 docker exec --help 查看。 删除容器 可以使用 docker container rm 来删除一个处于终止状态的容器。例如 docker container rm trusting_newton trusting_newton 如果要删除一个运行中的容器，可以添加 -f 参数。Docker 会发送 SIGKILL 信号给容器。 docker rm -f unruffled_jang:unruffled_jang为容器名,也可以根据容器id删除 清理所有处于终止状态的容器 用 docker container ls -a 命令可以查看所有已经创建的包括终止状态的容器，如果数量太多要一个个删除可能会很麻烦，用下面的命令可以清理掉所有处于终止状态的容器。 docker container prune dockerfile定制镜像 概述 Dockerfile 是一个文本文件，其内包含了一条条的 指令(Instruction)，每一条指令构建一层，因此每一条指令的内容，就是描述该层应当如何构建。 以之前的 Nginx 镜像为例，这次我们使用 Dockerfile 来定制。在一个空白目录中，建立一个文本文件，并命名为 Dockerfile mkdir mynginx cd mynginx touch Dockerfile 其内容为： FROM nginx RUN echo '&lt;h1&gt;Hello, Docker!&lt;/h1&gt;' &gt; /usr/share/nginx/html/index.html 这个 Dockerfile 很简单，一共就两行。涉及到了两条指令，FROM 和 RUN。 FROM 指定基础镜像 所谓定制镜像，那一定是以一个镜像为基础，在其上进行定制。就像我们之前运行了一个 Nginx 镜像的容器，再进行修改一样，基础镜像是必须指定的。而 FROM 就是指定 基础镜像，因此一个 Dockerfile 中 FROM 是必备的指令，并且必须是第一条指令。 除了选择现有镜像为基础镜像外，Docker 还存在一个特殊的镜像，名为 scratch。这个镜像是虚拟的概念，并不实际存在，它表示一个空白的镜像。 FROM scratch 如果你以 scratch 为基础镜像的话，意味着你不以任何镜像为基础，接下来所写的指令将作为镜像第一层开始存在。 不以任何系统为基础，直接将可执行文件复制进镜像的做法并不罕见，比如 swarm、coreos/etcd。对于 Linux 下静态编译的程序来说，并不需要有操作系统提供运行时支持，所需的一切库都已经在可执行文件里了，因此直接 FROM scratch 会让镜像体积更加小巧。使用 Go 语言开发的应用很多会使用这种方式来制作镜像，这也是为什么有人认为 Go 是特别适合容器微服务架构语言的原因之一。 RUN 执行命令 RUN 指令是用来执行命令行命令的。由于命令行的强大能力，RUN 指令在定制镜像时是最常用的指令之一。其格式有两种： shell 格式： RUN &lt;命令&gt;，就像直接在命令行中输入的命令一样。刚才写的 Dockerfile 中的 RUN 指令就是这种格式。 RUN echo '&lt;h1&gt;Hello, Docker!&lt;/h1&gt;' &gt; /usr/share/nginx/html/index.html exec 格式： RUN [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;]，这更像是函数调用中的格式。 既然 RUN 就像 Shell 脚本一样可以执行命令，那么我们是否就可以像 Shell 脚本一样把每个命令对应一个 RUN 呢？比如这样： FROM debian:jessie RUN apt-get update RUN apt-get install -y gcc libc6-dev make RUN wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; RUN mkdir -p /usr/src/redis RUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 RUN make -C /usr/src/redisRUN make -C /usr/src/redis install 之前说过，Dockerfile 中每一个指令都会建立一层，RUN 也不例外。每一个 RUN 的行为，就和刚才我们手工建立镜像的过程一样：新建立一层，在其上执行这些命令，执行结束后，commit 这一层的修改，构成新的镜像。 而上面的这种写法，创建了 7 层镜像。这是完全没有意义的，而且很多运行时不需要的东西，都被装进了镜像里，比如编译环境、更新的软件包等等。结果就是产生非常臃肿、非常多层的镜像，不仅仅增加了构建部署的时间，也很容易出错。这是很多初学 Docker 的人常犯的一个错误。 注意： Union FS 是有最大层数限制的，比如 AUFS，曾经是最大不得超过 42 层，现在是不得超过 127 层。 上面的 Dockerfile 正确的写法应该是这样： FROM debian:jessie RUN buildDeps='gcc libc6-dev make' \\ &amp;&amp; apt-get update \\ &amp;&amp; apt-get install -y $buildDeps \\ &amp;&amp; wget -O redis.tar.gz &quot;http://download.redis.io/releases/redis-3.2.5.tar.gz&quot; \\ &amp;&amp; mkdir -p /usr/src/redis \\ &amp;&amp; tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1 \\ &amp;&amp; make -C /usr/src/redis \\ &amp;&amp; make -C /usr/src/redis install \\ &amp;&amp; rm -rf /var/lib/apt/lists/* \\ &amp;&amp; rm redis.tar.gz \\ &amp;&amp; rm -r /usr/src/redis \\ &amp;&amp; apt-get purge -y --auto-remove $buildDeps 首先，之前所有的命令只有一个目的，就是编译、安装 Redis 可执行文件。因此没有必要建立很多层，这只是一层的事情。因此，这里没有使用很多个 RUN 对一一对应不同的命令，而是仅仅使用一个 RUN 指令，并使用 &amp;&amp; 将各个所需命令串联起来。将之前的 7 层，简化为了 1 层。在撰写 Dockerfile 的时候，要经常提醒自己，这并不是在写 Shell 脚本，而是在定义每一层该如何构建。 并且，这里为了格式化还进行了换行。Dockerfile 支持 Shell 类的行尾添加 \\ 的命令换行方式，以及行首 # 进行注释的格式。良好的格式，比如换行、缩进、注释等，会让维护、排障更为容易，这是一个比较好的习惯。 此外，还可以看到这一组命令的最后添加了清理工作的命令，删除了为了编译构建所需要的软件，清理了所有下载、展开的文件，并且还清理了 apt 缓存文件。这是很重要的一步，我们之前说过，镜像是多层存储，每一层的东西并不会在下一层被删除，会一直跟随着镜像。因此镜像构建时，一定要确保每一层只添加真正需要添加的东西，任何无关的东西都应该清理掉。 很多人初学 Docker 制作出了很臃肿的镜像的原因之一，就是忘记了每一层构建的最后一定要清理掉无关文件。 构建镜像 好了，让我们再回到之前定制的 Nginx 镜像的 Dockerfile 来。现在我们明白了这个 Dockerfile 的内容，那么让我们来构建这个镜像吧。在 Dockerfile 文件所在目录执行： docker build -t nginx:v3 . # 输出如下 Sending build context to Docker daemon 2.048 kB Step 1 : FROM nginx ---&gt; e43d811ce2f4 Step 2 : RUN echo '&lt;h1&gt;Hello, Docker!&lt;/h1&gt;' &gt; /usr/share/nginx/html/index.html ---&gt; Running in 9cdc27646c7b ---&gt; 44aa4490ce2c Removing intermediate container 9cdc27646c7b Successfully built 44aa4490ce2c 从命令的输出结果中，我们可以清晰的看到镜像的构建过程。在 Step 2 中，如同我们之前所说的那样，RUN 指令启动了一个容器 9cdc27646c7b，执行了所要求的命令，并最后提交了这一层 44aa4490ce2c，随后删除了所用到的这个容器 9cdc27646c7b。 这里我们使用了 docker build 命令进行镜像构建。其格式为： docker build [选项] &lt;上下文路径/URL/-&gt; 在这里我们指定了最终镜像的名称 -t nginx:v3，构建成功后，我们可以像之前运行 nginx:v2 那样来运行这个镜像，其结果会和 nginx:v2 一样。 镜像构建上下文 如果注意，会看到 docker build 命令最后有一个 .。. 表示当前目录，而 Dockerfile 就在当前目录，因此不少初学者以为这个路径是在指定 Dockerfile 所在路径，这么理解其实是不准确的。如果对应上面的命令格式，你可能会发现，这是在指定 上下文路径。那么什么是上下文呢？ 首先我们要理解 docker build 的工作原理。Docker 在运行时分为 Docker 引擎（也就是服务端守护进程）和客户端工具。Docker 的引擎提供了一组 REST API，被称为 Docker Remote API，而如 docker 命令这样的客户端工具，则是通过这组 API 与 Docker 引擎交互，从而完成各种功能。因此，虽然表面上我们好像是在本机执行各种 docker 功能，但实际上，一切都是使用的远程调用形式在服务端（Docker 引擎）完成。也因为这种 C/S 设计，让我们操作远程服务器的 Docker 引擎变得轻而易举。 当我们进行镜像构建的时候，并非所有定制都会通过 RUN 指令完成，经常会需要将一些本地文件复制进镜像，比如通过 COPY 指令、ADD 指令等。而 docker build 命令构建镜像，其实并非在本地构建，而是在服务端，也就是 Docker 引擎中构建的。那么在这种客户端/服务端的架构中，如何才能让服务端获得本地文件呢？ 这就引入了上下文的概念。当构建的时候，用户会指定构建镜像上下文的路径，docker build 命令得知这个路径后，会将路径下的所有内容打包，然后上传给 Docker 引擎。这样 Docker 引擎收到这个上下文包后，展开就会获得构建镜像所需的一切文件。 如果在 Dockerfile 中这么写： COPY ./package.json /app/ 这并不是要复制执行 docker build 命令所在的目录下的 package.json，也不是复制 Dockerfile 所在目录下的 package.json，而是复制 上下文（context） 目录下的 package.json。 因此，COPY 这类指令中的源文件的路径都是相对路径。这也是初学者经常会问的为什么 COPY ../package.json /app 或者 COPY /opt/xxxx /app 无法工作的原因，因为这些路径已经超出了上下文的范围，Docker 引擎无法获得这些位置的文件。如果真的需要那些文件，应该将它们复制到上下文目录中去。 现在就可以理解刚才的命令 docker build -t nginx:v3 . 中的这个 .，实际上是在指定上下文的目录，docker build 命令会将该目录下的内容打包交给 Docker 引擎以帮助构建镜像。 如果观察 docker build 输出，我们其实已经看到了这个发送上下文的过程： docker build -t nginx:v3 . # 输出如下 Sending build context to Docker daemon 2.048 kB 理解构建上下文对于镜像构建是很重要的，避免犯一些不应该的错误。比如有些初学者在发现 COPY /opt/xxxx /app 不工作后，于是干脆将 Dockerfile 放到了硬盘根目录去构建，结果发现 docker build 执行后，在发送一个几十 GB 的东西，极为缓慢而且很容易构建失败。那是因为这种做法是在让 docker build 打包整个硬盘，这显然是使用错误。 一般来说，应该会将 Dockerfile 置于一个空目录下，或者项目根目录下。如果该目录下没有所需文件，那么应该把所需文件复制一份过来。如果目录下有些东西确实不希望构建时传给 Docker 引擎，那么可以用 .gitignore 一样的语法写一个 .dockerignore，该文件是用于剔除不需要作为上下文传递给 Docker 引擎的。 那么为什么会有人误以为 . 是指定 Dockerfile 所在目录呢？这是因为在默认情况下，如果不额外指定 Dockerfile 的话，会将上下文目录下的名为 Dockerfile 的文件作为 Dockerfile。 这只是默认行为，实际上 Dockerfile 的文件名并不要求必须为 Dockerfile，而且并不要求必须位于上下文目录中，比如可以用 -f ../Dockerfile.php 参数指定某个文件作为 Dockerfile。 当然，一般大家习惯性的会使用默认的文件名 Dockerfile，以及会将其置于镜像构建上下文目录中。 dockerfile 指令 概述 我们已经介绍了 FROM，RUN，还提及了 COPY, ADD，其实 Dockerfile 功能很强大，它提供了十多个指令。下面我们继续讲解其他的指令。 COPY 格式： COPY &lt;源路径&gt;... &lt;目标路径&gt; COPY [&quot;&lt;源路径1&gt;&quot;,... &quot;&lt;目标路径&gt;&quot;] 和 RUN 指令一样，也有两种格式，一种类似于命令行，一种类似于函数调用。 COPY 指令将从构建上下文目录中 &lt;源路径&gt; 的文件/目录复制到新的一层的镜像内的 &lt;目标路径&gt; 位置。比如： COPY package.json /usr/src/app/ &lt;源路径&gt; 可以是多个，甚至可以是通配符，其通配符规则要满足 Go 的 filepath.Match规则，如： COPY hom* /mydir/ COPY hom?.txt /mydir/ &lt;目标路径&gt; 可以是容器内的绝对路径，也可以是相对于工作目录的相对路径（工作目录可以用 WORKDIR 指令来指定）。目标路径不需要事先创建，如果目录不存在会在复制文件前先行创建缺失目录。 此外，还需要注意一点，使用 COPY 指令，源文件的各种元数据都会保留。比如读、写、执行权限、文件变更时间等。这个特性对于镜像定制很有用。特别是构建相关文件都在使用 Git 进行管理的时候。 ADD ADD 指令和 COPY 的格式和性质基本一致。但是在 COPY 基础上增加了一些功能。 比如 &lt;源路径&gt; 可以是一个 URL，这种情况下，Docker 引擎会试图去下载这个链接的文件放到 &lt;目标路径&gt; 去。下载后的文件权限自动设置为 600，如果这并不是想要的权限，那么还需要增加额外的一层 RUN 进行权限调整，另外，如果下载的是个压缩包，需要解压缩，也一样还需要额外的一层 RUN 指令进行解压缩。所以不如直接使用 RUN 指令，然后使用 wget 或者 curl 工具下载，处理权限、解压缩、然后清理无用文件更合理。因此，这个功能其实并不实用，而且不推荐使用。 如果 &lt;源路径&gt; 为一个 tar 压缩文件的话，压缩格式为 gzip, bzip2 以及 xz 的情况下，ADD 指令将会自动解压缩这个压缩文件到 &lt;目标路径&gt; 去。 在某些情况下，这个自动解压缩的功能非常有用，比如官方镜像 ubuntu 中： FROM scratch ADD ubuntu-xenial-core-cloudimg-amd64-root.tar.gz / 但在某些情况下，如果我们真的是希望复制个压缩文件进去，而不解压缩，这时就不可以使用 ADD 命令了。 在 Docker 官方的 Dockerfile 最佳实践文档 中要求，尽可能的使用 COPY，因为 COPY 的语义很明确，就是复制文件而已，而 ADD 则包含了更复杂的功能，其行为也不一定很清晰。最适合使用 ADD 的场合，就是所提及的需要自动解压缩的场合。 另外需要注意的是，ADD 指令会令镜像构建缓存失效，从而可能会令镜像构建变得比较缓慢。 因此在 COPY 和 ADD 指令中选择的时候，可以遵循这样的原则，所有的文件复制均使用 COPY 指令，仅在需要自动解压缩的场合使用 ADD。 CMD CMD 指令的格式和 RUN 相似，也是两种格式： shell 格式：CMD &lt;命令&gt; exec 格式：CMD [&quot;可执行文件&quot;, &quot;参数1&quot;, &quot;参数2&quot;...] 参数列表格式：CMD [&quot;参数1&quot;, &quot;参数2&quot;...]。在指定了 ENTRYPOINT 指令后，用 CMD 指定具体的参数。 之前介绍容器的时候曾经说过，Docker 不是虚拟机，容器就是进程。既然是进程，那么在启动容器的时候，需要指定所运行的程序及参数。CMD 指令就是用于指定默认的容器主进程的启动命令的。 在运行时可以指定新的命令来替代镜像设置中的这个默认命令，比如，ubuntu 镜像默认的 CMD 是 /bin/bash，如果我们直接 docker run -it ubuntu 的话，会直接进入 bash。我们也可以在运行时指定运行别的命令，如 docker run -it ubuntu cat /etc/os-release。这就是用 cat /etc/os-release 命令替换了默认的 /bin/bash 命令了，输出了系统版本信息。 在指令格式上，一般推荐使用 exec 格式，这类格式在解析时会被解析为 JSON 数组，因此一定要使用双引号 &quot;，而不要使用单引号。 如果使用 shell 格式的话，实际的命令会被包装为 sh -c 的参数的形式进行执行。比如： CMD echo $HOME 在实际执行中，会将其变更为： CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;echo $HOME&quot; ] 这就是为什么我们可以使用环境变量的原因，因为这些环境变量会被 shell 进行解析处理。 提到 CMD 就不得不提容器中应用在前台执行和后台执行的问题。这是初学者常出现的一个混淆。 Docker 不是虚拟机，容器中的应用都应该以前台执行，而不是像虚拟机、物理机里面那样，用 upstart/systemd 去启动后台服务，容器内没有后台服务的概念。 一些初学者将 CMD 写为： CMD service nginx start 然后发现容器执行后就立即退出了。甚至在容器内去使用 systemctl 命令结果却发现根本执行不了。这就是因为没有搞明白前台、后台的概念，没有区分容器和虚拟机的差异，依旧在以传统虚拟机的角度去理解容器。 对于容器而言，其启动程序就是容器应用进程，容器就是为了主进程而存在的，主进程退出，容器就失去了存在的意义，从而退出，其它辅助进程不是它需要关心的东西。 而使用 service nginx start 命令，则是希望 upstart 来以后台守护进程形式启动 nginx 服务。而刚才说了 CMD service nginx start 会被理解为 CMD [ &quot;sh&quot;, &quot;-c&quot;, &quot;service nginx start&quot;]，因此主进程实际上是 sh。那么当 service nginx start 命令结束后，sh 也就结束了，sh 作为主进程退出了，自然就会令容器退出。 正确的做法是直接执行 nginx 可执行文件，并且要求以前台形式运行。比如： CMD [&quot;nginx&quot;, &quot;-g&quot;, &quot;daemon off;&quot;] ENTRYPOINT ENTRYPOINT 的格式和 RUN 指令格式一样，分为 exec 格式和 shell 格式。 ENTRYPOINT 的目的和 CMD 一样，都是在指定容器启动程序及参数。ENTRYPOINT 在运行时也可以替代，不过比 CMD 要略显繁琐，需要通过 docker run 的参数 --entrypoint 来指定。 当指定了 ENTRYPOINT 后，CMD 的含义就发生了改变，不再是直接的运行其命令，而是将 CMD 的内容作为参数传给 ENTRYPOINT 指令，换句话说实际执行时，将变为： &lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 那么有了 CMD 后，为什么还要有 ENTRYPOINT 呢？这种 &lt;ENTRYPOINT&gt; &quot;&lt;CMD&gt;&quot; 有什么好处么？让我们来看几个场景。 场景一：让镜像变成像命令一样使用 假设我们需要一个得知自己当前公网 IP 的镜像，那么可以先用 CMD 来实现： FROM ubuntu:16.04 RUN apt-get update \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; rm -rf /var/lib/apt/lists/* CMD [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://ip.cn&quot; ] 假如我们使用 docker build -t myip . 来构建镜像的话，如果我们需要查询当前公网 IP，只需要执行： docker run myip 当前 IP：61.148.226.66 来自：北京市 联通 嗯，这么看起来好像可以直接把镜像当做命令使用了，不过命令总有参数，如果我们希望加参数呢？比如从上面的 CMD 中可以看到实质的命令是 curl，那么如果我们希望显示 HTTP 头信息，就需要加上 -i 参数。那么我们可以直接加 -i 参数给 docker run myip 么？ docker run myip -i docker: Error response from daemon: invalid header field value &quot;oci runtime error: container_linux.go:247: starting container process caused \\&quot;exec: \\\\\\&quot;-i\\\\\\&quot;: executable file not found in $PATH\\&quot;\\n&quot;. 我们可以看到可执行文件找不到的报错，executable file not found。之前我们说过，跟在镜像名后面的是 command，运行时会替换 CMD 的默认值。因此这里的 -i 替换了原来的 CMD，而不是添加在原来的 curl -s http://ip.cn 后面。而 -i 根本不是命令，所以自然找不到。 那么如果我们希望加入 -i 这参数，我们就必须重新完整的输入这个命令： docker run myip curl -s http://ip.cn -i 这显然不是很好的解决方案，而使用 ENTRYPOINT 就可以解决这个问题。现在我们重新用 ENTRYPOINT 来实现这个镜像： FROM ubuntu:16.04 RUN apt-get update \\ &amp;&amp; apt-get install -y curl \\ &amp;&amp; rm -rf /var/lib/apt/lists/* ENTRYPOINT [ &quot;curl&quot;, &quot;-s&quot;, &quot;http://ip.cn&quot; ] 这次我们再来尝试直接使用 docker run myip -i： docker run myip 当前 IP：61.148.226.66 来自：北京市 联通 docker run myip -i HTTP/1.1 200 OK Server: nginx/1.8.0 Date: Tue, 22 Nov 2016 05:12:40 GMT Content-Type: text/html; charset=UTF-8 Vary: Accept-Encoding X-Powered-By: PHP/5.6.24-1~dotdeb+7.1 X-Cache: MISS from cache-2 X-Cache-Lookup: MISS from cache-2:80 X-Cache: MISS from proxy-2_6 Transfer-Encoding: chunked Via: 1.1 cache-2:80, 1.1 proxy-2_6:8006 Connection: keep-alive当前 IP：61.148.226.66 来自：北京市 联通 可以看到，这次成功了。这是因为当存在 ENTRYPOINT 后，CMD 的内容将会作为参数传给 ENTRYPOINT，而这里 -i 就是新的 CMD，因此会作为参数传给 curl，从而达到了我们预期的效果。 场景二：应用运行前的准备工作 启动容器就是启动主进程，但有些时候，启动主进程前，需要一些准备工作。 比如 mysql 类的数据库，可能需要一些数据库配置、初始化的工作，这些工作要在最终的 mysql 服务器运行之前解决。 此外，可能希望避免使用 root 用户去启动服务，从而提高安全性，而在启动服务前还需要以 root 身份执行一些必要的准备工作，最后切换到服务用户身份启动服务。或者除了服务外，其它命令依旧可以使用 root 身份执行，方便调试等。 这些准备工作是和容器 CMD 无关的，无论 CMD 为什么，都需要事先进行一个预处理的工作。这种情况下，可以写一个脚本，然后放入 ENTRYPOINT 中去执行，而这个脚本会将接到的参数（也就是 &lt;CMD&gt;）作为命令，在脚本最后执行。比如官方镜像 redis 中就是这么做的： FROM alpine:3.4 RUN addgroup -S redis &amp;&amp; adduser -S -G redis redis ENTRYPOINT [&quot;docker-entrypoint.sh&quot;] EXPOSE 6379 CMD [ &quot;redis-server&quot; ] 可以看到其中为了 redis 服务创建了 redis 用户，并在最后指定了 ENTRYPOINT 为 docker-entrypoint.sh 脚本。 #!/bin/sh # allow the container to be started with `--user` if [ &quot;$1&quot; = 'redis-server' -a &quot;$(id -u)&quot; = '0' ]; then chown -R redis . exec su-exec redis &quot;$0&quot; &quot;$@&quot; fi exec &quot;$@&quot; 该脚本的内容就是根据 CMD 的内容来判断，如果是 redis-server 的话，则切换到 redis 用户身份启动服务器，否则依旧使用 root 身份执行。比如： docker run -it redis id uid=0(root) gid=0(root) groups=0(root) ENV 格式有两种： ENV &lt;key&gt; &lt;value&gt; ENV &lt;key1&gt;=&lt;value1&gt; &lt;key2&gt;=&lt;value2&gt;... 这个指令很简单，就是设置环境变量而已，无论是后面的其它指令，如 RUN，还是运行时的应用，都可以直接使用这里定义的环境变量。 ENV VERSION=1.0 DEBUG=on \\ NAME=&quot;Happy Feet&quot; 这个例子中演示了如何换行，以及对含有空格的值用双引号括起来的办法，这和 Shell 下的行为是一致的。 定义了环境变量，那么在后续的指令中，就可以使用这个环境变量。比如在官方 node 镜像 Dockerfile 中，就有类似这样的代码： ENV NODE_VERSION 7.2.0 RUN curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/node-v$NODE_VERSION-linux-x64.tar.xz&quot; \\ &amp;&amp; curl -SLO &quot;https://nodejs.org/dist/v$NODE_VERSION/SHASUMS256.txt.asc&quot; \\ &amp;&amp; gpg --batch --decrypt --output SHASUMS256.txt SHASUMS256.txt.asc \\ &amp;&amp; grep &quot; node-v$NODE_VERSION-linux-x64.tar.xz\\$&quot; SHASUMS256.txt | sha256sum -c - \\ &amp;&amp; tar -xJf &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; -C /usr/local --strip-components=1 \\ &amp;&amp; rm &quot;node-v$NODE_VERSION-linux-x64.tar.xz&quot; SHASUMS256.txt.asc SHASUMS256.txt \\ &amp;&amp; ln -s /usr/local/bin/node /usr/local/bin/nodejs 在这里先定义了环境变量 NODE_VERSION，其后的 RUN 这层里，多次使用 $NODE_VERSION 来进行操作定制。可以看到，将来升级镜像构建版本的时候，只需要更新 7.2.0 即可，Dockerfile 构建维护变得更轻松了。 下列指令可以支持环境变量展开： ADD、COPY、ENV、EXPOSE、LABEL、USER、WORKDIR、VOLUME、STOPSIGNAL、ONBUILD。 可以从这个指令列表里感觉到，环境变量可以使用的地方很多，很强大。通过环境变量，我们可以让一份 Dockerfile 制作更多的镜像，只需使用不同的环境变量即可。 VOLUME 格式为： VOLUME [&quot;&lt;路径1&gt;&quot;, &quot;&lt;路径2&gt;&quot;...] VOLUME &lt;路径&gt; 之前我们说过，容器运行时应该尽量保持容器存储层不发生写操作，对于数据库类需要保存动态数据的应用，其数据库文件应该保存于卷(volume)中，后面的章节我们会进一步介绍 Docker 卷的概念。为了防止运行时用户忘记将动态文件所保存目录挂载为卷，在 Dockerfile 中，我们可以事先指定某些目录挂载为匿名卷，这样在运行时如果用户不指定挂载，其应用也可以正常运行，不会向容器存储层写入大量数据。 VOLUME /data 这里的 /data 目录就会在运行时自动挂载为匿名卷，任何向 /data 中写入的信息都不会记录进容器存储层，从而保证了容器存储层的无状态化。当然，运行时可以覆盖这个挂载设置。比如： docker run -d -v mydata:/data xxxx 在这行命令中，就使用了 mydata 这个命名卷挂载到了 /data 这个位置，替代了 Dockerfile 中定义的匿名卷的挂载配置。 EXPOSE 格式为 EXPOSE &lt;端口1&gt; [&lt;端口2&gt;...]。 EXPOSE 指令是声明运行时容器提供服务端口，这只是一个声明，在运行时并不会因为这个声明应用就会开启这个端口的服务。在 Dockerfile 中写入这样的声明有两个好处，一个是帮助镜像使用者理解这个镜像服务的守护端口，以方便配置映射；另一个用处则是在运行时使用随机端口映射时，也就是 docker run -P 时，会自动随机映射 EXPOSE 的端口。 此外，在早期 Docker 版本中还有一个特殊的用处。以前所有容器都运行于默认桥接网络中，因此所有容器互相之间都可以直接访问，这样存在一定的安全性问题。于是有了一个 Docker 引擎参数 --icc=false，当指定该参数后，容器间将默认无法互访，除非互相间使用了 --links 参数的容器才可以互通，并且只有镜像中 EXPOSE 所声明的端口才可以被访问。这个 --icc=false 的用法，在引入了 docker network 后已经基本不用了，通过自定义网络可以很轻松的实现容器间的互联与隔离。 要将 EXPOSE 和在运行时使用 -p &lt;宿主端口&gt;:&lt;容器端口&gt; 区分开来。-p，是映射宿主端口和容器端口，换句话说，就是将容器的对应端口服务公开给外界访问，而 EXPOSE 仅仅是声明容器打算使用什么端口而已，并不会自动在宿主进行端口映射。 WORKDIR 格式为 WORKDIR &lt;工作目录路径&gt;。 使用 WORKDIR 指令可以来指定工作目录（或者称为当前目录），以后各层的当前目录就被改为指定的目录，如该目录不存在，WORKDIR 会帮你建立目录。 之前提到一些初学者常犯的错误是把 Dockerfile 等同于 Shell 脚本来书写，这种错误的理解还可能会导致出现下面这样的错误： RUN cd /app RUN echo &quot;hello&quot; &gt; world.txt 如果将这个 Dockerfile 进行构建镜像运行后，会发现找不到 /app/world.txt 文件，或者其内容不是 hello。原因其实很简单，在 Shell 中，连续两行是同一个进程执行环境，因此前一个命令修改的内存状态，会直接影响后一个命令；而在 Dockerfile 中，这两行 RUN 命令的执行环境根本不同，是两个完全不同的容器。这就是对 Dockerfile 构建分层存储的概念不了解所导致的错误。 之前说过每一个 RUN 都是启动一个容器、执行命令、然后提交存储层文件变更。第一层 RUN cd /app 的执行仅仅是当前进程的工作目录变更，一个内存上的变化而已，其结果不会造成任何文件变更。而到第二层的时候，启动的是一个全新的容器，跟第一层的容器更完全没关系，自然不可能继承前一层构建过程中的内存变化。 因此如果需要改变以后各层的工作目录的位置，那么应该使用 WORKDIR 指令。 docker compose 简介 概述 Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。从功能上看，跟 OpenStack 中的 Heat 十分类似。 其代码目前在 https://github.com/docker/compose上开源。 Compose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。 我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。 Compose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（Project）。Compose 中有两个重要的概念： 服务 (Service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (Project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。Compose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。 安装 Docker Compose Compose 支持 Linux、macOS、Windows 10 三大平台。在 Linux 上的也安装十分简单，从 官方 GitHub Release 处直接下载编译好的二进制文件即可。 curl -L https://github.com/docker/compose/releases/download/1.24.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose # 上面是官方提供的下载地址 可能会链接不稳定导致下载不下来 可以用下面这个地址进行安装 curl -L https://get.daocloud.io/docker/compose/releases/download/1.24.0/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose dockercompose chmod +x /usr/local/bin/docker-compose 验证安装是否成功 docker-compose version # 输出如下 docker-compose version 1.24.0, build 0aa59064 docker-py version: 3.7.2 CPython version: 3.6.8 OpenSSL version: OpenSSL 1.1.0j 20 Nov 2018 docker compose 使用 术语 首先介绍几个术语。 服务 (Service)：一个应用容器，实际上可以运行多个相同镜像的实例。 项目 (Project)：由一组关联的应用容器组成的一个完整业务单元。 可见，一个项目可以由多个服务（容器）关联而成，Compose 面向项目进行管理。 场景 最常见的项目是 Web 网站，该项目应该包含 Web 应用和缓存。下面我们用 Python 来建立一个能够记录页面访问次数的 Web 网站。 Python 应用 新建文件夹，在该目录中编写 app.py 文件 from flask import Flask from redis import Redis app = Flask(__name__) redis = Redis(host='redis', port=6379) @app.route('/')d ef hello(): count = redis.incr('hits') return 'Hello World! 该页面已被访问 {} 次。\\n'.format(count) if __name__ == &quot;__main__&quot;: app.run(host=&quot;0.0.0.0&quot;, debug=True) Dockerfile 编写 Dockerfile 文件，内容为 FROM python:3.6-alpine ADD . /code WORKDIR /code RUN pip install redis flask CMD [&quot;python&quot;, &quot;app.py&quot;] Docker Compose 模板 编写 docker-compose.yml 文件，这个是 Compose 使用的主模板文件。 version: '3' services: web: build: . ports: - &quot;5000:5000&quot; redis: image: &quot;redis:alpine&quot; 运行 Compose 项目 docker-compose up -d 此时访问本地 5000 端口，每次刷新页面，计数就会加 1。 ###使用docker compose 安装启动tomcat cd /usr/local/:到usr/local目录下 mkdir -p docker/tomcat:创建测试目录 vi docker-compose.yml:创建docker compose yml文件 # 粘贴内容到yml中,需要原样粘贴 version: '3.1' services: tomcat: restart: always image: tomcat container_name: tomcat ports: - 8080:8080 docker-compose up:创建成功后执行docker-compose up [-d]文件 -d守护态运行 扩展阅读 YAML 配置文件语言 YAML 是专门用来写配置文件的语言，非常简洁和强大，远比 JSON 格式方便。YAML 语言的设计目标，就是方便人类读写。它实质上是一种通用的数据串行化格式。它的基本语法规则如下： 大小写敏感 使用缩进表示层级关系 缩进时不允许使用 TAB 键，只允许使用空格。 缩进的空格数目不重要，只要相同层级的元素左侧对齐即可 # 表示注释，从这个字符一直到行尾，都会被解析器忽略。YAML 支持的数据结构有三种： 对象： 键值对的集合，又称为映射（mapping）/ 哈希（hashes） / 字典（dictionary） 数组： 一组按次序排列的值，又称为序列（sequence） / 列表（list） 纯量（scalars）： 单个的、不可再分的值 YAML 对象 对象的一组键值对，使用冒号结构表示 animal: pets YAML 数组 一组连词线开头的行，构成一个数组 - Cat - Dog - Goldfish 数据结构的子成员是一个数组，则可以在该项下面缩进一个空格 - Array - Cat - Dog - Goldfish YAML 复合结构 对象和数组可以结合使用，形成复合结构 languages: - Ruby - Perl - Python websites: YAML: yaml.org Ruby: ruby-lang.org Python: python.org Perl: use.perl.org YAML 纯量 纯量是最基本的、不可再分的值。以下数据类型都属于 JavaScript 的纯量 字符串 布尔值 整数 浮点数 Null 时间 日期 修改 IP 和 DNS 课程演示会采用多虚拟机模拟分布式场景，为防止 IP 冲突，无法联网等问题，需要预先设置好主机名、IP、DNS 配置(修改完得重启系统) 修改主机名 修改 cloud.cfg 防止重启后主机名还原 vi /etc/cloud/cloud.cfg # 该配置默认为 false，修改为 true 即可 preserve_hostname: true 修改主机名 # 修改主机名 hostnamectl set-hostname deployment # 配置 hosts cat &gt;&gt; /etc/hosts &lt;&lt; EOF 192.168.141.130 deployment EOF 修改 IP 编辑 vi /etc/netplan/50-cloud-init.yaml 配置文件，修改内容如下 network: ethernets: ens33: addresses: [192.168.141.130/24] gateway4: 192.168.141.2 nameservers: addresses: [192.168.141.2] version: 2 使用 netplan apply 命令让配置生效 修改 DNS # 取消 DNS 行注释，并增加 DNS 配置如：114.114.114.114，修改后重启下计算机 vi /etc/systemd/resolved.conf docker compose 部署应用程序 部署 Tomcat version: '3.1' services: tomcat: restart: always image: tomcat container_name: tomcat ports: - 8080:8080 volumes: - ./webapps:/usr/local/tomcat/webapps environment: TZ: Asia/Shanghai 部署 MySQL version: '3.1' services: db: # 目前 latest 版本为 MySQL8.x image: mysql restart: always environment: MYSQL_ROOT_PASSWORD: 123456 command: --default-authentication-plugin=mysql_native_password --character-set-server=utf8mb4 --collation-server=utf8mb4_general_ci --explicit_defaults_for_timestamp=true --lower_case_table_names=1 ports: - 3306:3306 volumes: - ./data:/var/lib/mysql # MySQL 的 Web 客户端 adminer: image: adminer restart: always ports: - 8081:8080 docker compose 部署 GitLab 什么是 GitLab GitLab 是利用 Ruby on Rails 一个开源的版本管理系统，实现一个自托管的 Git 项目仓库，可通过 Web 界面进行访问公开的或者私人项目。它拥有与 Github 类似的功能，能够浏览源代码，管理缺陷和注释。可以管理团队对仓库的访问，它非常易于浏览提交过的版本并提供一个文件历史库。团队成员可以利用内置的简单聊天程序 (Wall) 进行交流。它还提供一个代码片段收集功能可以轻松实现代码复用，便于日后有需要的时候进行查找。 部署 GitLab 我们使用 Docker 来安装和运行 GitLab 中文版，docker-compose.yml 配置如下： version: '3' services: web: image: 'twang2218/gitlab-ce-zh' restart: always hostname: '192.168.75.145' environment: TZ: 'Asia/Shanghai' GITLAB_OMNIBUS_CONFIG: | external_url 'http://192.168.75.145' gitlab_rails['gitlab_shell_ssh_port'] = 2222 unicorn['port'] = 8888 nginx['listen_port'] = 80 ports: - '80:80' - '443:443' - '2222:22' volumes: - ./config:/etc/gitlab - ./data:/var/opt/gitlab - ./logs:/var/log/gitlab 配置 GitLab 访问地址：http://ip:8080 设置管理员初始密码，这里的密码最好是 字母 + 数字组合，并且大于等于 8 位 配置完成后登录，管理员账号是 root 注意： 如果服务器配置较低，启动运行可能需要较长时间，请耐心等待 设置 GitLab 第一次使用时可以做一些初始化设置，点击 管理区域 -&gt; 设置 关闭头像功能，由于 Gravatar 头像为网络头像，在网络情况不理想时可能导致访问时卡顿 由于是内部代码托管服务器，可以直接关闭注册功能，由管理员统一创建用户即可 账户管理 使用时请不要直接通过 root 用户操作，需要先创建用户，然后通过创建的用户操作，如果你是管理员还需要为其他开发人员分配账户 创建账户，点击 管理区域 -&gt; 新建用户 设置账户信息，同时你可以将自己设置为管理员 修改用户密码，由于我们创建时并没有配置邮箱，所以还需要重新编辑用户信息并手动设置密码 退出并使用新账户登录 注意： 创建完账户，第一次登录时还会提示你修改登录密码 项目管理 点击 + 号 -&gt; 新建项目 输入项目名称及描述信息，设置可见等级为私有，这样别人就看不见你的项目 我们选择通过增加一个 README 的方式来初始化项目 直接提交修改即可 使用 SSH 方式拉取和推送 生成 SSH KEY 使用 ssh-keygen 工具生成，位置在 Git 安装目录下，我的是 C:\\Program Files\\Git\\usr\\bin，输入命令： ssh-keygen -t rsa -C &quot;your_email@example.com&quot; 执行成功后的效果： Microsoft Windows [版本 10.0.14393] (c) 2016 Microsoft Corporation。保留所有权利。 C:\\Program Files\\Git\\usr\\bin&gt;ssh-keygen -t rsa -C &quot;topsale@vip.qq.com&quot; Generating public/private rsa key pair. Enter file in which to save the key (/c/Users/Lusifer/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /c/Users/Lusifer/.ssh/id_rsa. Your public key has been saved in /c/Users/Lusifer/.ssh/id_rsa.pub. The key fingerprint is: SHA256:cVesJKa5VnQNihQOTotXUAIyphsqjb7Z9lqOji2704E topsale@vip.qq.com The key's randomart image is: +---[RSA 2048]----+ | + ..=o=. .+. | | o o + B .+.o.o | |o . + +=o+.. | |.= . oo... | |= o So | |oE . o | | .. .. . | | o*o+ | | *B*oo | +----[SHA256]-----+ C:\\Program Files\\Git\\usr\\bin&gt; 复制 SSH-KEY 信息到 GitLab 密钥位置在：C:\\Users\\你的用户名\\.ssh 目录下，找到 id_rsa.pub 并使用编辑器打开，如： 登录 GitLab，点击“用户头像”--&gt;“设置”--&gt;“SSH 密钥” 成功增加密钥后的效果 使用 TortoiseGit 克隆项目 新建一个存放代码仓库的本地文件夹 在文件夹空白处按右键 选择 Git 克隆... 复制项目地址到 URL 如果弹出连接信息请选择是 成功克隆项目到本地 推送项目 创建或修改文件（这里的文件为所有文件，包括：代码、图片等） 我们以创建 .gitignore 过滤配置文件为例，该文件的主要作用为过滤不需要上传的文件，比如：IDE 生成的工程文件、编译后的 class 文件等 在工程目录下，新建 .gitignore 文件，并填入如下配置 target/ !.mvn/wrapper/maven-wrapper.jar ## STS ## .apt_generated .classpath .factorypath .project .settings .springBeans ## IntelliJ IDEA ## .idea *.iws *.iml *.ipr ## JRebel ## rebel.xml ## MAC ## .DS_Store ## Other ## logs/ temp/ 右键呼出菜单，选择 提交 Master... 点击 全部 并填入 日志信息 点击 提交并推送 成功后的效果图 查看 GitLab 确认提交成功 docker compose 部署 Nexus 什么是 Nexus Nexus 是一个强大的 Maven 仓库管理器，极大地简化了内部仓库的维护和外部仓库的访问。2016 年 4 月 6 日 Nexus 3.0 版本发布，相较 2.x 版本有了很大的改变 对低层代码进行了大规模重构，提升性能，增加可扩展性以及改善用户体验。 升级界面，极大的简化了用户界面的操作和管理。 提供新的安装包，让部署更加简单。 增加对 Docker, NeGet, npm, Bower 的支持。 提供新的管理接口，以及增强对自动任务的管理。 部署 Nexus 我们使用 Docker 来安装和运行 Nexus，docker-compose.yml 配置如下： version: '3.1' services: nexus: restart: always image: sonatype/nexus3 container_name: nexus ports: - 80:8081 volumes: - data:/nexus-data volumes: data: 验证安装是否成功 地址： http://ip:port/ 用户名： admin 密码： admin123 注意： 新版本密码在 cat /var/lib/docker/volumes/nexus_data/_data/admin.password Maven 仓库介绍 代理仓库(Proxy Repository) 第三方仓库 maven-central nuget.org-proxy 版本策略(Version Policy) Release： 正式版本 Snapshot： 快照版本 Mixed： 混合模式 布局策略(Layout Policy) Strict： 严格 Permissive： 宽松 宿主仓库(Hosted Repository) 存储本地上传的组件和资源的 maven-releases maven-snapshots nuget-hosted 部署策略(Deployment Policy) Allow Redeploy： 允许重新部署 Disable Redeploy： 禁止重新部署 Read-Only： 只读 仓库组(Repository Group) 通常包含了多个代理仓库和宿主仓库，在项目中只要引入仓库组就可以下载到代理仓库和宿主仓库中的包 maven-public nuget-group 在项目中使用 Nexus 配置认证信息 在 Maven settings.xml 中添加 Nexus 认证信息 (servers 节点下) &lt;server&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; &lt;server&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin123&lt;/password&gt; &lt;/server&gt; Snapshots 与 Releases 的区别 nexus-releases： 用于发布 Release 版本 nexus-snapshots： 用于发布 Snapshot 版本（快照版） Release 版本与 Snapshot 定义 Release: 1.0.0/1.0.0-RELEASE Snapshot: 1.0.0-SNAPSHOT 在项目 pom.xml 中设置的版本号添加 SNAPSHOT 标识的都会发布为 SNAPSHOT 版本，没有 SNAPSHOT 标识的都会发布为 RELEASE 版本。 SNAPSHOT 版本会自动加一个时间作为标识，如：1.0.0-SNAPSHOT 发布后为变成 1.0.0-SNAPSHOT-20180522.123456-1.jar 配置自动化部署 在 pom.xml 中添加如下代码 &lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;nexus-releases&lt;/id&gt; &lt;name&gt;Nexus Release Repository&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/repository/maven-releases/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;nexus-snapshots&lt;/id&gt; &lt;name&gt;Nexus Snapshot Repository&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/repository/maven-snapshots/&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;/distributionManagement&gt; 注意事项 ID 名称必须要与 settings.xml 中 Servers 配置的 ID 名称保持一致 项目版本号中有 SNAPSHOT 标识的，会发布到 Nexus Snapshots Repository， 否则发布到 Nexus Release Repository，并根据 ID 去匹配授权账号 部署到仓库 mvn deploy 配置代理仓库 &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Nexus Repository&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/repository/maven-public/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;Nexus Plugin Repository&lt;/name&gt; &lt;url&gt;http://127.0.0.1:8081/repository/maven-public/&lt;/url&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; 扩展阅读 手动上传第三方依赖 Nexus 3.1.x 开始支持页面上传第三方依赖功能，以下为手动上传命令 # 如第三方JAR包：aliyun-sdk-oss-2.2.3.jar mvn deploy:deploy-file -DgroupId=com.aliyun.oss -DartifactId=aliyun-sdk-oss -Dversion=2.2.3 -Dpackaging=jar -Dfile=D:\\aliyun-sdk-oss-2.2.3.jar -Durl=http://127.0.0.1:8081/repository/maven-3rd/ -DrepositoryId=nexus-releases 注意事项 建议在上传第三方 JAR 包时，创建单独的第三方 JAR 包管理仓库，便于管理有维护。（maven-3rd） -DrepositoryId=nexus-releases 对应的是 settings.xml 中 Servers 配置的 ID 名称。（授权） docker compose 部署 Harbor 什么是 Harbor Harbor 是一个用于存储和分发 Docker 镜像的企业级 Registry 服务器，通过添加一些企业必需的功能特性，例如安全、标识和管理等，扩展了开源 Docker Distribution。作为一个企业级私有 Registry 服务器，Harbor 提供了更好的性能和安全。提升用户使用 Registry 构建和运行环境传输镜像的效率。Harbor 支持安装在多个 Registry 节点的镜像资源复制，镜像全部保存在私有 Registry 中， 确保数据和知识产权在公司内部网络中管控。另外，Harbor 也提供了高级的安全特性，诸如用户管理，访问控制和活动审计等。 Harbor 特性 基于角色的访问控制 ： 用户与 Docker 镜像仓库通过 “项目” 进行组织管理，一个用户可以对多个镜像仓库在同一命名空间（project）里有不同的权限。 镜像复制 ： 镜像可以在多个 Registry 实例中复制（同步）。尤其适合于负载均衡，高可用，混合云和多云的场景。 图形化用户界面 ： 用户可以通过浏览器来浏览，检索当前 Docker 镜像仓库，管理项目和命名空间。 AD/LDAP 支持 ： Harbor 可以集成企业内部已有的 AD/LDAP，用于鉴权认证管理。 审计管理 ： 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。 国际化 ： 已拥有英文、中文、德文、日文和俄文的本地化版本。更多的语言将会添加进来。 RESTful API ： RESTful API 提供给管理员对于 Harbor 更多的操控，使得与其它管理软件集成变得更容易。 部署简单 ： 提供在线和离线两种安装工具， 也可以安装到 vSphere 平台 (OVA 方式) 虚拟设备。 Harbor 组件 Proxy： Harbor 的 registry, UI, token 等服务，通过一个前置的反向代理统一接收浏览器、Docker 客户端的请求，并将请求转发给后端不同的服务。 Registry： 负责储存 Docker 镜像，并处理 docker push/pull 命令。由于我们要对用户进行访问控制，即不同用户对 Docker image 有不同的读写权限，Registry 会指向一个 token 服务，强制用户的每次 docker pull/push 请求都要携带一个合法的 token, Registry 会通过公钥对 token 进行解密验证。 Core services： 这是 Harbor 的核心功能，主要提供以下服务： UI： 提供图形化界面，帮助用户管理 registry 上的镜像（image）, 并对用户进行授权。 WebHook： 为了及时获取 registry 上 image 状态变化的情况， 在 Registry 上配置 webhook，把状态变化传递给 UI 模块。 Token： 负责根据用户权限给每个 docker push/pull 命令签发 token. Docker 客户端向 - Registry 服务发起的请求，如果不包含 token，会被重定向到这里，获得 token 后再重新向 Registry 进行请求。 Database： 为 core services 提供数据库服务，负责储存用户权限、审计日志、Docker image 分组信息等数据。 Job Services： 提供镜像远程复制功能，可以把本地镜像同步到其他 Harbor 实例中。 Log Collector： 为了帮助监控 Harbor 运行，负责收集其他组件的 log，供日后进行分析。 安装 Harbor 官方 GitHub 上下载最新离线安装版（我已经下载并放置在群分享的 Linux 目录下）并上传至服务器 解压安装包 tar -zxvf harbor-offline-installer-v1.8.0.tgz # 输出如下 harbor/harbor.v1.8.0.tar.gz harbor/prepare harbor/LICENSE harbor/install.sh harbor/harbor.yml 修改配置文件 vi harbor.yml # 修改为域名或你服务器 IP hostname: 192.168.141.150 执行安装脚本 ./install.sh # 输出如下 [Step 0]: checking installation environment ... Note: docker version: 18.09.6 Note: docker-compose version: 1.24.0 [Step 1]: loading Harbor images ... 23d9f72a5270: Loading layer [==================================================&gt;] 33.25MB/33.25MB 1d4a1da12c02: Loading layer [==================================================&gt;] 50.51MB/50.51MB 8eb1a006f3b0: Loading layer [==================================================&gt;] 3.584kB/3.584kB 41b6f75847f4: Loading layer [==================================================&gt;] 3.072kB/3.072kB ec9bd6e4d4e8: Loading layer [==================================================&gt;] 2.56kB/2.56kB 6d852bb664c2: Loading layer [==================================================&gt;] 3.072kB/3.072kB 0e4ed2b5a5b8: Loading layer [==================================================&gt;] 3.584kB/3.584kB 8dfb2b644f30: Loading layer [==================================================&gt;] 12.29kB/12.29kB Loaded image: goharbor/harbor-log:v1.8.0 d8c53538042b: Loading layer [==================================================&gt;] 63.34MB/63.34MB 1b5fb7ee22e0: Loading layer [==================================================&gt;] 47.96MB/47.96MB a8bdca5e9d71: Loading layer [==================================================&gt;] 6.656kB/6.656kB f7cec940b52c: Loading layer [==================================================&gt;] 2.048kB/2.048kB 301a4a2af7db: Loading layer [==================================================&gt;] 7.68kB/7.68kB e588e1e3a775: Loading layer [==================================================&gt;] 2.56kB/2.56kB 539f28a5d0ea: Loading layer [==================================================&gt;] 2.56kB/2.56kB 8b4a72241226: Loading layer [==================================================&gt;] 2.56kB/2.56kB Loaded image: goharbor/harbor-db:v1.8.0 c88db349fb2f: Loading layer [==================================================&gt;] 8.972MB/8.972MB 1f2d4d72bba2: Loading layer [==================================================&gt;] 35.77MB/35.77MB dddbcf598df5: Loading layer [==================================================&gt;] 2.048kB/2.048kB 0ced476c2d9c: Loading layer [==================================================&gt;] 3.072kB/3.072kB af24eb0bf40b: Loading layer [==================================================&gt;] 35.77MB/35.77MB Loaded image: goharbor/chartmuseum-photon:v0.8.1-v1.8.0 b185d348bd7d: Loading layer [==================================================&gt;] 2.56kB/2.56kB f032ded7f92e: Loading layer [==================================================&gt;] 1.536kB/1.536kB c6c822edbc47: Loading layer [==================================================&gt;] 66.9MB/66.9MB 73ef3c4363bf: Loading layer [==================================================&gt;] 39.75MB/39.75MB 0c490e002448: Loading layer [==================================================&gt;] 144.4kB/144.4kB 31afe2abafb4: Loading layer [==================================================&gt;] 3.004MB/3.004MB Loaded image: goharbor/prepare:v1.8.0 257ebcc1c9c4: Loading layer [==================================================&gt;] 8.967MB/8.967MB 7579d3c94fca: Loading layer [==================================================&gt;] 38.68MB/38.68MB 323611f7dd17: Loading layer [==================================================&gt;] 38.68MB/38.68MB Loaded image: goharbor/harbor-jobservice:v1.8.0 587a5757a7f6: Loading layer [==================================================&gt;] 3.548MB/3.548MB Loaded image: goharbor/nginx-photon:v1.8.0 a61ab2060e6e: Loading layer [==================================================&gt;] 8.967MB/8.967MB 25359ae00f57: Loading layer [==================================================&gt;] 5.143MB/5.143MB 610a1668f8bf: Loading layer [==================================================&gt;] 15.13MB/15.13MB db2252abd9e0: Loading layer [==================================================&gt;] 26.47MB/26.47MB 4f406312560b: Loading layer [==================================================&gt;] 22.02kB/22.02kB 1cee0947e5a7: Loading layer [==================================================&gt;] 3.072kB/3.072kB 48db2b9b0752: Loading layer [==================================================&gt;] 46.74MB/46.74MB Loaded image: goharbor/notary-server-photon:v0.6.1-v1.8.0 aaf447150765: Loading layer [==================================================&gt;] 113MB/113MB 6835441e1a1d: Loading layer [==================================================&gt;] 10.94MB/10.94MB 9f4739e3a532: Loading layer [==================================================&gt;] 2.048kB/2.048kB 928f489135f0: Loading layer [==================================================&gt;] 48.13kB/48.13kB 1495a1a09ada: Loading layer [==================================================&gt;] 3.072kB/3.072kB 1a5f5b141717: Loading layer [==================================================&gt;] 10.99MB/10.99MB Loaded image: goharbor/clair-photon:v2.0.8-v1.8.0 66006ea937c6: Loading layer [==================================================&gt;] 337.8MB/337.8MB d272ba122880: Loading layer [==================================================&gt;] 106.5kB/106.5kB Loaded image: goharbor/harbor-migrator:v1.8.0 05bc5efb1724: Loading layer [==================================================&gt;] 8.967MB/8.967MB af3a6f89469a: Loading layer [==================================================&gt;] 46.85MB/46.85MB 452d238b3e48: Loading layer [==================================================&gt;] 5.632kB/5.632kB 36e1cb2d6ffa: Loading layer [==================================================&gt;] 27.14kB/27.14kB 5385ffb8451e: Loading layer [==================================================&gt;] 46.85MB/46.85MB Loaded image: goharbor/harbor-core:v1.8.0 268091c30a67: Loading layer [==================================================&gt;] 71.66MB/71.66MB 4433bcd802e7: Loading layer [==================================================&gt;] 3.072kB/3.072kB 420b26399278: Loading layer [==================================================&gt;] 59.9kB/59.9kB 8864c4b9ac3d: Loading layer [==================================================&gt;] 61.95kB/61.95kB Loaded image: goharbor/redis-photon:v1.8.0 63645c97bf5d: Loading layer [==================================================&gt;] 8.968MB/8.968MB ccb295818ad9: Loading layer [==================================================&gt;] 3.072kB/3.072kB 1ec2d1eefa8f: Loading layer [==================================================&gt;] 2.56kB/2.56kB b88acf0f9f5f: Loading layer [==================================================&gt;] 20.1MB/20.1MB 0e7375de12e6: Loading layer [==================================================&gt;] 20.1MB/20.1MB Loaded image: goharbor/registry-photon:v2.7.1-patch-2819-v1.8.0 444b0c8bfeee: Loading layer [==================================================&gt;] 3.548MB/3.548MB ed0415346760: Loading layer [==================================================&gt;] 6.568MB/6.568MB 572bd51089e0: Loading layer [==================================================&gt;] 160.8kB/160.8kB 1410c2919a92: Loading layer [==================================================&gt;] 215kB/215kB 8ecdca210598: Loading layer [==================================================&gt;] 3.584kB/3.584kB Loaded image: goharbor/harbor-portal:v1.8.0 7fb66591fb58: Loading layer [==================================================&gt;] 8.968MB/8.968MB 42ec4a6394bf: Loading layer [==================================================&gt;] 3.072kB/3.072kB be6c2180cb57: Loading layer [==================================================&gt;] 20.1MB/20.1MB d956d9e974c5: Loading layer [==================================================&gt;] 3.072kB/3.072kB e2e0b4f17ad8: Loading layer [==================================================&gt;] 7.465MB/7.465MB 7e29d670afe9: Loading layer [==================================================&gt;] 27.56MB/27.56MB Loaded image: goharbor/harbor-registryctl:v1.8.0 453732ea69d4: Loading layer [==================================================&gt;] 13.72MB/13.72MB c985f3824f33: Loading layer [==================================================&gt;] 26.47MB/26.47MB 76eaa2763221: Loading layer [==================================================&gt;] 22.02kB/22.02kB 0ef55a752948: Loading layer [==================================================&gt;] 3.072kB/3.072kB c5749b90723d: Loading layer [==================================================&gt;] 45.33MB/45.33MB Loaded image: goharbor/notary-signer-photon:v0.6.1-v1.8.0 [Step 2]: preparing environment ... prepare base dir is set to /usr/local/docker/harbor/harbor Generated configuration file: /config/log/logrotate.conf Generated configuration file: /config/nginx/nginx.conf Generated configuration file: /config/core/env Generated configuration file: /config/core/app.conf Generated configuration file: /config/registry/config.yml Generated configuration file: /config/registryctl/env Generated configuration file: /config/db/env Generated configuration file: /config/jobservice/env Generated configuration file: /config/jobservice/config.yml Generated and saved secret to file: /secret/keys/secretkey Generated certificate, key file: /secret/core/private_key.pem, cert file: /secret/registry/root.crt Generated configuration file: /compose_location/docker-compose.yml Clean up the input dir [Step 3]: starting Harbor ... Creating network &quot;harbor_harbor&quot; with the default driver Creating harbor-log ... done Creating harbor-db ... done Creating registryctl ... done Creating redis ... done Creating registry ... done Creating harbor-core ... done Creating harbor-jobservice ... done Creating harbor-portal ... done Creating nginx ... done ✔ ----Harbor has been installed and started successfully.---- Now you should be able to visit the admin portal at http://192.168.141.150. For more details, please visit https://github.com/goharbor/harbor . 验证安装是否成功 通过浏览器访问 http://192.168.141.150，看到登录页面 输入账号 admin，密码 Harbor12345，登录成功后 Harbor 启动和停止 Harbor 的日常运维管理是通过 docker-compose 来完成的，Harbor 本身有多个服务进程，都放在 docker 容器之中运行，我们可以通过 docker ps 命令查看。 docker ps | grep goharbor # 输出如下 07b401504357 goharbor/nginx-photon:v1.8.0 &quot;nginx -g 'daemon of…&quot; 23 minutes ago Up 23 minutes (healthy) 0.0.0.0:80-&gt;80/tcp nginx 050f39a147bc goharbor/harbor-portal:v1.8.0 &quot;nginx -g 'daemon of…&quot; 23 minutes ago Up 23 minutes (healthy) 80/tcp harbor-portal 305077bc0a3e goharbor/harbor-jobservice:v1.8.0 &quot;/harbor/start.sh&quot; 23 minutes ago Up 23 minutes harbor-jobservice 4eb33b09b268 goharbor/harbor-core:v1.8.0 &quot;/harbor/start.sh&quot; 23 minutes ago Up 23 minutes (healthy) harbor-core e9efb7a6abf9 goharbor/registry-photon:v2.7.1-patch-2819-v1.8.0 &quot;/entrypoint.sh /etc…&quot; 24 minutes ago Up 23 minutes (healthy) 5000/tcp registry f9bc75d47752 goharbor/harbor-registryctl:v1.8.0 &quot;/harbor/start.sh&quot; 24 minutes ago Up 23 minutes (healthy) registryctl 76d33d1755f6 goharbor/redis-photon:v1.8.0 &quot;docker-entrypoint.s…&quot; 24 minutes ago Up 23 minutes 6379/tcp redis 3870b3b93f46 goharbor/harbor-db:v1.8.0 &quot;/entrypoint.sh post…&quot; 24 minutes ago Up 23 minutes (healthy) 5432/tcp harbor-db 6e848e4d8bc2 goharbor/harbor-log:v1.8.0 &quot;/bin/sh -c /usr/loc…&quot; 24 minutes ago Up 24 minutes (healthy) 127.0.0.1:1514-&gt;10514/tcp harbor-log # 启动 docker-compose start # 停止 `docker-comose stop # 重启 docker-compose restart 说明： nginx： nginx 负责流量转发和安全验证，对外提供的流量都是从 nginx 中转，所以开放 https 的 443 端口，它将流量分发到后端的 ui 和正在 docker 镜像存储的 docker registry。 harbor-jobservice： harbor-jobservice 是 harbor 的 job 管理模块，job 在 harbor 里面主要是为了镜像仓库之前同步使用的； harbor-ui： harbor-ui 是 web 管理页面，主要是前端的页面和后端 CURD 的接口； registry： registry 就是 docker 原生的仓库，负责保存镜像。 harbor-adminserver： harbor-adminserver 是 harbor 系统管理接口，可以修改系统配置以及获取系统信息。 harbor-db： harbor-db 是 harbor 的数据库，这里保存了系统的 job 以及项目、人员权限管理。由于本 harbor 的认证也是通过数据，在生产环节大多对接到企业的 ldap 中； harbor-log： harbor-log 是 harbor 的日志服务，统一管理 harbor 的日志。通过 inspect 可以看出容器统一将日志输出的 syslog。 这几个容器通过 Docker link 的形式连接在一起，这样，在容器之间可以通过容器名字互相访问。对终端用户而言，只需要暴露 proxy （即 Nginx）的服务端口。 配置客户端 在 /etc/docker/daemon.json 中增加如下内容（如果文件不存在请新建该文件） { &quot;registry-mirrors&quot;: [ &quot;https://registry.docker-cn.com&quot; ], &quot;insecure-registries&quot;: [ &quot;192.168.141.150&quot; ] } 注意： 该文件必须符合 JSON 规范，否则 Docker 将不能启动。 重启服务 systemctl daemon-reload systemctl restart docker 检查客户端配置是否生效 使用 docker info 命令手动检查，如果从配置中看到如下内容，说明配置成功 Insecure Registries: 192.168.141.150 127.0.0.0/8 Harbor 上传镜像 新建项目 我们以推送 Nginx 为例，首先需要在 Harbor 上创建一个 公开/私有 的项目 推送镜像 # 在项目中标记镜像 docker tag nginx 192.168.141.150/myshop/nginx:latest # 登录 Harbor docker login 192.168.141.150 -u admin -p Harbor12345 # 推送镜像到项目 docker push 192.168.141.150/myshop/nginx:latest 查看镜像 Harbor 下载镜像 在其它机器下载镜像只需要配置好客户端即可 docker pull 192.168.141.150/myshop/nginx:latest docker compose 网络设置 概述 默认情况下，Compose 会为我们的应用创建一个网络，服务的每个容器都会加入该网络中。这样，容器就可被该网络中的其他容器访问，不仅如此，该容器还能以服务名称作为 Hostname 被其他容器访问。 默认情况下，应用程序的网络名称基于 Compose 的工程名称，而项目名称基于 docker-compose.yml 所在目录的名称。如需修改工程名称，可使用 --project-name 标识或 COMPOSE_PORJECT_NAME 环境变量。 假如一个应用程序在名为 myapp 的目录中，并且 docker-compose.yml 如下所示： version: '2' services: web: build: . ports: - &quot;8000:8000&quot; db: image: postgres 当我们运行 docker-compose up 时，将会执行以下几步： 创建一个名为 myapp_default 的网络 使用 web 服务的配置创建容器，它以 web 这个名称加入网络 myapp_default 使用 db 服务的配置创建容器，它以 db 这个名称加入网络 myapp_default 容器间可使用服务名称（web 或 db）作为 Hostname 相互访问。例如，web 这个服务可使用 postgres://db:5432 访问 db 容器。 当服务的配置发生更改时，可使用 docker-compose up 命令更新配置。此时，Compose 会删除旧容器并创建新容器。新容器会以不同的 IP 地址加入网络，名称保持不变。任何指向旧容器的连接都会被关闭，容器会重新找到新容器并连接上去。 使用 links 默认情况下，服务之间可使用服务名称相互访问。links 允许我们定义一个别名，从而使用该别名访问其他服务。 version: '2' services: web: build: . links: - &quot;db:database&quot; db: image: postgres 自定义网络 一些场景下，默认的网络配置满足不了我们的需求，此时我们可使用 networks 命令自定义网络。networks 命令允许我们创建更加复杂的网络拓扑并指定自定义网络驱动和选项。不仅如此，我们还可使用 networks 将服务连接到不是由 Compose 管理的、外部创建的网络。 version: '2' services: proxy: build: ./proxy networks: - front app: build: ./app networks: - front - back db: image: postgres networks: - back networks: front: # Use a custom driver driver: custom-driver-1 back: # Use a custom driver which takes special options driver: custom-driver-2 driver_opts: foo: &quot;1&quot; bar: &quot;2&quot; 其中，proxy 服务与 db 服务隔离，两者分别使用自己的网络；app 服务可与两者通信。使用 networks 命令，即可方便实现服务间的网络隔离与连接。 配置默认网络 version: '2' services: web: build: . ports: - &quot;8000:8000&quot; db: image: postgres networks: default: # Use a custom driver driver: custom-driver-1 这样，就可为该应用指定自定义的网络驱动 已存在的网络 我们可以预先创建一个名为 myapp 的网络，让 Compose 加入这个新创建的网络，使所有 Compose 可以通信，此时使用 external 选项。 # 创建网络 docker network create &lt;Network Name&gt; # 查看已存在的网络 docker network list networks: default: external: name: myapp ","link":"http://blog.ludangxin.club/post/docker/"},{"title":"Linux","content":"文件目录介绍及文件颜色区别 目录介绍 目录 说明 bin 存放二进制可执行文件(ls,cat,madir等) boot 存放用于系统引导时使用的各种文件 dev 用于存放设备文件 etc 存放系统配置文件 home 存放所有用户文件的根目录 lib 存放跟文件系统中的程序运行所需要的共享库及内核模块 mnt 系统管理员安装临时文件系统的安装点 opt 额外安装的可选应用程序包所放置的位置 proc 虚拟文件系统,存放当前内存的映射 root 超级用户目录 sbin 存放二进制可执行文件,只有root才能访问 tmp 用于存放各种临时文件 usr 用于存放系统应用程序,比较重要的目录/usr/local本地管理员软件安装目录 var 用于存放运行时需要改变数据的文件 颜色区分 颜色 文件类型 白色 普通文件 蓝色 目录 绿色 可执行文件 红色 压缩文件 浅蓝色 链接文件 红色闪烁 链接的文件有问题 黄色 设备文件 灰色 其它文件 系统管理命令 命令 说明 备注 lscpu cup查看 free -h 内存 ip a 查看IP whoami 查看用户名 who 当前登陆人列表 lsb_release -a 查看操作系统版本 其description:中版本介绍中的LTS是长期维护版的意思,最好用LTS版本Codename:当前版本代号 hostname 主机名 clear 清屏 top 显示当前系统中耗费资源最多的进程 stat 显示指定文件的相关信息,比ls命令显示内容更多 stat test.txt : 查看test.txt的文件详情 ps 显示当瞬间的进程状态 ps -ef | grep java: 查看关于java的进程信息 df -h 显示文件系统磁盘空间的使用情况 ping 心跳检测 检查网络情况 netstat 显示网络状态信息 kill 杀死一个进程 kill 666: 杀死进程id为666的进程 sudo 提权(由于当前账号权限太低不可使用相关操作时可以提权再使用) sudo reboot : 重启 shutdown -h now: 关机 快捷键 剪切字符 Ctrl+K：剪切光标处到行尾的字符（包括光标处字符） Ctrl+U：剪切光标处到行首的字符（不包含光标处字符） Ctrl+Y：将剪切的字符进行粘贴 复制粘贴 Ctrl+Ins：复制 Shift+Ins：粘贴 Ctrl+C : 终端正在运行的命令 Ctrl+D : 退出Xshell Ctrl+R : 搜索命令行使用过的历史命令记录 Ctrl+L : 清屏 Ctrl+Z : 暂停 Ctrl+S : 锁屏 Ctrl+Q : 解除锁屏 !! : 执行上一条命令 文件目录操作 命令 说明 语法 参数 参数说明 备注 pwd 查看当前绝对路径 ls 显示文件和目录列表 ls [OPTION]... [FILE]... ls -lS:按照从大到小列出所有文件详细信息 [OPTION] -l 分行列出文件的详细信息 [OPTION] -a 列出当前目录所有文件,包含隐藏文件 [OPTION] -S 按从大到小排序 [OPTION] -X 按文件后缀排序 l. 只显示隐藏文件 cd 切换目录 cd [dir] - 回到上次停留的目录下 cd /: 到根目录下 mkdir 创建目录 mkdir [OPTION]... [dirName] mkdir test/test.txt [OPTION] -p 父目录不存在情况下先生成父目录 touch 生成一个空文件 touch [fileName] touch test.txt : 生成一个test.txt的空文件 echo 生成一个带内容文件 echo [content] &gt; fileName; echo [content] &gt;&gt; fileNmae &gt;;&gt;&gt; &gt;:覆盖文件内容;&gt;&gt;:追加内容到文件中 cat 显示文本文件内容 cat [fileName] cat test.txt: 查看test.txt文件的内容 cp 复制文件或目录 cp [OPTION] [source dest] cp test.txt : 复制test.txt文件 rm 删除文件 rm [OPTION] [name]... rm -rf test:删除test文件夹及其子文件 [OPTION] -f force:是强制删除文件或目录 [OPTION] -r recursive:递归处理 mv 移动文件或目录 mv [OPTION] [source dest] mv test.txt .. : 将test.txt文件移动到上级目录 find 在文件系统中查找指定的文件 find [OPTION] [fileName] find . -name test.txt: 在当前目录下查找名为test.txt的文件 [OPTION] -name 文件名 grep 在指定的文本文件中查找指定的字符串 cat test.txt | grep hello: 在test.txt文件中查找hello字符串 ln 建立软链接(类似于创建快捷方式) ln test1.txt test2.txt: 创建test1.txt的软连接为test2.txt (不是复制) more 分页显示文本文件内容 more test.txt:分页查看test.txt文件内容;回车换页 head 显示文件开头内容 head test.txt :查看test.txt文件开头的内容 tail 显示文件结尾内容 tail test.txt: 查看test.txt文件结尾内容 -f 跟踪输出 压缩解压缩 tar 命令 语法 参数 参数说明 tar tar [-cxzjvf] 压缩打包文档的名称 欲打包目录 -c 建立一个归档文件 -x 解开一个归档文件 -z 是否需要用gzip压缩(常用) -j 是否需要用bzip2压缩(不常用) -v 压缩的过程中显示文件 -f 使用档名,在f之后要立即接档名 -tf 查看归档文件里面的文件 例子: 压缩文件夹: tar -zcvf test.tar.gz test\\ 解压文件夹: tar -zxvf test.tar.gz Vim 编辑器 概述 ​ Vim是从vi发展出来的一个文本编辑器.代码补完,编译及错误跳转等方便编程的功能特别丰富,在程序员中被广泛使用. 简单的来说,vi是老师的字处理器,不过功能已经很齐全了,但是还是有可以进步的地方.vim则可以说是程序开发者的 一项很好用的工具. 运行模式 编辑模式: vi fieleName进入文件编辑模式 插入模式: 编辑模式下,输入i或按Insert键进入插入模式,插入文本信息,编辑完毕后按Esc键进入编辑模式 命令模式: 在编辑模式下,输入: 进行命令模式 命令模式 命令 说明 :q quit:直接退出vi :wq write quit:保存后退出vi,并可以新建文件 :q! 强制退出 w file 将当前内容保存成某个文件 / 查找字符串 :set number 在编辑文件显示行号 :set nonumber 在编辑文件不显示行号 :set paste 原样粘贴 Linux用户和组 sudo passwd root: 修改root密码 su: 切换到root用户下 su ludangxin: 切换到ludangxin用户下 设置允许远程登陆Root (Ubuntu操作系统) vi /etc/ssh/sshd_config: 打开配置文件 打开PermitRootLogin prohibit-password 且将prohibit-password 改为yes,保存退出 service ssh restart : 重启ssh服务 Linux 文件权限管理 查看文件和目录的权限 概述 ls -al:使用ls不带参数只显示文件名称,通过ls -al可以显示文件或者目录的权限信息. ls -l 文件名 显示信息包括 : 文件类型(d目录,-普通文件,l链接文件),文件权限,文件的用户,文件的所属组,文件的大小,文件的创建时间,文件的名称 rwx===read write excute -rw-r--r-- 1 ludangxin ludangxin 675 Oct26 17:20 .prifile -:普通文件 rw-: 说明用户ludangxin有读写权限,没有运行权限 r--: 表示用户组ludangxin只有读权限,没有写和运行的权限 r--:其他用户只有读权限,没有写权限和运行的权限 |-rw-r--r-- | 1 | ludangxin | ludangxin | 675 | Oct 26 17:20 | .profile | | :-: | :-: | :-: | :-: | :-: | :-: | :-: | |文档类型及权限 | 连接数 | 文档所属用户 | 文档所属组 | 文档大小 | 文档最后被修改日期 | 文档名称 | - rw- r-- r-- 文档类型 文档所有者权限(user) 文档所属用户组权限(group) 其他用户权限(other) ###文档类型 d 表示目录 -表示普通文件 l 链接文件 更改操作权限 命令 说明 语法 参数 参数说明 备注 chmod change modify:文件授权 chmod [OPTION] [MODE] [fileName] chmod +x test.sh:给test.sh文件增加可执行的权限 [OPTION] u user:用户 [OPTION] g group:用户组 [OPTION] o others:表示其他用户 [OPTION] a all:表示所有用户是系统默认的 [MODE] + 增加权限 [MODE] - 取消权限 [MODE] = 赋予给定的权限,取消文档以前的所有权限 chown change owner:主要作用就是改变文件或者目录所有者,所有着包含用户和用户组 chown [-R] 用户名称 文件或者目录chown [-R] 用户名称:用户组名称 文件或目录 -R 进行递归式的权限更改,将目录下的所有文件,子目录更新为指定用户组权限 数字设定法(权限) 数字设定法中数字表示的含义 0 : 表示没有任何权限 1 : 表示有可执行权限 = x 2 : 表示有可写权限 = w 4 : 表示有可读权限 = r 也可以用数字来表示权限如 chmod 755 fileNmae r w x r - x r - x 4 2 1 4 - 1 4 - 1 user group others 若要 rwx 属性则 4+2+1=7 若要rw-属性则 4+2=6 若要r-x属性则 4+1=5 例: ​ 若要给test.sh文件赋予以上权限则:chmod 765 test.sh 命令行操作 history:查看历史命令 history -c: 删除内存中的例是命令 ![历史命令编号]: 执行历史命令 Linux 部署应用程序 安装JDK 移动到指定目录并解压缩 sudo mkdir /usr/local/java : 在/usr/local目录下新建java文件夹 mv jdk-8u171-linux-x64.tar.gz /usr/local/java: 将jdk文件移动到java目录下 cd /usr/local/java : 进入java目录 sudo tar -zxvf jdk-8u171-linux-x64.tar.gz: 解压缩 sudo rm jdk-8u171-linux-x64.tar.gz: 删除压缩包 chown -R root:root /usr/local/java: 将文件的所有权赋给root 配置环境变量 sudo vi /etc/profile: 配置环境变量 修改系统环境变量 (等号两侧不要加入空格，不然会出现“不是有效的标识符”，因为source /etc/profile 时不能识别多余到空格，会理解为是路径一部分) export JAVA_HOME=/usr/local/java/jdk1.8.0_211 export JRE_HOME=/usr/local/java/jdk1.8.0_211/jre export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/lib:$CLASSPATH export PATH=$JAVA_HOME/bin:$PATH source /etc/profile: 使profile立即生效 数据源配置 centos cd /etc/yum.repos.d:到配置数据源的文件夹下 cp CentOS-Base.repo CentOS-Base.repo.backup:先备份数据源文件 wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo:下载阿里数据源文件 或者 curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo: 下载阿里数据源文件 注意数据源版本需和操作系统版本一致,如需要下载其他版本修改7为自己的版本即可 wget https://mirrors.163.com/.help/CentOS7-Base-163.repo: 163的数据源文件 yum clean all: 清除缓存 yum makecache: 生成缓存 非阿里云ECS用户会出现 Couldn't resolve host 'mirrors.cloud.aliyuncs.com' 信息，不影响使用。用户也可自行修改相关配置: eg:sed -i -e '/mirrors.cloud.aliyuncs.com/d' -e '/mirrors.aliyuncs.com/d' /etc/yum.repos.d/CentOS-Base.repo ubuntu cd /etc/apt:到配置数据源的文件夹下 vi sources.list:打开配置数据源的文件,ubuntu 18.04(bionic) 配置如下将文件内容替换为 deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse apt-get update: 更新数据源 常用APT命令 命令 说明 apt-mark showmanual 打印手动安装的软件包列表 apt-get install &lt;Package Name&gt; 安装软件包 apt-get remove &lt;Package Name&gt; 删除安装包 apt-get update 更新软件包列表 apt-get upgrade 升级有可用更新的系统(慎用) apt-cache search &lt;Package Name&gt; 搜索软件包 apt-cache show &lt;Package Name&gt; 获取包信息 apt-get remove --purge &lt;Package Name&gt; 删除包及配置文件 apt-cache depends &lt;Package Name&gt; 了解使用依赖 apt-cache rdepends &lt;Package Name&gt; 查看被那些包依赖 apt-get build-dep &lt;Package Name&gt; 安装相关的编译环境 apt-get source &lt;Package Name&gt; 下载源代码 apt-get clean &amp;&amp; apt-get autoclean 清理无用包 apt-get check 检查是否有损坏的依赖 ","link":"http://blog.ludangxin.club/post/linux/"},{"title":"Java8新特性","content":"java8新特性介绍 速度更快 代码更少 强大的stream API 便于并行 最大化减少空指针异常 Optional Lanmbda lambda是一个匿名函数，我们可以把lambda表达式理解为是一段可以 传递的代码（将代码像数据一样进行传递）。可以细写出更简洁，更灵活的代码。 Lanmbda 语法： 横批：能省则省 上联：左右遇一括号省 下联：左侧推断类型省 方法引用：若Lambda 体内的内容有方法已经实现了，我们可以使用“方法引用”（可以理解为方法引用是Lambda表达式的另外一种表现形式） 主要有三种语法格式：注意：Lambda 体中调用的方法参数列表与返回值类型必须与函数的抽象方法一致 对象::实例方法名 类::静态方法名 类::实例方法名 构造器引用：具体使用哪个构造器，取决于Lambda 函数抽象类的参数列表 格式：ClassName::new 数组引用： 格式：Type[]::new Java8 内置的四大核心函数是接口 Consumer : 消费型接口 void accept(T t); Supplier : 供给型接口 T get(); Function&lt;T,R&gt; : 函数型接口 R apply(T t); Predicate : 断言型接口 boolean test(T t); Stream API(java.unil.stream.*) Stream是java8中处理集合的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常负责的查找，过滤和映射数据等操作。 使用Stream API 对集合数据进行操作，就类似于使用过SQL执行的数据查询。也可以使用Stream API来并行执行操作。简而言之， StreamAPI提供了一种高校且易于使用的处理数据的方式。 什么是流（Stream）？ 是数据渠道，用于操作数据源（集合，数组等）所生成的元素序列。“集合讲的是数据，流讲的是计算” Stream自己不会存储元素 Stream不会改变源对象。相反，他们会返回一个持有结果的新Stream。 Stream操作时延迟执行的。这意味着他们等到需要结果的时候才执行。 Stream的操作三个步骤 创建Stream：一个数据源（如：集合，数组），获取一个流 中间操作：一个中间操作链，对数据源的数据进行处理 终止操作（终端操作）：一个终止操作，执行中间操作链，并产生结果 Stream Api 关于中间操作的 筛选与切片 filter ：接受Lambda，从流中派出某些元素 limit ：截断流，使其元素不超过给定数量 skip(n) ：跳过元素，返回一个扔掉了前n个元素的流。若流中元素不足n个，则返回一个空留。与limit(n)互补 distinct ：筛选，通过流所生成元素的hashCode() 和 equals()去除重复元素 映射 map:接收Lambda，将元素转换成其他形式或提取信息。接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新的元素。 flatMap:接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流 排序 sorted():自然排序(Comparable) sorted(Comparator com):定制排序(Comparator) 关于终止操作 查找与匹配 allMatch:检查是否匹配所有元素 anyMatch:检查是否至少匹配一个元素 noneMatch:检查是否没有匹配所有元素 findFirst:返回第一个元素 findAny:返回当前刘忠德任意元素 count:返回流中元素的总个数 max:返回流中的最大值 min:返回流中最小值 规约 reduce(T identity,BinaryOperator)/reduce(BinaryOperator):可以将流中元素反复结合起来，得到一个值 收集 collect:将流转化为其他形式。接受一个Collector接口的实现，用于Stream中元素做汇总的方法 并行流 并行流就是把一个内容分成多个数据块，并用不同的县城分别处理每个数据块的流，其底层原理用的时fork/join。 Java8中将并行进行了优化，我们可以很容易的对数据进行并行操作。StreamApi可以声明性的通过parallel()与sequential()在并行流与顺序流之间进行切换 Fork/Join框架（了解） 就时在必要的情况下，将一个大任务，进行拆分(fork)成若干个小任务（拆到不可再拆时），再将一个个的小任务运算的结果进行join汇总。 总体实现过程类似与将一个大任务以二叉树的形式拆分到不可拆分，在把最小单元进行运算类似于倒着的二叉树进行汇总 Optional类 Optional 类(java.unit.Optional)是一个容器类，代表一个值存在或不存在，原来用null表示一个值不存在，现在Optional可以更好的表达这个概念。并且可以避免空指针异常。 常用方法： Optional.of(T t):创建一个Optional实例 Optional.empty():创建一个空的Optional实例 Optional.ofNullable(T t):若t不为null,创建Optional实例,否则创建空实例 isPresent():判断是否包含值 orElse(T t): 如果调用对象包含值,返回该值，否则返回t orElseGet(Supplier s):如果调用对象包含值，返回该值，否则返回s获取的值 map(Function f):如果有值对其处理,并返回处理后的Optional,否则返回Optional.empty() flatMap(Function mapper):与map类似，要求返回值必须是Optionaljava8 ","link":"http://blog.ludangxin.club/post/java8-xin-te-xing/"},{"title":"SpringBoot 集成 数据源","content":"druid 简介 什么是Druid？ Druid是一个高效的数据查询系统，主要解决的是对于大量的基于时序的数据进行聚合查询。数据可以实时摄入，进入到Druid后立即可查，同时数据是几乎是不可变。通常是基于时序的事实事件，事实发生后进入Druid，外部系统就可以对该事实进行查询。 Druid采用的架构: shared-nothing架构与lambda架构 Druid设计三个原则: 快速查询（Fast Query） : 部分数据聚合（Partial Aggregate） + 内存华（In-Memory） + 索引（Index） 水平拓展能力（Horizontal Scalability）:分布式数据（Distributed data）+并行化查询（Parallelizable Query） 实时分析（Realtime Analytics）：Immutable Past , Append-Only Future 添加所需依赖 &lt;!-- druid 依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.22&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 配置 application.yml spring: datasource: name: druidDataSource type: com.alibaba.druid.pool.DruidDataSource druid: # 5.7之前版本使用 com.mysql.jdbc.Driver driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/test?useUnicode=true&amp;zeroDateTimeBehavior=convertToNull&amp;autoReconnect=true&amp;characterEncoding=utf-8 username: root password: root filters: stat,wall,log4j,config max-active: 100 initial-size: 1 max-wait: 60000 min-idle: 1 time-between-eviction-runs-millis: 60000 min-evictable-idle-time-millis: 300000 validation-query: SELECT 1 test-while-idle: true test-on-borrow: false test-on-return: false pool-prepared-statements: true max-open-prepared-statements: 50 max-pool-prepared-statement-per-connection-size: 20 import java.sql.SQLException; import javax.servlet.Filter; import javax.servlet.Servlet; import javax.sql.DataSource; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean; import org.springframework.boot.context.properties.EnableConfigurationProperties; import org.springframework.boot.web.servlet.FilterRegistrationBean; import org.springframework.boot.web.servlet.ServletRegistrationBean; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import com.alibaba.druid.pool.DruidDataSource; import com.alibaba.druid.support.http.StatViewServlet; import com.alibaba.druid.support.http.WebStatFilter; @Configuration @EnableConfigurationProperties({DruidDataSourceProperties.class}) public class DruidConfig { @Autowired private DruidDataSourceProperties properties; @Bean @ConditionalOnMissingBean public DataSource druidDataSource() { DruidDataSource druidDataSource = new DruidDataSource(); druidDataSource.setDriverClassName(properties.getDriverClassName()); druidDataSource.setUrl(properties.getUrl()); druidDataSource.setUsername(properties.getUsername()); druidDataSource.setPassword(properties.getPassword()); druidDataSource.setInitialSize(properties.getInitialSize()); druidDataSource.setMinIdle(properties.getMinIdle()); druidDataSource.setMaxActive(properties.getMaxActive()); druidDataSource.setMaxWait(properties.getMaxWait()); druidDataSource.setTimeBetweenEvictionRunsMillis(properties.getTimeBetweenEvictionRunsMillis()); druidDataSource.setMinEvictableIdleTimeMillis(properties.getMinEvictableIdleTimeMillis()); druidDataSource.setValidationQuery(properties.getValidationQuery()); druidDataSource.setTestWhileIdle(properties.isTestWhileIdle()); druidDataSource.setTestOnBorrow(properties.isTestOnBorrow()); druidDataSource.setTestOnReturn(properties.isTestOnReturn()); druidDataSource.setPoolPreparedStatements(properties.isPoolPreparedStatements()); druidDataSource.setMaxPoolPreparedStatementPerConnectionSize(properties.getMaxPoolPreparedStatementPerConnectionSize()); try { druidDataSource.setFilters(properties.getFilters()); druidDataSource.init(); } catch (SQLException e) { e.printStackTrace(); } return druidDataSource; } /** * 注册Servlet信息， 配置监控视图 * @return */ @Bean @ConditionalOnMissingBean public ServletRegistrationBean&lt;Servlet&gt; druidServlet() { ServletRegistrationBean&lt;Servlet&gt; servletRegistrationBean = new ServletRegistrationBean&lt;Servlet&gt;(new StatViewServlet(), &quot;/druid/*&quot;); //白名单：如果是限定指定的子网里的所有ip都可以访问，那就是ip/子网掩码数。例如 192.168.1.120/24 就相当于192.168.1.* servletRegistrationBean.addInitParameter(&quot;allow&quot;,&quot;192.168.1.195&quot;); //IP黑名单 (存在共同时，deny优先于allow) : 如果满足deny的话提示:Sorry, you are not permitted to view this page. servletRegistrationBean.addInitParameter(&quot;deny&quot;,&quot;192.168.1.119&quot;); //登录查看信息的账号密码, 用于登录Druid监控后台 servletRegistrationBean.addInitParameter(&quot;loginUsername&quot;, &quot;admin&quot;); servletRegistrationBean.addInitParameter(&quot;loginPassword&quot;, &quot;admin&quot;); //是否能够重置数据. servletRegistrationBean.addInitParameter(&quot;resetEnable&quot;, &quot;true&quot;); return servletRegistrationBean; } /** * 注册Filter信息, 监控拦截器 * @return */ @Bean @ConditionalOnMissingBean public FilterRegistrationBean&lt;Filter&gt; filterRegistrationBean() { FilterRegistrationBean&lt;Filter&gt; filterRegistrationBean = new FilterRegistrationBean&lt;Filter&gt;(); filterRegistrationBean.setFilter(new WebStatFilter()); filterRegistrationBean.addUrlPatterns(&quot;/*&quot;); filterRegistrationBean.addInitParameter(&quot;exclusions&quot;, &quot;*.js,*.gif,*.jpg,*.png,*.css,*.ico,/druid/*&quot;); return filterRegistrationBean; } } import org.springframework.boot.context.properties.ConfigurationProperties; @ConfigurationProperties(prefix = &quot;spring.datasource.druid&quot;) @Data public class DruidDataSourceProperties { // jdbc private String driverClassName; private String url; private String username; private String password; // jdbc connection pool private int initialSize; private int minIdle; private int maxActive = 100; private long maxWait; private long timeBetweenEvictionRunsMillis; private long minEvictableIdleTimeMillis; private String validationQuery; private boolean testWhileIdle; private boolean testOnBorrow; private boolean testOnReturn; private boolean poolPreparedStatements; private int maxPoolPreparedStatementPerConnectionSize; // filter private String filters; hikaricp 简介 官方GitHub地址 什么是hikaricp? HikariCP是由日本程序员开源的一个数据库连接池组件，代码非常轻量，并且速度非常的快。根据官方提供的数据，在i7,开启32个线程32个连接的情况下，进行随机数据库读写操作，HikariCP的速度是现在常用的C3P0数据库连接池的数百倍。在SpringBoot2.0中，官方也是推荐使用HikariCP。 优化 为什么hikaricp这么块? 字节码精简 ： 优化代码，直到编译后的字节码最少，这样，CPU 缓存可以加载更多的程序代码 优化代理和拦截器 ： 减少代码，例如 HikariCP 的 Statement proxy 只有 100 行代码，只有 BoneCP 的十分之一 自定义数组类型（FastStatementList）代替 ArrayList ： 避免每次 get() 调用都要进行 range check，避免调用 remove() 时的从头到尾的扫描 自定义集合类型（ConcurrentBag）： 提高并发读写的效率 其他针对 BoneCP 缺陷的优化： 比如对于耗时超过一个 CPU 时间片的方法调用的研究（但没说具体怎么优化） 与druid对比 在github上有网友贴出了阿里巴巴Druid与hikari的对比，认为hikari在性能上是完全秒杀阿里巴巴的Druid连接池的。对此，阿里的工程师也做了一定的回应，说Druid的性能稍微差点是锁机制的不同，并且Druid提供了更丰富的功能，两者的侧重点不一样。 添加所需依赖 如果我们使用的是Spring Boot 2.0或者之后的版本，我们不需要去单独在pom.xml文件中引入HikariCP依赖。因为默认情况下spring-boot-starter-jdbc 或者 mybatis-spring-boot-starter 会依赖进来。 &lt;!-- mysql依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; 配置 application.yml spring: datasource: type: com.zaxxer.hikari.HikariDataSource driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/test?useUnicode=true&amp;zeroDateTimeBehavior=convertToNull&amp;autoReconnect=true&amp;characterEncoding=utf-8 username: root password: root hikari: minimum-idle: 5 idle-timeout: 600000 maximum-pool-size: 10 auto-commit: true pool-name: MyHikariCP max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1 如何选择 选择哪一款就见仁见智了，不过两款都是开源产品，阿里的Druid有中文的开源社区，交流起来更加方便，并且经过阿里多个系统的实验，想必也是非常的稳定，而Hikari是SpringBoot2.0默认的连接池，全世界使用范围也非常广，对于大部分业务来说，使用哪一款都是差不多的，毕竟性能瓶颈一般都不在连接池。大家可根据自己的喜好自由选择。 ","link":"http://blog.ludangxin.club/post/springboot-ji-cheng-shu-ju-yuan/"},{"title":"SpringBoot 集成 tkMybatis pageHelper","content":"项目结构图示 引入所需依赖 &lt;!--数据库--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--结合tk-mybatis mybatis的升级插件--&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.5&lt;/version&gt; &lt;/dependency&gt; &lt;!--分页插件--&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.13&lt;/version&gt; &lt;/dependency&gt; &lt;!-- lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; 配置 application.yml spring: datasource: # Oracle: oracle.jdbc.OracleDriver driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/test?useUnicode=true&amp;characterEncoding=utf8&amp;zeroDateTimeBehavior=convertToNull&amp;useSSL=true&amp;serverTimezone=GMT%2B8 username: root password: root type: com.zaxxer.hikari.HikariDataSource hikari: minimum-idle: 5 maximum-pool-size: 5 auto-commit: true idle-timeout: 30000 pool-name: DatebookHikariCP max-lifetime: 1800000 connection-timeout: 30000 connection-test-query: SELECT 1 # Oracle: SELECT 1 FROM DUAL # 配置mybatis mybatis: # 搜索指定包别名 typeAliasesPackage: com.ldx.project.model # 配置mapper的扫描，找到所有的mapper.xml映射文件 mapperLocations: classpath*:/mapper/*Mapper.xml # 打印sql打开configuration log-impl configuration: log-impl: org.apache.ibatis.logging.stdout.StdOutImpl # PageHelper分页插件 pagehelper: # 方言 helperDialect: mysql # 分页合理化 即:页码&lt;=0 查询第一页，页码&gt;=总页数查询最后一页 reasonable: true # 支持参数过滤 supportMethodsArguments: true params: count=countSql # tk mybatis mapper: # 指定基类 mappers: - com.ldx.project.util.BaseMapper # &lt;selectKey&gt;中的order属性，可选值为BEFORE和AFTER;类似Oracle序列或者通用的 UUID 时为 true before: false # insertSelective 和 updateByPrimaryKeySelective 中，是否判断字符串类型 !='' not-empty: false # 取回主键的方式 MySQL :SELECT LAST_INSERT_ID() identity: MYSQL # 驼峰转下划线小写形式 camelhumpAndLowercase:驼峰转下划线大写形式 style: camelhumpAndUppercase 创建实体类 import lombok.Data; import javax.persistence.GeneratedValue; import javax.persistence.GenerationType; import javax.persistence.Id; import javax.persistence.Table; /** * @Author: ludangxin * @Date: 2020/5/13 15:25 */ @Data @Table(name=&quot;sys_user&quot;) public class SysUser { // @Id表示该字段对应数据库表的主键id // @GeneratedValue中strategy表示使用数据库自带的主键生成策略. // @GeneratedValue中generator配置为&quot;JDBC&quot;,在数据插入完毕之后,会自动将主键id填充到实体类中.类似普通mapper.xml中配置的selectKey标签 @Id @GeneratedValue(strategy = GenerationType.IDENTITY,generator = &quot;JDBC&quot;) private Long id; private String username; private String password; } 创建tkMybatis基类 import tk.mybatis.mapper.common.Mapper; import tk.mybatis.mapper.common.MySqlMapper; /** * mapper 基类 * 特别注意，该接口不能被扫描到，否则会出错 */ public interface BaseMapper&lt;T&gt; extends Mapper&lt;T&gt;, MySqlMapper&lt;T&gt; { } 创建mapper继承BaseMapper import com.ldx.project.model.SysUser; import com.ldx.project.util.BaseMapper; /** * @Author: ludangxin * @Date: 2020/5/13 17:27 */ public interface SysUserMapper extends BaseMapper&lt;SysUser&gt; { } 修改启动类 import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import tk.mybatis.spring.annotation.MapperScan; @MapperScan(basePackages = &quot;com.ldx.project.mapper&quot;) @SpringBootApplication public class SpringbootTkMybatisPageHelper { public static void main(String[] args) { SpringApplication.run(SpringbootTkMybatisPageHelper.class, args); } } 创建测试类 import com.github.pagehelper.PageHelper; import com.github.pagehelper.PageInfo; import com.ldx.project.mapper.SysUserMapper; import com.ldx.project.model.SysUser; import org.junit.jupiter.api.Test; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.test.context.SpringBootTest; import org.springframework.test.annotation.Rollback; import org.springframework.transaction.annotation.Transactional; import tk.mybatis.mapper.entity.Example; import java.util.List; @SpringBootTest(classes = SpringbootTkMybatisPageHelper.class) @Transactional @Rollback public class MybatisTest { /** * 注入数据查询接口 */ @Autowired private SysUserMapper tbUserMapper; /** * 测试插入数据 */ @Test public void testInsert() { // 构造一条测试数据 SysUser sysUser = new SysUser(); sysUser.setUsername(&quot;ludangxin&quot;); sysUser.setPassword(&quot;123456&quot;); // 插入数据 tbUserMapper.insert(sysUser); } /** * 测试删除数据 */ @Test public void testDelete() { // 构造条件，等同于 DELETE from tb_user WHERE username = 'ludangxin' Example example = new Example(SysUser.class); example.createCriteria().andEqualTo(&quot;username&quot;, &quot;ludangxin&quot;); // 删除数据 tbUserMapper.deleteByExample(example); } /** * 测试修改数据 */ @Test public void testUpdate() { // 构造条件 Example example = new Example(SysUser.class); example.createCriteria().andEqualTo(&quot;username&quot;, &quot;ludangxin&quot;); // 构造一条测试数据 SysUser sysUser = new SysUser(); sysUser.setUsername(&quot;ludangxin&quot;); sysUser.setPassword(&quot;123456&quot;); // 修改数据 tbUserMapper.updateByExample(sysUser, example); } /** * 测试查询集合 */ @Test public void testSelect() { List&lt;SysUser&gt; sysUsers = tbUserMapper.selectAll(); for (SysUser user : sysUsers) { System.out.println(user.getUsername()); } } /** * 测试分页查询 */ @Test public void testPage() { // PageHelper 使用非常简单，只需要设置页码和每页显示笔数即可 PageHelper.startPage(0, 2); // 设置分页查询条件 Example example = new Example(SysUser.class); PageInfo&lt;SysUser&gt; pageInfo = new PageInfo&lt;&gt;(tbUserMapper.selectByExample(example)); // 获取查询结果 List&lt;SysUser&gt; sysUsers = pageInfo.getList(); for (SysUser sysUser : sysUsers) { System.out.println(sysUser.getUsername()); } } } ","link":"http://blog.ludangxin.club/post/springboot-ji-cheng-tkmybatis-pagehelper/"}]}